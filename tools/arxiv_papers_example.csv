Paper ID,Title,URL,Summary,First Author,Publish Date,Update Date,Code URL,Stars
2502.03466v1,On the origin of mid-infrared colors in $Î³$-ray blazars,http://arxiv.org/abs/2502.03466v1,"Context. The combination between non-thermal and thermal emission in$\gamma$-ray blazars pushes them to a specific region of the mid-infraredthree-dimensional color diagram, the so-called blazar locus, built based onobservations performed with the Wide-field Infrared Survey Explorer. Theselection of blazar candidates based on these mid-infrared colors has beenextensively used in the past decade in the hunt for the counterparts ofunassociated $\gamma$-ray sources observed with the Fermi Large Area Telescopeand in the search for new blazars in optical spectroscopic campaigns.  Aims. In this work, we provide a theoretical description of the origin of theblazar locus and show how we can reasonably reproduce it with a modelconsisting of only three spectral components: a log-parabola accounting for thenon-thermal emission, and an elliptical host and dust torus accounting for thethermal emission.  Methods. We simulate spectral energy distributions for blazars, starting witha pure log-parabola model and then increasing its complexity by adding atemplate elliptical galaxy and dust torus. From these simulations, we computethe mid-infrared magnitudes and corresponding colors to create our own versionof the blazar locus.  Results. Our modeling allows for the selection of spectral parameters thatbetter characterize the mid-infrared emission of $\gamma$-ray blazars, such asthe log-parabola curvature ($\beta < 0.04$ for 50\% of our sample) and anaverage spectral peak around $E_p \approx 1.5 \times 10^{-13}$ erg. We alsofind that the log-parabola is the main spectral component behind the observedmid-infrared blazar colors, although additional components such as a hostgalaxy and a dust torus are crucial to obtain a precise reconstruction of theblazar locus.",Raniere de Menezes,2025-02-05,2025-02-05,,N/A
2502.03465v1,Seeing World Dynamics in a Nutshell,http://arxiv.org/abs/2502.03465v1,"We consider the problem of efficiently representing casually capturedmonocular videos in a spatially- and temporally-coherent manner. While existingapproaches predominantly rely on 2D/2.5D techniques treating videos ascollections of spatiotemporal pixels, they struggle with complex motions,occlusions, and geometric consistency due to absence of temporal coherence andexplicit 3D structure. Drawing inspiration from monocular video as a projectionof the dynamic 3D world, we explore representing videos in their intrinsic 3Dform through continuous flows of Gaussian primitives in space-time. In thispaper, we propose NutWorld, a novel framework that efficiently transformsmonocular videos into dynamic 3D Gaussian representations in a single forwardpass. At its core, NutWorld introduces a structured spatial-temporal alignedGaussian (STAG) representation, enabling optimization-free scene modeling witheffective depth and flow regularization. Through comprehensive experiments, wedemonstrate that NutWorld achieves high-fidelity video reconstruction qualitywhile enabling various downstream applications in real-time. Demos and codewill be available at https://github.com/Nut-World/NutWorld.",Qiuhong Shen,2025-02-05,2025-02-05,,N/A
2502.03462v1,Efficient Lindblad synthesis for noise model construction,http://arxiv.org/abs/2502.03462v1,"Effective noise models are essential for analyzing and understanding thedynamics of quantum systems, particularly in applications like quantum errormitigation and correction. However, even when noise processes arewell-characterized in isolation, the effective noise channels impacting targetquantum operations can differ significantly, as different gates experiencenoise in distinct ways. Here, we present a noise model construction method thatbuilds an effective model from a Lindbladian description of the physical noiseprocesses acting simultaneously to the desired gate operation. It employs theMagnus expansion and Dyson series, and can be utilized for both low-ordersymbolic and high-order numerical approximations of the noise channel of amulti-qubit quantum gate. We envision multiple use cases of our noiseconstruction method such as (i) computing the corresponding noise channel froma learned Lindbladian, and (ii) generating the noise channel starting withphysically motivated Lindbladians for a given hardware architecture. In doingso, we close the gap between physical Lindbladians and operational level noisemodel parameters. We demonstrate a strong agreement between our symbolic noiseconstruction and full numerical Lindblad simulations for various two-qubitgates, in isolation and in three- and four-qubit scenarios, for a variety ofphysically motivated noise sources. Our symbolic construction provides a usefulbreakdown of how noise model parameters depend on the underlying physical noiseparameters, which gives qualitative insight into the structure of errors. Forinstance, our theory provides insight into the interplay of Lindblad noise withthe intended gate operations, and can predict how local Lindblad noise caneffectively spread into multi-qubit error.",Moein Malekakhlagh,2025-02-05,2025-02-05,,N/A
2502.03461v1,Do Large Language Model Benchmarks Test Reliability?,http://arxiv.org/abs/2502.03461v1,"When deploying large language models (LLMs), it is important to ensure thatthese models are not only capable, but also reliable. Many benchmarks have beencreated to track LLMs' growing capabilities, however there has been no similarfocus on measuring their reliability. To understand the potential ramificationsof this gap, we investigate how well current benchmarks quantify modelreliability. We find that pervasive label errors can compromise theseevaluations, obscuring lingering model failures and hiding unreliable behavior.  Motivated by this gap in the evaluation of reliability, we then propose theconcept of so-called platinum benchmarks, i.e., benchmarks carefully curated tominimize label errors and ambiguity. As a first attempt at constructing suchbenchmarks, we revise examples from fifteen existing popular benchmarks. Weevaluate a wide range of models on these platinum benchmarks and find that,indeed, frontier LLMs still exhibit failures on simple tasks such aselementary-level math word problems. Analyzing these failures further revealspreviously unidentified patterns of problems on which frontier modelsconsistently struggle. We provide code athttps://github.com/MadryLab/platinum-benchmarks",Joshua Vendrow,2025-02-05,2025-02-05,,N/A
2502.03460v1,Adapt-Pruner: Adaptive Structural Pruning for Efficient Small Language Model Training,http://arxiv.org/abs/2502.03460v1,"Small language models (SLMs) have attracted considerable attention from bothacademia and industry due to their broad range of applications in edge devices.To obtain SLMs with strong performance, conventional approaches eitherpre-train the models from scratch, which incurs substantial computationalcosts, or compress/prune existing large language models (LLMs), which resultsin performance drops and falls short in comparison to pre-training. In thispaper, we investigate the family of acceleration methods that involve bothstructured pruning and model training. We found 1) layer-wise adaptive pruning(Adapt-Pruner) is extremely effective in LLMs and yields significantimprovements over existing pruning techniques, 2) adaptive pruning equippedwith further training leads to models comparable to those pre-training fromscratch, 3) incremental pruning brings non-trivial performance gain byinterleaving pruning with training and only removing a small portion of neurons($\sim$5%) at a time. Experimental results on LLaMA-3.1-8B demonstrate thatAdapt-Pruner outperforms conventional pruning methods, such as LLM-Pruner,FLAP, and SliceGPT, by an average of 1%-7% in accuracy on commonsensebenchmarks. Additionally, Adapt-Pruner restores the performance ofMobileLLM-125M to 600M on the MMLU benchmark with 200$\times$ fewer tokens viapruning from its larger counterparts, and discovers a new 1B model thatsurpasses LLaMA-3.2-1B in multiple benchmarks.",Boyao Wang,2025-02-05,2025-02-05,,N/A
2502.03459v1,SKI Models: Skeleton Induced Vision-Language Embeddings for Understanding Activities of Daily Living,http://arxiv.org/abs/2502.03459v1,"The introduction of vision-language models like CLIP has enabled thedevelopment of foundational video models capable of generalizing to unseenvideos and human actions. However, these models are typically trained on webvideos, which often fail to capture the challenges present in Activities ofDaily Living (ADL) videos. Existing works address ADL-specific challenges, suchas similar appearances, subtle motion patterns, and multiple viewpoints, bycombining 3D skeletons and RGB videos. However, these approaches are notintegrated with language, limiting their ability to generalize to unseen actionclasses. In this paper, we introduce SKI models, which integrate 3D skeletonsinto the vision-language embedding space. SKI models leverage askeleton-language model, SkeletonCLIP, to infuse skeleton information intoVision Language Models (VLMs) and Large Vision Language Models (LVLMs) throughcollaborative training. Notably, SKI models do not require skeleton data duringinference, enhancing their robustness for real-world applications. Theeffectiveness of SKI models is validated on three popular ADL datasets forzero-shot action recognition and video caption generation tasks.",Arkaprava Sinha,2025-02-05,2025-02-05,,N/A
2502.03457v1,Clustering of the extrema: A theoretical description of weak lensing critical points power spectra in the mildly nonlinear regime,http://arxiv.org/abs/2502.03457v1,"In cosmic web analysis, complementary to traditional cosmological probes, theextrema (e.g. peaks and voids) two-point correlation functions (2PCFs) are ofparticular interest for the study of both astrophysical phenomena andcosmological structure formation. However most previous studies constructedthose statistics via N-body simulations without a robust theoretical derivationfrom first principles. A strong motivation exists for analytically describingthe 2PCFs of these local extrema, taking into account the nonlineargravitational evolution in the late Universe. In this paper, we deriveanalytical formulae for the power spectra and 2PCFs of 2D critical points,including peaks (maxima), voids (minima) and saddle points, in mildlynon-Gaussian weak gravitational lensing fields. We apply a perturbative biasexpansion to model the clustering of 2D critical points. We successfully derivethe power spectrum of weak lensing critical points up to thenext-to-next-to-leading order (NNLO) in gravitational perturbation theory,where trispectrum configurations of the weak lensing field have to be included.We numerically evaluate those power spectra up to the next-to-leading order(NLO), which correspond to the inclusion of bispectrum configurations, andtransform them to the corresponding 2PCFs. An exact Monte Carlo (MC)integration is performed assuming a Gaussian distributed density field tovalidate our theoretical predictions. Overall, we find similar properties in 2Dcompared to the clustering of 3D critical points previously measured fromN-body simulations. Contrary to standard lensing power spectra analysis, wefind distinct BAO features in the lensing peak 2PCFs due to the gradient andcurvature constraints, and we quantify that non-Gaussianity makes for ~10% ofthe signal at quasi-linear scales which could be important for current stage-IVsurveys.",Zhengyangguang Gong,2025-02-05,2025-02-05,,N/A
2502.03455v1,DESI Strong Lens Foundry I: HST Observations and Modeling with GIGA-Lens,http://arxiv.org/abs/2502.03455v1,"We present the Dark Energy Spectroscopic Instrument (DESI) Strong LensFoundry. We discovered $\sim 3500$ new strong gravitational lens candidates inthe DESI Legacy Imaging Surveys using residual neural networks (ResNet). Weobserved a subset (51) of our candidates using the Hubble Space Telescope(HST). All of them were confirmed to be strong lenses. We also briefly describespectroscopic follow-up observations by DESI and Keck NIRES programs. From thisvery rich dataset, a number of studies will be carried out, includingevaluating the quality of the ResNet search candidates and lens modeling. Inthis paper we present our initial effort in these directions. In particular, asa demonstration, we present the lens model for DESI-165.4754-06.0423, withimaging data from HST, and lens and source redshifts from DESI and Keck NIRES,respectively. We use a fast, fully forward-modeling Bayesian pipeline,GIGA-Lens. This is the first time a strong lens with HST data, or any highresolution imaging, has been modeled using GPUs.",X. Huang,2025-02-05,2025-02-05,,N/A
2502.03454v1,Kineto-Dynamical Planning and Accurate Execution of Minimum-Time Maneuvers on Three-Dimensional Circuits,http://arxiv.org/abs/2502.03454v1,"Online planning and execution of minimum-time maneuvers on three-dimensional(3D) circuits is an open challenge in autonomous vehicle racing. In this paper,we present an artificial race driver (ARD) to learn the vehicle dynamics, planand execute minimum-time maneuvers on a 3D track. ARD integrates a novelkineto-dynamical (KD) vehicle model for trajectory planning with economicnonlinear model predictive control (E-NMPC). We use a high-fidelity vehiclesimulator (VS) to compare the closed-loop ARD results with a minimum-lap-timeoptimal control problem (MLT-VS), solved offline with the same VS. Our ARD setslap times close to the MLT-VS, and the new KD model outperforms a literaturebenchmark. Finally, we study the vehicle trajectories, to assess there-planning capabilities of ARD under execution errors. A video with the mainresults is available as supplementary material.",Mattia Piccinini,2025-02-05,2025-02-05,,N/A
2502.03452v1,Unconventional anomalous Hall effect in hexagonal polar magnet Y_3Co_8Sn_4,http://arxiv.org/abs/2502.03452v1,"We report a rare realization of unconventional anomalous Hall effect (UAHE)both below and above the magnetic transition temperature (T_C) in a hexagonalnoncentrosymmetric magnet Y_3Co_8Sn_4, using a combined experimental andab-initio calculations. Occurrence of such UAHE is mainly attributed to thereciprocal (KS) topology (i.e. the presence of topological Weyl points at/nearthe Fermi level), along with some contribution from the topological magnetictexture, as inferred from the measured field-dependent ac susceptibility. Theeffect of UAHE on the measured transport behavior however evolves differentlywith temperature above and below T_C, suggesting different physical mechanismresponsible in the two phases. A unique planar ferrimagnetic ordering is foundto be the most stable state with ab-plane as the easy plane below TC, asobserved experimentally. The simulated net magnetization and the moment per Coatom agrees fairly well with the measured values. A reasonably large AHC isalso observed in both the phases (above and below and T_C) of the presentcompound, which is again not so ubiquitous. Our results underscore the familyof R_3Co_8Sn_4 (R= rare earth) polar magnets as a compelling backdrop forexploring the synergy of topological magnetism and non-trivial electronicbands, pivotal for spintronic applications.",Afsar Ahmed,2025-02-05,2025-02-05,,N/A
2502.03450v1,A Schema-Guided Reason-while-Retrieve framework for Reasoning on Scene Graphs with Large-Language-Models (LLMs),http://arxiv.org/abs/2502.03450v1,"Scene graphs have emerged as a structured and serializable environmentrepresentation for grounded spatial reasoning with Large Language Models(LLMs). In this work, we propose SG-RwR, a Schema-Guided Retrieve-while-Reasonframework for reasoning and planning with scene graphs. Our approach employstwo cooperative, code-writing LLM agents: a (1) Reasoner for task planning andinformation queries generation, and a (2) Retriever for extractingcorresponding graph information following the queries. Two agents collaborateiteratively, enabling sequential reasoning and adaptive attention to graphinformation. Unlike prior works, both agents are prompted only with the scenegraph schema rather than the full graph data, which reduces the hallucinationby limiting input tokens, and drives the Reasoner to generate reasoning traceabstractly.Following the trace, the Retriever programmatically query the scenegraph data based on the schema understanding, allowing dynamic and globalattention on the graph that enhances alignment between reasoning and retrieval.Through experiments in multiple simulation environments, we show that ourframework surpasses existing LLM-based approaches in numerical Q\&A andplanning tasks, and can benefit from task-level few-shot examples, even in theabsence of agent-level demonstrations. Project code will be released.",Yiye Chen,2025-02-05,2025-02-05,,N/A
2502.03449v1,Dress-1-to-3: Single Image to Simulation-Ready 3D Outfit with Diffusion Prior and Differentiable Physics,http://arxiv.org/abs/2502.03449v1,"Recent advances in large models have significantly advanced image-to-3Dreconstruction. However, the generated models are often fused into a singlepiece, limiting their applicability in downstream tasks. This paper focuses on3D garment generation, a key area for applications like virtual try-on withdynamic garment animations, which require garments to be separable andsimulation-ready. We introduce Dress-1-to-3, a novel pipeline that reconstructsphysics-plausible, simulation-ready separated garments with sewing patterns andhumans from an in-the-wild image. Starting with the image, our approachcombines a pre-trained image-to-sewing pattern generation model for creatingcoarse sewing patterns with a pre-trained multi-view diffusion model to producemulti-view images. The sewing pattern is further refined using a differentiablegarment simulator based on the generated multi-view images. Versatileexperiments demonstrate that our optimization approach substantially enhancesthe geometric alignment of the reconstructed 3D garments and humans with theinput image. Furthermore, by integrating a texture generation module and ahuman motion generation module, we produce customized physics-plausible andrealistic dynamic garment demonstrations. Project page:https://dress-1-to-3.github.io/",Xuan Li,2025-02-05,2025-02-05,,N/A
2502.03445v1,TensorQC: Towards Scalable Distributed Quantum Computing via Tensor Networks,http://arxiv.org/abs/2502.03445v1,"A quantum processing unit (QPU) must contain a large number of high qualityqubits to produce accurate results for problems at useful scales. In contrast,most scientific and industry classical computation workloads happen in parallelon distributed systems, which rely on copying data across multiple cores.Unfortunately, copying quantum data is theoretically prohibited due to thequantum non-cloning theory. Instead, quantum circuit cutting techniques cut alarge quantum circuit into multiple smaller subcircuits, distribute thesubcircuits on parallel QPUs and reconstruct the results with classicalcomputing. Such techniques make distributed hybrid quantum computing (DHQC) apossibility but also introduce an exponential classical co-processing cost inthe number of cuts and easily become intractable. This paper presents TensorQC,which leverages classical tensor networks to bring an exponential runtimeadvantage over state-of-the-art parallelization post-processing techniques. Asa result, this paper demonstrates running benchmarks that are otherwiseintractable for a standalone QPU and prior circuit cutting techniques.Specifically, this paper runs six realistic benchmarks using QPUs availablenowadays and a single GPU, and reduces the QPU size and quality requirements bymore than $10\times$ over purely quantum platforms.",Wei Tang,2025-02-05,2025-02-05,,N/A
2502.03444v1,Masked Autoencoders Are Effective Tokenizers for Diffusion Models,http://arxiv.org/abs/2502.03444v1,"Recent advances in latent diffusion models have demonstrated theireffectiveness for high-resolution image synthesis. However, the properties ofthe latent space from tokenizer for better learning and generation of diffusionmodels remain under-explored. Theoretically and empirically, we find thatimproved generation quality is closely tied to the latent distributions withbetter structure, such as the ones with fewer Gaussian Mixture modes and morediscriminative features. Motivated by these insights, we propose MAETok, anautoencoder (AE) leveraging mask modeling to learn semantically rich latentspace while maintaining reconstruction fidelity. Extensive experiments validateour analysis, demonstrating that the variational form of autoencoders is notnecessary, and a discriminative latent space from AE alone enablesstate-of-the-art performance on ImageNet generation using only 128 tokens.MAETok achieves significant practical improvements, enabling a gFID of 1.69with 76x faster training and 31x higher inference throughput for 512x512generation. Our findings show that the structure of the latent space, ratherthan variational constraints, is crucial for effective diffusion models. Codeand trained models are released.",Hao Chen,2025-02-05,2025-02-05,,N/A
2502.03443v1,Top-quark spin correlations as a tool to distinguish pseudoscalar $A \to ZH$ and scalar $H \to ZA$ signatures in $Z t \bar t$ final states at the LHC,http://arxiv.org/abs/2502.03443v1,"Both ATLAS and CMS have recently performed the first searches for a heavy newspin-0 resonance decaying into a lighter new spin-0 resonance and a $Z$ boson,where the lighter spin-0 resonance subsequently decays into $t \bar t$ pairs.These searches are of particular interest to probe Two Higgs doublet model(2HDM) parameter space regions that predict a strong first-order electroweakphase transition. In the absence of CP violation, the investigated decay ispossible if the lighter and the heavier spin-0 particles have opposite CPparities. The analysis techniques employed by ATLAS and CMS do not distinguishbetween the two possible signatures $A \to ZH$ and $H \to ZA$, where $A$ and$H$ denote CP-odd and CP-even Higgs bosons, respectively, if both signals arepredicted to have the same total cross sections. We demonstrate the capabilityof angular variables that are sensitive to spin correlations of the top quarksto differentiate between $A \to ZH$ and $H \to ZA$ decays, even in scenarioswhere both signals possess identical total cross sections. Focusing on massesof 600 GeV and 800 GeV as a representative 2HDM benchmark, we find that adistinction between the two possible channels is possible with highsignificance with the anticipated data from the high-luminosity LHC, if theinvariant mass distribution of the $t \bar t$ system is further binned inangular variables defined by the direction of flight of the leptons produced inthe top-quark decays. Moreover, we find a moderate gain in experimentalsensitivity due to the improved background rejection for both signals.",Francisco Arco,2025-02-05,2025-02-05,,N/A
2502.03438v1,BFS-Prover: Scalable Best-First Tree Search for LLM-based Automatic Theorem Proving,http://arxiv.org/abs/2502.03438v1,"Recent advancements in large language models (LLMs) have spurred growinginterest in automatic theorem proving using Lean4, where effective tree searchmethods are crucial for navigating proof search spaces. While the existingapproaches primarily rely on value functions and Monte Carlo Tree Search(MCTS), the potential of simpler methods like Best-First Search (BFS) remainsunderexplored. This paper investigates whether BFS can achieve competitiveperformance in large-scale theorem proving tasks. We present\texttt{BFS-Prover}, a scalable expert iteration framework, featuring three keyinnovations. First, we implement strategic data filtering at each expertiteration round, excluding problems solvable via beam search node expansion tofocus on harder cases. Second, we improve the sample efficiency of BFS throughDirect Preference Optimization (DPO) applied to state-tactic pairsautomatically annotated with compiler error feedback, refining the LLM's policyto prioritize productive expansions. Third, we employ length normalization inBFS to encourage exploration of deeper proof paths. \texttt{BFS-Prover}achieves a score of $71.31$ on the MiniF2F test set and therefore challengesthe perceived necessity of complex tree search methods, demonstrating that BFScan achieve competitive performance when properly scaled.",Ran Xin,2025-02-05,2025-02-05,,N/A
2502.03437v1,The Second Moment of Sums of Hecke Eigenvalues I,http://arxiv.org/abs/2502.03437v1,"Let $f$ be a Hecke cusp form of weight $k$ for $\mathrm{SL}_2(\mathbb{Z})$,and let $(\lambda_f(n))_{n\geq1}$ denote its (suitably normalised) sequence ofHecke eigenvalues. We compute the first and second moments of the sums$S(x,f)=\sum_{x\leq n\leq 2x}\lambda_f(n)$, on average over forms $f$ of largeweight $k$, in the regime where the length of the sums $x$ is smaller than$k^2$. We observe interesting transitions in the size of the sums when$x\approx k$ and $x\approx k^2$. In subsequent work (part II), it will be shownthat once $x$ is larger than $k^2$ (where the latter transition occurs), theaverage size of the sums $S(x,f)$ becomes dramatically smaller.",Ned Carmichael,2025-02-05,2025-02-05,,N/A
2502.03436v1,The Second Moment of Sums of Hecke Eigenvalues II,http://arxiv.org/abs/2502.03436v1,"Let $f$ be a Hecke cusp form of weight $k$ for $\mathrm{SL}_2(\mathbb{Z})$,and let $(\lambda_f(n))_{n\geq 1}$ denote its (suitably normalised) sequence ofHecke eigenvalues. We compute the first and second moments of the sums$S(x,f)=\sum_{x\leq n\leq 2x} \lambda_f(n)$, on average over forms $f$ of largeweight $k$. It is proved that when the length of the sums $x$ is larger than$k^2$, the second moment is roughly of size $x^{1/2}$. This is in sharpcontrast to the regime where $x$ is slightly smaller than $k^2$, where it wasshown in preceding work (part I) that the second moment is of size $x$.",Ned Carmichael,2025-02-05,2025-02-05,,N/A
2502.03435v1,Taking a Big Step: Large Learning Rates in Denoising Score Matching Prevent Memorization,http://arxiv.org/abs/2502.03435v1,"Denoising score matching plays a pivotal role in the performance ofdiffusion-based generative models. However, the empirical optimal score--theexact solution to the denoising score matching--leads to memorization, wheregenerated samples replicate the training data. Yet, in practice, only amoderate degree of memorization is observed, even without explicitregularization. In this paper, we investigate this phenomenon by uncovering animplicit regularization mechanism driven by large learning rates. Specifically,we show that in the small-noise regime, the empirical optimal score exhibitshigh irregularity. We then prove that, when trained by stochastic gradientdescent with a large enough learning rate, neural networks cannot stablyconverge to a local minimum with arbitrarily small excess risk. Consequently,the learned score cannot be arbitrarily close to the empirical optimal score,thereby mitigating memorization. To make the analysis tractable, we considerone-dimensional data and two-layer neural networks. Experiments validate thecrucial role of the learning rate in preventing memorization, even beyond theone-dimensional setting.",Yu-Han Wu,2025-02-05,2025-02-05,,N/A
2502.03434v1,Dynamics of monitored SSH Model in Krylov Space: From Complexity to Quantum Fisher Information,http://arxiv.org/abs/2502.03434v1,"In this paper, we investigate the dynamics of a non-Hermitian SSH model thatarises out of the no-click limit of a monitored SSH model in the Krylov space.We find that the saturation timescale of the complexity associated with thespread of the state in the Krylov subspace increases with the measurement rate,and late time behaviour differs across the $\mathrm{PT}$ symmetry transitionpoint. Furthermore, extending the notion of this complexity for subsystems inKrylov space, we find that the scaling of its late time value with subsystemsize shows a discontinuous jump across the $\mathrm{PT}$ transition point,indicating that it can be used as a suitable order parameter for suchtransition but not for the measurement-induced transition. Finally, we showthat the measurement-induced transition can be detected using a generalizedmeasure in the Krylov subspace, which contains information about thecorrelation landscape, such as Quantum Fisher information, which also possessessome structural similarity with the complexity functional.",Nilachal Chakrabarti,2025-02-05,2025-02-05,,N/A
2502.03433v1,Analyzing Political Discourse on Discord during the 2024 U.S. Presidential Election,http://arxiv.org/abs/2502.03433v1,"Social media networks have amplified the reach of social and politicalmovements, but most research focuses on mainstream platforms such as X, Reddit,and Facebook, overlooking Discord. As a rapidly growing, community-drivenplatform with optional decentralized moderation, Discord offers uniqueopportunities to study political discourse. This study analyzes over 30 millionmessages from political servers on Discord discussing the 2024 U.S. elections.Servers were classified as Republican-aligned, Democratic-aligned, or unalignedbased on their descriptions. We tracked changes in political conversationduring key campaign events and identified distinct political valence andimplicit biases in semantic association through embedding analysis. We observedthat Republican servers emphasized economic policies, while Democratic serversfocused on equality-related and progressive causes. Furthermore, we detected anincrease in toxic language, such as sexism, in Republican-aligned servers afterKamala Harris's nomination. These findings provide a first look at politicalbehavior on Discord, highlighting its growing role in shaping and understandingonline political engagement.",Arthur Buzelin,2025-02-05,2025-02-05,,N/A
2502.03430v1,A Temporal Convolutional Network-Based Approach and a Benchmark Dataset for Colonoscopy Video Temporal Segmentation,http://arxiv.org/abs/2502.03430v1,"Following recent advancements in computer-aided detection and diagnosissystems for colonoscopy, the automated reporting of colonoscopy procedures isset to further revolutionize clinical practice. A crucial yet underexploredaspect in the development of these systems is the creation of computer visionmodels capable of autonomously segmenting full-procedure colonoscopy videosinto anatomical sections and procedural phases. In this work, we aim to createthe first open-access dataset for this task and propose a state-of-the-artapproach, benchmarked against competitive models. We annotated the publiclyavailable REAL-Colon dataset, consisting of 2.7 million frames from 60 completecolonoscopy videos, with frame-level labels for anatomical locations andcolonoscopy phases across nine categories. We then present ColonTCN, alearning-based architecture that employs custom temporal convolutional blocksdesigned to efficiently capture long temporal dependencies for the temporalsegmentation of colonoscopy videos. We also propose a dual k-foldcross-validation evaluation protocol for this benchmark, which includes modelassessment on unseen, multi-center data.ColonTCN achieves state-of-the-artperformance in classification accuracy while maintaining a low parameter countwhen evaluated using the two proposed k-fold cross-validation settings,outperforming competitive models. We report ablation studies to provideinsights into the challenges of this task and highlight the benefits of thecustom temporal convolutional blocks, which enhance learning and improve modelefficiency. We believe that the proposed open-access benchmark and the ColonTCNapproach represent a significant advancement in the temporal segmentation ofcolonoscopy procedures, fostering further open-access research to address thisclinical need.",Carlo Biffi,2025-02-05,2025-02-05,,N/A
2502.03429v1,On Fairness of Unified Multimodal Large Language Model for Image Generation,http://arxiv.org/abs/2502.03429v1,"Unified multimodal large language models (U-MLLMs) have demonstratedimpressive performance in visual understanding and generation in an end-to-endpipeline. Compared with generation-only models (e.g., Stable Diffusion),U-MLLMs may raise new questions about bias in their outputs, which can beaffected by their unified capabilities. This gap is particularly concerninggiven the under-explored risk of propagating harmful stereotypes. In thispaper, we benchmark the latest U-MLLMs and find that most exhibit significantdemographic biases, such as gender and race bias. To better understand andmitigate this issue, we propose a locate-then-fix strategy, where we audit andshow how the individual model component is affected by bias. Our analysis showsthat bias originates primarily from the language model. More interestingly, weobserve a ""partial alignment"" phenomenon in U-MLLMs, where understanding biasappears minimal, but generation bias remains substantial. Thus, we propose anovel balanced preference model to balance the demographic distribution withsynthetic data. Experiments demonstrate that our approach reduces demographicbias while preserving semantic fidelity. We hope our findings underscore theneed for more holistic interpretation and debiasing strategies of U-MLLMs inthe future.",Ming Liu,2025-02-05,2025-02-05,,N/A
2502.03428v1,Propagation of ultrashort voltage pulses through a small quantum dot,http://arxiv.org/abs/2502.03428v1,"The coherent transport of time-resolved ultrafast excitations innanoelectronic interferometers is expected to exhibit an interesting interplaybetween the interferences and the time-dependent drive. However, the typicalfrequencies required to unlock this physics are in the THz range, making itsobservation challenging. In this work, we consider the propagation of theexcitation generated by ultrashort voltage pulses through a small quantum dot,a system which we argue can display similar physics at significantly lowerfrequencies. We model the system with a single resonant level connected to twoinfinite electrodes subjected to a time-dependent voltage bias. For shortpulses, we predict that the behaviour of the dot contrasts sharply with thelong pulse (adiabatic) limit: the current actually oscillates with theamplitude of the voltage pulse. In the ultrafast limit, we predict that thecurrent can even be negative, i.e. flow against the voltage drop. Our resultsare obtained by a combination of two approaches that are in quantitativeagreement: explicit analytical expressions in the ultrafast and ultraslowlimits and exact numerical simulations. We discuss the applicability of ourfindings and conclude that this system should be within reach of existingexperimental platforms.",Thomas Kloss,2025-02-05,2025-02-05,,N/A
2502.03427v1,A Hybrid Blockchain-IPFS Solution for Secure and Scalable Data Collection and Storage for Smart Water Meters,http://arxiv.org/abs/2502.03427v1,"Scalable and secure data management is important in Internet of Things (IoT)applications such as smart water meters, where traditional blockchain storagecan be restrictive due to high data volumes. This paper investigates a hybridblockchain and InterPlanetary File System (IPFS) approach designed to optimisestorage efficiency, enhance throughput, and reduce block time by offloadinglarge data off-chain to IPFS while preserving on-chain integrity. Asubstrate-based private blockchain was developed to store smart water meter(SWM) data, and controlled experiments were conducted to evaluate blockchainperformance with and without IPFS. Key metrics, including block size, blocktime, and transaction throughput, were analysed across varying data volumes andnode counts. Results show that integrating IPFS significantly reduces on-chainstorage demands, leading to smaller block sizes, increased throughput, andimproved block times compared to blockchain-only storage. These findingshighlight the potential of hybrid blockchain-IPFS models for efficiently andsecurely managing high-volume IoT data.",Thandile Nododile,2025-02-05,2025-02-05,,N/A
2502.03426v1,TruePose: Human-Parsing-guided Attention Diffusion for Full-ID Preserving Pose Transfer,http://arxiv.org/abs/2502.03426v1,"Pose-Guided Person Image Synthesis (PGPIS) generates images that maintain asubject's identity from a source image while adopting a specified target pose(e.g., skeleton). While diffusion-based PGPIS methods effectively preservefacial features during pose transformation, they often struggle to accuratelymaintain clothing details from the source image throughout the diffusionprocess. This limitation becomes particularly problematic when there is asubstantial difference between the source and target poses, significantlyimpacting PGPIS applications in the fashion industry where clothing stylepreservation is crucial for copyright protection. Our analysis reveals thatthis limitation primarily stems from the conditional diffusion model'sattention modules failing to adequately capture and preserve clothing patterns.To address this limitation, we propose human-parsing-guided attentiondiffusion, a novel approach that effectively preserves both facial and clothingappearance while generating high-quality results. We propose ahuman-parsing-aware Siamese network that consists of three key components: dualidentical UNets (TargetNet for diffusion denoising and SourceNet for sourceimage embedding extraction), a human-parsing-guided fusion attention (HPFA),and a CLIP-guided attention alignment (CAA). The HPFA and CAA modules can embedthe face and clothes patterns into the target image generation adaptively andeffectively. Extensive experiments on both the in-shop clothes retrievalbenchmark and the latest in-the-wild human editing dataset demonstrate ourmethod's significant advantages over 13 baseline approaches for preserving bothfacial and clothes appearance in the source image.",Zhihong Xu,2025-02-05,2025-02-05,,N/A
2502.03425v1,Harnessing Large Language Models for Curated Code Reviews,http://arxiv.org/abs/2502.03425v1,"In code review, generating structured and relevant comments is crucial foridentifying code issues and facilitating accurate code changes that ensure anefficient code review process. Well-crafted comments not only streamline thecode review itself but are also essential for subsequent tasks like coderefinement, where the code is modified to satisfy the input review comment.Although various AI-based approaches aimed to automate comment generation,their effectiveness remains limited by the quality of the training data.Existing code review datasets are often noisy and unrefined, posing limitationsto the learning potential of AI models and hindering the automation process.  To address these challenges, we propose a curation pipeline designed toenhance the quality of the largest publicly available code review dataset. Webegin by establishing an evaluation framework, incorporating specific criteriaand categories to empirically study the initial quality of the dataset. Using alarge language model (LLM)-driven approach, we then apply our curation pipelineto refine the dataset. A comparative analysis of the newly curated dataset,based on the same evaluation framework, demonstrates substantial improvementsin the clarity and conciseness of the comments. Additionally, we assess theimpact of the curated dataset on automating downstream tasks, specificallycomment generation and code refinement. Our findings show that the curateddataset leads to enhanced model performance in generating more accuratecomments. Curated comments are also more useful as they lead to more accuratecode refinement.",Oussama Ben Sghaier,2025-02-05,2025-02-05,,N/A
2502.03424v1,Prediction of the Most Fire-Sensitive Point in Building Structures with Differentiable Agents for Thermal Simulators,http://arxiv.org/abs/2502.03424v1,"Fire safety is a critical area of research in civil and mechanicalengineering, particularly in ensuring the structural stability of buildingsduring fire events. The Most Fire-Sensitive Point (MFSP) in a structure is thelocation where a fire would cause the greatest impact on structural stability.Accurate prediction of the MFSP is vital for streamlining structuralassessments and optimizing the design process. This paper presents a novelframework for MFSP prediction using a neural network-based approach thatintegrates fire dynamics and finite element analysis through a differentiableagent model. The framework focuses on predicting the Maximum Interstory DriftRatio (MIDR), a key indicator of structural performance under fire conditions.By leveraging the differentiable agent model, we efficiently generate labeleddata for MFSP and directly train a predictor for this critical metric. Toachieve this, we generated extensive simulation data encompassing structuraland fire scenarios and employed graph neural networks to represent the buildingstructures. Transfer learning was applied to optimize the training process, andan edge update mechanism was introduced to dynamically adjust edge attributes,reflecting property changes under fire conditions. The proposed model wasrigorously evaluated on simulation data, demonstrating strong performance inaccurately predicting both MIDR and MFSP, thus advancing fire safety analysisfor building structures.",Yuan Xinjie,2025-02-05,2025-02-05,,N/A
2502.03422v1,Concept Based Explanations and Class Contrasting,http://arxiv.org/abs/2502.03422v1,"Explaining deep neural networks is challenging, due to their large size andnon-linearity. In this paper, we introduce a concept-based explanation method,in order to explain the prediction for an individual class, as well ascontrasting any two classes, i.e. explain why the model predicts one class overthe other. We test it on several openly available classification models trainedon ImageNet1K, as well as on a segmentation model trained to detect tumor instained tissue samples. We perform both qualitative and quantitative tests. Forexample, for a ResNet50 model from pytorch model zoo, we can use theexplanation for why the model predicts a class 'A' to automatically select sixdataset crops where the model does not predict class 'A'. The model thenpredicts class 'A' again for the newly combined image in 71\% of the cases(works for 710 out of the 1000 classes). The code including an .ipynb exampleis available on git:https://github.com/rherdt185/concept-based-explanations-and-class-contrasting.",Rudolf Herdt,2025-02-05,2025-02-05,,N/A
2502.03421v1,Investigating Corporate Social Responsibility Initiatives: Examining the case of corporate Covid-19 response,http://arxiv.org/abs/2502.03421v1,"In todays age of freely available information, policy makers have to takeinto account a huge amount of information while making decisions affectingrelevant stakeholders. While increase in the amount of information sources anddocuments increases credibility of decisions based on the corpus of availabletext, it is challenging for policymakers to make sense of this information.This paper demonstrates how policy makers can implement some of the mostpopular topic recognition methods, Latent Dirichlet Allocation, DeepDistributed Representation method, text summarization approaches, Word BasedSentence Ranking method and TextRank for sentence extraction method, to sum upthe content of large volume of documents to understand the gist of the overloadof information. We have applied popular NLP methods to corporate press releasesduring the early period and advanced period of Covid-19 pandemic which hasresulted in a global unprecedented health and socio-economic crisis, whenpolicymaking and regulations have become especially important to standardizecorporate practices for employee and social welfare in the face of similarfuture unseen crises. The steps undertaken in this study can be replicated toyield insights from relevant documents in any other social decision-makingcontext.",Meheli Basu,2025-02-05,2025-02-05,,N/A
2502.03420v1,Can Text-to-Image Generative Models Accurately Depict Age? A Comparative Study on Synthetic Portrait Generation and Age Estimation,http://arxiv.org/abs/2502.03420v1,"Text-to-image generative models have shown remarkable progress in producingdiverse and photorealistic outputs. In this paper, we present a comprehensiveanalysis of their effectiveness in creating synthetic portraits that accuratelyrepresent various demographic attributes, with a special focus on age,nationality, and gender. Our evaluation employs prompts specifying detailedprofiles (e.g., Photorealistic selfie photo of a 32-year-old Canadian male),covering a broad spectrum of 212 nationalities, 30 distinct ages from 10 to 78,and balanced gender representation. We compare the generated images againstground truth age estimates from two established age estimation models to assesshow faithfully age is depicted. Our findings reveal that although text-to-imagemodels can consistently generate faces reflecting different identities, theaccuracy with which they capture specific ages and do so across diversedemographic backgrounds remains highly variable. These results suggest thatcurrent synthetic data may be insufficiently reliable for high-stakesage-related tasks requiring robust precision, unless practitioners are preparedto invest in significant filtering and curation. Nevertheless, they may stillbe useful in less sensitive or exploratory applications, where absolute ageprecision is not critical.",Alexey A. Novikov,2025-02-05,2025-02-05,,N/A
2502.03419v1,Dynamic Cybersickness Mitigation via Adaptive FFR and FoV adjustments,http://arxiv.org/abs/2502.03419v1,"This paper presents a novel adaptive Virtual Reality (VR) system that aims tomitigate cybersickness in immersive environments through dynamic, real-timeadjustments. The system predicts cybersickness levels in real-time using amachine learning (ML) model trained on head tracking and kinematic data. Theadaptive system adjusts foveated rendering (FFR) strength and field of view(FOV) to enhance user comfort. With a goal to balance usability with systemperformance, we believe our approach will optimize both user experience andperformance. Adapting responsively to user needs, our work explores thepotential of a machine learning-based feedback loop for user experiencemanagement, contributing to a user-centric VR system design.",Ananth N. Ramaseri-Chandra,2025-02-05,2025-02-05,,N/A
2502.03418v1,Think or Step-by-Step? UnZIPping the Black Box in Zero-Shot Prompts,http://arxiv.org/abs/2502.03418v1,"Zero-shot prompting techniques have significantly improved the performance ofLarge Language Models (LLMs). However, we lack a clear understanding of whyzero-shot prompts are so effective. For example, in the prompt ""Let's thinkstep-by-step,"" is ""think"" or ""step-by-step"" more crucial to its success?Existing interpretability methods, such as gradient-based and attention-basedapproaches, are computationally intensive and restricted to open-source models.We introduce the ZIP score (Zero-shot Importance of Perturbation score), aversatile metric applicable to both open and closed-source models, based onsystematic input word perturbations. Our experiments across four recent LLMs,seven widely-used prompts, and several tasks, reveal interesting patterns inword importance. For instance, while both 'step-by-step' and 'think' show highZIP scores, which one is more influential depends on the model and task. Wevalidate our method using controlled experiments and compare our results withhuman judgments, finding that proprietary models align more closely with humanintuition regarding word significance. These findings enhance our understandingof LLM behavior and contribute to developing more effective zero-shot promptsand improved model analysis.",Nikta Gohari Sadr,2025-02-05,2025-02-05,,N/A
2502.03417v1,From Features to Transformers: Redefining Ranking for Scalable Impact,http://arxiv.org/abs/2502.03417v1,"We present LiGR, a large-scale ranking framework developed at LinkedIn thatbrings state-of-the-art transformer-based modeling architectures intoproduction. We introduce a modified transformer architecture that incorporateslearned normalization and simultaneous set-wise attention to user history andranked items. This architecture enables several breakthrough achievements,including: (1) the deprecation of most manually designed feature engineering,outperforming the prior state-of-the-art system using only few features(compared to hundreds in the baseline), (2) validation of the scaling law forranking systems, showing improved performance with larger models, more trainingdata, and longer context sequences, and (3) simultaneous joint scoring of itemsin a set-wise manner, leading to automated improvements in diversity. To enableefficient serving of large ranking models, we describe techniques to scaleinference effectively using single-pass processing of user history and set-wiseattention. We also summarize key insights from various ablation studies and A/Btests, highlighting the most impactful technical approaches.",Fedor Borisyuk,2025-02-05,2025-02-05,,N/A
2502.03412v1,Deep Reinforcement Learning-Based Optimization of Second-Life Battery Utilization in Electric Vehicles Charging Stations,http://arxiv.org/abs/2502.03412v1,"The rapid rise in electric vehicle (EV) adoption presents significantchallenges in managing the vast number of retired EV batteries. Researchindicates that second-life batteries (SLBs) from EVs typically retainconsiderable residual capacity, offering extended utility. These batteries canbe effectively repurposed for use in EV charging stations (EVCS), providing acost-effective alternative to new batteries and reducing overall planningcosts. Integrating battery energy storage systems (BESS) with SLBs into EVCS isa promising strategy to alleviate system overload. However, efficient operationof EVCS with integrated BESS is hindered by uncertainties such as fluctuatingEV arrival and departure times and variable power prices from the grid. Thispaper presents a deep reinforcement learning-based (DRL) planning framework forEV charging stations with BESS, leveraging SLBs. We employ the advanced softactor-critic (SAC) approach, training the model on a year's worth of data toaccount for seasonal variations, including weekdays and holidays. A tailoredreward function enables effective offline training, allowing real-timeoptimization of EVCS operations under uncertainty.",Rouzbeh Haghighi,2025-02-05,2025-02-05,,N/A
2502.03410v1,The Thermodynamic Cost of Ignorance: Thermal State Preparation with One Ancilla Qubit,http://arxiv.org/abs/2502.03410v1,"In this work we investigate a model of thermalization wherein a singleancillary qubit randomly interacts with the system to be thermalized. This notonly sheds light on the emergence of Gibbs states in nature, but also providesa routine for preparing arbitrary thermal states on a digital quantum computer.For desired $\beta$ and random interaction $G$ the routine boils down to timeindependent Hamiltonian simulation and is represented by the channel $\Phi :\rho \mapsto \mathbb{E}_G {\rm Tr}_{\rm Env} \left[ e^{-i(H + \alpha G)t}\left(\rho \otimes \frac{e^{-\beta H_E}}{\mathcal{Z}}\right) e^{i (H + \alphaG)t} \right]$. We rigorously prove that these dynamics reduce to a Markov chainprocess in the weak-coupling regime with the thermal state as the approximatefixed point. We upper bound the total simulation time required in terms of theMarkov chain spectral gap $\lambda_\star$, which we compute exactly in theground state limit. These results are independent of any eigenvalue knowledgeof the system, but we are further able to show that with knowledge ofeigenvalue differences $\lambda_S(i) - \lambda_S(j)$, then the total simulationtime is dramatically reduced. The ratio of the complete ignorance simulationcost to the perfect knowledge simulation cost scales as $\widetilde{O}\left({\frac{\|{H_S}\|^7}{\delta_{\rm min}^7 \epsilon^{3.5}\lambda_\star(\beta)^{3.5}}}\right)$, where $\delta_{\min}$ is related to theeigenvalue differences of the system. Additionally, we provide more specificresults for single qubit and harmonic oscillator systems as well as numericexperiments with hydrogen chains. In addition to the algorithmic merits, theseresults can be viewed as broad extensions of the Repeated Interactions model togeneric Hamiltonians with unknown interactions, giving a complete picture ofthe thermalization process for quantum systems.",Matthew Hagan,2025-02-05,2025-02-05,,N/A
2502.03407v1,Detecting Strategic Deception Using Linear Probes,http://arxiv.org/abs/2502.03407v1,"AI models might use deceptive strategies as part of scheming or misalignedbehaviour. Monitoring outputs alone is insufficient, since the AI might produceseemingly benign outputs while their internal reasoning is misaligned. We thusevaluate if linear probes can robustly detect deception by monitoring modelactivations. We test two probe-training datasets, one with contrastinginstructions to be honest or deceptive (following Zou et al., 2023) and one ofresponses to simple roleplaying scenarios. We test whether these probesgeneralize to realistic settings where Llama-3.3-70B-Instruct behavesdeceptively, such as concealing insider trading (Scheurer et al., 2023) andpurposely underperforming on safety evaluations (Benton et al., 2024). We findthat our probe distinguishes honest and deceptive responses with AUROCs between0.96 and 0.999 on our evaluation datasets. If we set the decision threshold tohave a 1% false positive rate on chat data not related to deception, our probecatches 95-99% of the deceptive responses. Overall we think white-box probesare promising for future monitoring systems, but current performance isinsufficient as a robust defence against deception. Our probes' outputs can beviewed at data.apolloresearch.ai/dd and our code atgithub.com/ApolloResearch/deception-detection.",Nicholas Goldowsky-Dill,2025-02-05,2025-02-05,,N/A
2502.03406v1,Estimating Export-productivity Cutoff Contours with Profit Data: A Novel Threshold Estimation Approach,http://arxiv.org/abs/2502.03406v1,"This paper develops a novel method to estimate firm-specific market-entrythresholds in international economics, allowing fixed costs to vary acrossfirms alongside productivity. Our framework models market entry as aninteraction between productivity and observable fixed-cost measures, extendingtraditional single-threshold models to ones with set-valued thresholds.Applying this approach to Chinese firm data, we estimate export-market entrythresholds as functions of domestic sales and surrogate variables for fixedcosts. The results reveal substantial heterogeneity and threshold contours,challenging conventional single-threshold-point assumptions. These findingsoffer new insights into firm behavior and provide a foundation for furthertheoretical and empirical advancements in trade research.",Peter H. Egger,2025-02-05,2025-02-05,,N/A
2502.03405v1,Deep Clustering via Probabilistic Ratio-Cut Optimization,http://arxiv.org/abs/2502.03405v1,"We propose a novel approach for optimizing the graph ratio-cut by modelingthe binary assignments as random variables. We provide an upper bound on theexpected ratio-cut, as well as an unbiased estimate of its gradient, to learnthe parameters of the assignment variables in an online setting. The clusteringresulting from our probabilistic approach (PRCut) outperforms the Rayleighquotient relaxation of the combinatorial problem, its online learningextensions, and several widely used methods. We demonstrate that the PRCutclustering closely aligns with the similarity measure and can perform as wellas a supervised classifier when label-based similarities are provided. Thisnovel approach can leverage out-of-the-box self-supervised representations toachieve competitive performance and serve as an evaluation method for thequality of these representations.",Ayoub Ghriss,2025-02-05,2025-02-05,,N/A
2502.03402v1,Tensor Evolution: A framework for Fast Evaluation of Tensor Computations using Recurrences,http://arxiv.org/abs/2502.03402v1,"This paper introduces a new mathematical framework for analysis andoptimization of tensor expressions within an enclosing loop. Tensors aremulti-dimensional arrays of values. They are common in high performancecomputing (HPC) and machine learning domains. Our framework extends ScalarEvolution -- an important optimization pass implemented in both LLVM and GCC --to tensors. Scalar Evolution (SCEV) relies on the theory of `Chain ofRecurrences' for its mathematical underpinnings. We use the same theory forTensor Evolution (TeV). While some concepts from SCEV map easily to TeV -- e.g.element-wise operations; tensors introduce new operations such asconcatenation, slicing, broadcast, reduction, and reshape which have noequivalent in scalars and SCEV. Not all computations are amenable to TeVanalysis but it can play a part in the optimization and analysis parts of MLand HPC compilers. Also, for many mathematical/compiler ideas, applications maygo beyond what was initially envisioned, once others build on it and take itfurther. We hope for a similar trajectory for the tensor-evolution concept.",Javed Absar,2025-02-05,2025-02-05,,N/A
2502.03400v1,DenseReviewer: A Screening Prioritisation Tool for Systematic Review based on Dense Retrieval,http://arxiv.org/abs/2502.03400v1,"Screening is a time-consuming and labour-intensive yet required task formedical systematic reviews, as tens of thousands of studies often need to bescreened. Prioritising relevant studies to be screened allows downstreamsystematic review creation tasks to start earlier and save time. In previouswork, we developed a dense retrieval method to prioritise relevant studies withreviewer feedback during the title and abstract screening stage. Our methodoutperforms previous active learning methods in both effectiveness andefficiency. In this demo, we extend this prior work by creating (1) a web-basedscreening tool that enables end-users to screen studies exploitingstate-of-the-art methods and (2) a Python library that integrates models andfeedback mechanisms and allows researchers to develop and demonstrate newactive learning methods. We describe the tool's design and showcase how it canaid screening. The tool is available at https://densereviewer.ielab.io. Thesource code is also open sourced at https://github.com/ielab/densereviewer.",Xinyu Mao,2025-02-05,2025-02-05,,N/A
2502.03398v1,The Adoption of Artificial Intelligence in Different Network Security Concepts,http://arxiv.org/abs/2502.03398v1,"The obstacles of each security system combined with the increase ofcyber-attacks, negatively affect the effectiveness of network securitymanagement and rise the activities to be taken by the security staff andnetwork administrators. So, there is a growing need for the automated auditingand intelligent reporting strategies for reliable network security with as lessmodel complexity as possible. Newly, artificial intelligence has beeneffectively applied to various network security issues, and numerous studieshave been conducted that utilize various artificial intelligence techniques forthe purposes of encryption and secure communication, in addition to usingartificial intelligence to perform a large number of data encryption operationsin record time. The aim of the study is to present and discuss the mostprominent methods of artificial intelligence recently used in the field ofnetwork security including user authentication, Key exchanging,encryption/decryption, data integrity and intrusion detection system.",Mamoon A. Al Jbaar,2025-02-05,2025-02-05,,N/A
2502.03397v1,SPRI: Aligning Large Language Models with Context-Situated Principles,http://arxiv.org/abs/2502.03397v1,"Aligning Large Language Models to integrate and reflect human values,especially for tasks that demand intricate human oversight, is arduous since itis resource-intensive and time-consuming to depend on human expertise forcontext-specific guidance. Prior work has utilized predefined sets of rules orprinciples to steer the behavior of models (Bai et al., 2022; Sun et al.,2023). However, these principles tend to be generic, making it challenging toadapt them to each individual input query or context. In this work, we presentSituated-PRInciples (SPRI), a framework requiring minimal or no human effortthat is designed to automatically generate guiding principles in real-time foreach input query and utilize them to align each response. We evaluate SPRI onthree tasks, and show that 1) SPRI can derive principles in a complexdomain-specific task that leads to on-par performance as expert-crafted ones;2) SPRI-generated principles lead to instance-specific rubrics that outperformprior LLM-as-a-judge frameworks; 3) using SPRI to generate synthetic SFT dataleads to substantial improvement on truthfulness. We release our code and modelgenerations at https://github.com/honglizhan/SPRI-public.",Hongli Zhan,2025-02-05,2025-02-05,,N/A
2502.03396v1,Accurate AI-Driven Emergency Vehicle Location Tracking in Healthcare ITS Digital Twin,http://arxiv.org/abs/2502.03396v1,"Creating a Digital Twin (DT) for Healthcare Intelligent TransportationSystems (HITS) is a hot research trend focusing on enhancing HITS management,particularly in emergencies where ambulance vehicles must arrive at the crashscene on time and track their real-time location is crucial to the medicalauthorities. Despite the claim of real-time representation, a temporalmisalignment persists between the physical and virtual domains, leading todiscrepancies in the ambulance's location representation. This study proposesintegrating AI predictive models, specifically Support Vector Regression (SVR)and Deep Neural Networks (DNN), within a constructed mock DT data pipelineframework to anticipate the medical vehicle's next location in the virtualworld. These models align virtual representations with their physicalcounterparts, i.e., metaphorically offsetting the synchronization delay betweenthe two worlds. Trained meticulously on a historical geospatial dataset, SVRand DNN exhibit exceptional prediction accuracy in MATLAB and Pythonenvironments. Through various testing scenarios, we visually demonstrate theefficacy of our methodology, showcasing SVR and DNN's key role in significantlyreducing the witnessed gap within the HITS's DT. This transformative approachenhances real-time synchronization in emergency HITS by approximately 88% to93%.",Sarah Al-Shareeda,2025-02-05,2025-02-05,,N/A
2502.03395v1,Benchmarking Time Series Forecasting Models: From Statistical Techniques to Foundation Models in Real-World Applications,http://arxiv.org/abs/2502.03395v1,"Time series forecasting is essential for operational intelligence in thehospitality industry, and particularly challenging in large-scale, distributedsystems. This study evaluates the performance of statistical, machine learning(ML), deep learning, and foundation models in forecasting hourly sales over a14-day horizon using real-world data from a network of thousands of restaurantsacross Germany. The forecasting solution includes features such as weatherconditions, calendar events, and time-of-day patterns. Results demonstrate thestrong performance of ML-based meta-models and highlight the emerging potentialof foundation models like Chronos and TimesFM, which deliver competitiveperformance with minimal feature engineering, leveraging only the pre-trainedmodel (zero-shot inference). Additionally, a hybrid PySpark-Pandas approachproves to be a robust solution for achieving horizontal scalability inlarge-scale deployments.",Issar Arab,2025-02-05,2025-02-05,,N/A
2502.03394v1,Demagnetisation effects in single-domain particles,http://arxiv.org/abs/2502.03394v1,"According to the classical laws of magnetism, the shape of magnetically softobjects limits the effective susceptibility. For example, spherical softmagnets cannot display an effective susceptibility larger than 3. Although truefor macroscopic multi-domain magnetic materials, we show that magneticnanoparticles in a single-domain state do not suffer from this limitation. Wefind that the differences between demagnetisation factors along principal axesare relevant and can influence susceptibility for single-domain particles, butdo not limit the susceptibility as in the case for multi-domain particles. Wevalidate this result experimentally on spherical nanoparticles with varyingdiameter (8 to 150 nm) and varying volume fraction (0.1 to 47 vol%). Inagreement with our predictions, we measure susceptibilities largely above 3, infact up to more than 250, for single-domain particles. Moreover, contrary to anexisting model, we find that the susceptibility of non-interactingsingle-domain particles in a non-magnetic matrix scales simply linearly withthe volume fraction of particles.",Mathias Zambach,2025-02-05,2025-02-05,,N/A
2502.03393v1,CAPE: Covariate-Adjusted Pre-Training for Epidemic Time Series Forecasting,http://arxiv.org/abs/2502.03393v1,"Accurate forecasting of epidemic infection trajectories is crucial forsafeguarding public health. However, limited data availability during emergingoutbreaks and the complex interaction between environmental factors and diseasedynamics present significant challenges for effective forecasting. In response,we introduce CAPE, a novel epidemic pre-training framework designed to harnessextensive disease datasets from diverse regions and integrate environmentalfactors directly into the modeling process for more informed decision-making ondownstream diseases. Based on a covariate adjustment framework, CAPE utilizespre-training combined with hierarchical environment contrasting to identifyuniversal patterns across diseases while estimating latent environmentalinfluences. We have compiled a diverse collection of epidemic time seriesdatasets and validated the effectiveness of CAPE under various evaluationscenarios, including full-shot, few-shot, zero-shot, cross-location, andcross-disease settings, where it outperforms the leading baseline by an averageof 9.9% in full-shot and 14.3% in zero-shot settings. The code will be releasedupon acceptance.",Zewen Liu,2025-02-05,2025-02-05,,N/A
2502.03391v1,"Explain Yourself, Briefly! Self-Explaining Neural Networks with Concise Sufficient Reasons",http://arxiv.org/abs/2502.03391v1,"Minimal sufficient reasons represent a prevalent form of explanation - thesmallest subset of input features which, when held constant at theircorresponding values, ensure that the prediction remains unchanged. Previouspost-hoc methods attempt to obtain such explanations but face two mainlimitations: (1) Obtaining these subsets poses a computational challenge,leading most scalable methods to converge towards suboptimal, less meaningfulsubsets; (2) These methods heavily rely on sampling out-of-distribution inputassignments, potentially resulting in counterintuitive behaviors. To tacklethese limitations, we propose in this work a self-supervised training approach,which we term *sufficient subset training* (SST). Using SST, we train models togenerate concise sufficient reasons for their predictions as an integral partof their output. Our results indicate that our framework produces succinct andfaithful subsets substantially more efficiently than competing post-hocmethods, while maintaining comparable predictive performance.",Shahaf Bassan,2025-02-05,2025-02-05,,N/A
2502.03390v1,Interacting dark energy constraints from the full-shape analyses of BOSS DR12 and DES Year 3 measurements,http://arxiv.org/abs/2502.03390v1,"Dark Scattering (DS) is an interacting dark energy model characterised bypure momentum exchange between dark energy and dark matter. It isphenomenologically interesting because it is unconstrained by CMB data and canalleviate the $S_8$ tension. We derive constraints on cosmological and DSparameters using three two-point correlation functions (3$\times$2pt) from theDark Energy Survey third year data release (DES Y3). We then add informationfrom the multipoles of the galaxy power spectrum combined with BaryonicAcoustic Oscillation (BAO) measurements using the twelfth data release of theBaryon Oscillation Spectroscopic Survey (BOSS DR12) and external BAOmeasurements. We compare results from the direct combination of the probes withthe joint posterior distribution calculated with a normalising flow approach.Additionally, we run a CMB analysis with the Planck Public Release 4 (PR4) forcomparison of the cosmological constraints. Overall, we find that thecombination of probes allows minimising the projection effects and improvesconstraints without the need to include CMB information. It brings themarginalised posterior maxima closer to the corresponding best-fit values andweakens the sensitivity to the priors of the spectroscopic modelling nuisanceparameters. These findings are highly relevant in light of forthcoming data ofsurveys like DESI, Euclid, and Rubin.",M. Tsedrik,2025-02-05,2025-02-05,,N/A
2502.03388v1,On the Simulation and Correlation Properties of TWDP Fading Process,http://arxiv.org/abs/2502.03388v1,"This paper introduces a novel statistical simulator designed to modelpropagation in two-way diffuse power (TWDP) fading channels. The simulatoremploys two zero-mean stochastic sinusoids to simulate specular components,while a sum of sinusoids is used to model the diffuse one. Using the developedsimulator, the autocorrelation and cross-correlation functions of thequadrature components, as well as the autocorrelation of the complex andsquared envelope, are derived for the first time in literature for channelsexperiencing TWDP fading. The statistical properties of the proposed simulatorare thoroughly validated through extensive simulations, which closely alignwith the theoretical results.",Almir Maric,2025-02-05,2025-02-05,,N/A
2502.03387v1,LIMO: Less is More for Reasoning,http://arxiv.org/abs/2502.03387v1,"We present a fundamental discovery that challenges our understanding of howcomplex reasoning emerges in large language models. While conventional wisdomsuggests that sophisticated reasoning tasks demand extensive training data(>100,000 examples), we demonstrate that complex mathematical reasoningabilities can be effectively elicited with surprisingly few examples. Throughcomprehensive experiments, our proposed model LIMO demonstrates unprecedentedperformance in mathematical reasoning. With merely 817 curated trainingsamples, LIMO achieves 57.1% accuracy on AIME and 94.8% on MATH, improving fromprevious SFT-based models' 6.5% and 59.2% respectively, while only using 1% ofthe training data required by previous approaches. LIMO demonstratesexceptional out-of-distribution generalization, achieving 40.5% absoluteimprovement across 10 diverse benchmarks, outperforming models trained on 100xmore data, challenging the notion that SFT leads to memorization rather thangeneralization. Based on these results, we propose the Less-Is-More ReasoningHypothesis (LIMO Hypothesis): In foundation models where domain knowledge hasbeen comprehensively encoded during pre-training, sophisticated reasoningcapabilities can emerge through minimal but precisely orchestrateddemonstrations of cognitive processes. This hypothesis posits that theelicitation threshold for complex reasoning is determined by two key factors:(1) the completeness of the model's encoded knowledge foundation duringpre-training, and (2) the effectiveness of post-training examples as ""cognitivetemplates"" that show the model how to utilize its knowledge base to solvecomplex reasoning tasks. To facilitate reproducibility and future research indata-efficient reasoning, we release LIMO as a comprehensive open-source suiteat https://github.com/GAIR-NLP/LIMO.",Yixin Ye,2025-02-05,2025-02-05,,N/A
2502.03386v1,A Structured Reasoning Framework for Unbalanced Data Classification Using Probabilistic Models,http://arxiv.org/abs/2502.03386v1,"This paper studies a Markov network model for unbalanced data, aiming tosolve the problems of classification bias and insufficient minority classrecognition ability of traditional machine learning models in environments withuneven class distribution. By constructing joint probability distribution andconditional dependency, the model can achieve global modeling and reasoningoptimization of sample categories. The study introduced marginal probabilityestimation and weighted loss optimization strategies, combined withregularization constraints and structured reasoning methods, effectivelyimproving the generalization ability and robustness of the model. In theexperimental stage, a real credit card fraud detection dataset was selected andcompared with models such as logistic regression, support vector machine,random forest and XGBoost. The experimental results show that the Markovnetwork performs well in indicators such as weighted accuracy, F1 score, andAUC-ROC, significantly outperforming traditional classification models,demonstrating its strong decision-making ability and applicability inunbalanced data scenarios. Future research can focus on efficient modeltraining, structural optimization, and deep learning integration in large-scaleunbalanced data environments and promote its wide application in practicalapplications such as financial risk control, medical diagnosis, and intelligentmonitoring.",Junliang Du,2025-02-05,2025-02-05,,N/A
2502.03382v1,High-Fidelity Simultaneous Speech-To-Speech Translation,http://arxiv.org/abs/2502.03382v1,"We introduce Hibiki, a decoder-only model for simultaneous speechtranslation. Hibiki leverages a multistream language model to synchronouslyprocess source and target speech, and jointly produces text and audio tokens toperform speech-to-text and speech-to-speech translation. We furthermore addressthe fundamental challenge of simultaneous interpretation, which unlike itsconsecutive counterpart, where one waits for the end of the source utterance tostart translating, adapts its flow to accumulate just enough context to producea correct translation in real-time, chunk by chunk. To do so, we introduce aweakly-supervised method that leverages the perplexity of an off-the-shelf texttranslation system to identify optimal delays on a per-word basis and createaligned synthetic data. After supervised training, Hibiki performs adaptive,simultaneous speech translation with vanilla temperature sampling. On aFrench-English simultaneous speech translation task, Hibiki demonstratesstate-of-the-art performance in translation quality, speaker fidelity andnaturalness. Moreover, the simplicity of its inference process makes itcompatible with batched translation and even real-time on-device deployment. Weprovide examples as well as models and inference code.",Tom Labiausse,2025-02-05,2025-02-05,,N/A
2502.03383v1,Transformers and Their Roles as Time Series Foundation Models,http://arxiv.org/abs/2502.03383v1,"We give a comprehensive analysis of transformers as time series foundationmodels, focusing on their approximation and generalization capabilities. First,we demonstrate that there exist transformers that fit an autoregressive modelon input univariate time series via gradient descent. We then analyze MOIRAI, amultivariate time series foundation model capable of handling an arbitrarynumber of covariates. We prove that it is capable of automatically fittingautoregressive models with an arbitrary number of covariates, offering insightsinto its design and empirical success. For generalization, we establish boundsfor pretraining when the data satisfies Dobrushin's condition. Experimentssupport our theoretical findings, highlighting the efficacy of transformers astime series foundation models.",Dennis Wu,2025-02-05,2025-02-05,,N/A
2502.03381v1,Integrating automatic speech recognition into remote healthcare interpreting: A pilot study of its impact on interpreting quality,http://arxiv.org/abs/2502.03381v1,"This paper reports on the results from a pilot study investigating the impactof automatic speech recognition (ASR) technology on interpreting quality inremote healthcare interpreting settings. Employing a within-subjects experimentdesign with four randomised conditions, this study utilises scripted medicalconsultations to simulate dialogue interpreting tasks. It involves four traineeinterpreters with a language combination of Chinese and English. It alsogathers participants' experience and perceptions of ASR support through cuedretrospective reports and semi-structured interviews. Preliminary data suggestthat the availability of ASR, specifically the access to full ASR transcriptsand to ChatGPT-generated summaries based on ASR, effectively improvedinterpreting quality. Varying types of ASR output had different impacts on thedistribution of interpreting error types. Participants reported similarinteractive experiences with the technology, expressing their preference forfull ASR transcripts. This pilot study shows encouraging results of applyingASR to dialogue-based healthcare interpreting and offers insights into theoptimal ways to present ASR output to enhance interpreter experience andperformance. However, it should be emphasised that the main purpose of thisstudy was to validate the methodology and that further research with a largersample size is necessary to confirm these findings.",Shiyi Tan,2025-02-05,2025-02-05,,N/A
2502.03379v1,Poisson Hypothesis and large-population limit for networks of spiking neurons,http://arxiv.org/abs/2502.03379v1,"We study mean-field descriptions for spatially-extended networks of linear(leaky) and quadratic integrate-and-fire neurons with stochastic spiking times.We consider large-population limits of continuous-time Galves-L\""ocherbach (GL)networks with linear and quadratic intrinsic dynamics. We prove that that thePoisson Hypothesis holds for the replica-mean-field limit of these networks,that is, in a suitably-defined limit, neurons are independent with interactiontimes replaced by independent time-inhomogeneous Poisson processes withintensities depending on the mean firing rates, extending known results tonetworks with quadratic intrinsic dynamics and resets. Proving that the PoissonHypothesis holds opens up the possibility of studying the large-populationlimit in these networks. We prove this limit to be a well-posed neural fieldmodel, subject to stochastic resets.",Daniele Avitabile,2025-02-05,2025-02-05,,N/A
2502.03377v1,Energy-Efficient Flying LoRa Gateways: A Multi-Agent Reinforcement Learning Approach,http://arxiv.org/abs/2502.03377v1,"With the rapid development of next-generation Internet of Things (NG-IoT)networks, the increasing number of connected devices has led to a surge inpower consumption. This rise in energy demand poses significant challenges toresource availability and raises sustainability concerns for large-scale IoTdeployments. Efficient energy utilization in communication networks,particularly for power-constrained IoT devices, has thus become a critical areaof research. In this paper, we deployed flying LoRa gateways (GWs) mounted onunmanned aerial vehicles (UAVs) to collect data from LoRa end devices (EDs) andtransmit it to a central server. Our primary objective is to maximize theglobal system energy efficiency (EE) of wireless LoRa networks by jointoptimization of transmission power (TP), spreading factor (SF), bandwidth (W),and ED association. To solve this challenging problem, we model the problem asa partially observable Markov decision process (POMDP), where each flying LoRaGW acts as a learning agent using a cooperative Multi-Agent ReinforcementLearning (MARL) approach under centralized training and decentralized execution(CTDE). Simulation results demonstrate that our proposed method, based on themulti-agent proximal policy optimization (MAPPO) algorithm, significantlyimproves the global system EE and surpasses the conventional MARL schemes.",Abdullahi Isa Ahmed,2025-02-05,2025-02-05,,N/A
2502.03375v1,Interactive Visualization Recommendation with Hier-SUCB,http://arxiv.org/abs/2502.03375v1,"Visualization recommendation aims to enable rapid visual analysis of massivedatasets. In real-world scenarios, it is essential to quickly gather andcomprehend user preferences to cover users from diverse backgrounds, includingvarying skill levels and analytical tasks. Previous approaches to personalizedvisualization recommendations are non-interactive and rely on initial user datafor new users. As a result, these models cannot effectively explore options oradapt to real-time feedback. To address this limitation, we propose aninteractive personalized visualization recommendation (PVisRec) system thatlearns on user feedback from previous interactions. For more interactive andaccurate recommendations, we propose Hier-SUCB, a contextual combinatorialsemi-bandit in the PVisRec setting. Theoretically, we show an improved overallregret bound with the same rank of time but an improved rank of action space.We further demonstrate the effectiveness of Hier-SUCB through extensiveexperiments where it is comparable to offline methods and outperforms otherbandit algorithms in the setting of visualization recommendation.",Songwen Hu,2025-02-05,2025-02-05,,N/A
2502.03374v1,An explicitly solvable NLS model with discontinuous standing waves,http://arxiv.org/abs/2502.03374v1,"We study the nonlinear Schr\""odinger Equation on the line in the presence ofa point interaction that consists in the superposition of an attractive deltapotential with a dipole interaction. In the energy space it induces adiscontinuity at the origin that breaks the parity symmetry. We treat the$L^2$-subcritical and the $L^2$-critical nonlinearity. For a subcriticalnonlinearity we prove the existence and the uniqueness of the Ground State atany mass, namely the positive minimizer of the associated energy among allfunctions with the same mass. If the mass is larger than an explicit threshold,then there exists another stationary solution, i.e. an excited state, which ispositive too. For the critical nonlinearity we prove that Ground States existonly in a specific interval of masses. Furthermore, one branch of excitedstates exists in a range of masses disjoint from that of the Ground States. Fora dipole interaction, i.e. without the Dirac's delta, all Ground Statesconcentrate at the same value of the mass and all excited states concentrate atanother value of the mass. Both masses depend on the strength of the dipoleinteractions. Furthermore, we provide the value of the optimal constant in theGagliardo-Nirenberg estimate and describe in detail the bifurcation from theunperturbed soliton that gives rise to both branches of stationary states,providing the motivation for the values of the mass that characterize the twobranches, in the limit of a dipole interaction of infinite strength. Since allstationary states are explicitly computed, ours is a solvable model involving anon-standard interplay of a nonlinearity with a point interaction, in the sensethat is richer than in the well-known model of a delta interaction with anonlinearity.",Riccardo Adami,2025-02-05,2025-02-05,,N/A
2502.03373v1,Demystifying Long Chain-of-Thought Reasoning in LLMs,http://arxiv.org/abs/2502.03373v1,"Scaling inference compute enhances reasoning in large language models (LLMs),with long chains-of-thought (CoTs) enabling strategies like backtracking anderror correction. Reinforcement learning (RL) has emerged as a crucial methodfor developing these capabilities, yet the conditions under which long CoTsemerge remain unclear, and RL training requires careful design choices. In thisstudy, we systematically investigate the mechanics of long CoT reasoning,identifying the key factors that enable models to generate long CoTtrajectories. Through extensive supervised fine-tuning (SFT) and RLexperiments, we present four main findings: (1) While SFT is not strictlynecessary, it simplifies training and improves efficiency; (2) Reasoningcapabilities tend to emerge with increased training compute, but theirdevelopment is not guaranteed, making reward shaping crucial for stabilizingCoT length growth; (3) Scaling verifiable reward signals is critical for RL. Wefind that leveraging noisy, web-extracted solutions with filtering mechanismsshows strong potential, particularly for out-of-distribution (OOD) tasks suchas STEM reasoning; and (4) Core abilities like error correction are inherentlypresent in base models, but incentivizing these skills effectively for complextasks via RL demands significant compute, and measuring their emergencerequires a nuanced approach. These insights provide practical guidance foroptimizing training strategies to enhance long CoT reasoning in LLMs. Our codeis available at: https://github.com/eddycmu/demystify-long-cot.",Edward Yeo,2025-02-05,2025-02-05,,N/A
2502.03372v1,Time scale competition in the Active Coagulation Model,http://arxiv.org/abs/2502.03372v1,"Spreading processes on top of active dynamics provide a novel theoreticalframework for capturing emerging collective behavior in living systems. Iconsider run-and-tumble dynamics coupled with coagulation/decoagulationreactions that lead to an absorbing state phase transition. While the activedynamics does not change the location of the transition point, the relaxationtoward the stationary state depends on motility parameters. Because of thecompetition between spreading dynamics and active motion, the system cansupport long-living currents whose typical time scale is a nontrivial functionof motility and reaction rates. Beyond the mean-field regime, instability atfinite length scales regulates a crossover from periodic to diffusive modes.Finally, it is possible to individuate different mechanisms of patternformation on a large time scale, ranging from Fisher-Kolmogorov toKardar-Parisi-Zhang equation.",Matteo Paoluzzi,2025-02-05,2025-02-05,,N/A
2502.03370v1,Deep Learning-Based Approach for Identification of Potato Leaf Diseases Using Wrapper Feature Selection and Feature Concatenation,http://arxiv.org/abs/2502.03370v1,"The potato is a widely grown crop in many regions of the world. In recentdecades, potato farming has gained incredible traction in the world. Potatoesare susceptible to several illnesses that stunt their development. This plantseems to have significant leaf disease. Early Blight and Late Blight are twoprevalent leaf diseases that affect potato plants. The early detection of thesediseases would be beneficial for enhancing the yield of this crop. The idealsolution is to use image processing to identify and analyze these disorders.Here, we present an autonomous method based on image processing and machinelearning to detect late blight disease affecting potato leaves. The proposedmethod comprises four different phases: (1) Histogram Equalization is used toimprove the quality of the input image; (2) feature extraction is performedusing a Deep CNN model, then these extracted features are concatenated; (3)feature selection is performed using wrapper-based feature selection; (4)classification is performed using an SVM classifier and its variants. Thisproposed method achieves the highest accuracy of 99% using SVM by selecting 550features.",Muhammad Ahtsam Naeem,2025-02-05,2025-02-05,,N/A
