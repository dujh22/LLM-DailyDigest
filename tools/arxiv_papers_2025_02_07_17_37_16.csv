Paper ID,Title,URL,Summary,First Author,Publish Date,Update Date,Code URL,Stars,Categories
2502.04330v1,"Geometrical frustration, power law tunneling and non-local gauge fields from scattered light",http://arxiv.org/abs/2502.04330v1,"Designing the amplitude and range of couplings in quantum systems is afundamental tool for exploring a large variety of quantum mechanical effects.Here, we consider off-resonant photon scattering processes on a geometricallyshaped molecular cloud. Our analysis shows that such a setup is properlymodeled by a Bose-Hubbard Hamiltonian where the range, amplitude and sign ofthe tunneling processes of the scattered photonic modes can be accuratelytuned. Specifically, by varying the molecular distribution, we demonstrate thatdifferent configurations characterized by geometrical frustration, long-rangepower law hopping processes, and non-local gauge fields can be achieved. Ourresults thus represent a powerful and alternative approach to perform anaccurate Hamiltonian engineering of quantum systems with non trivial couplingstructures.",Pavel P. Popov,2025-02-06,2025-02-06,,N/A,"['quant-ph', 'cond-mat.quant-gas']"
2502.04329v1,SMART: Advancing Scalable Map Priors for Driving Topology Reasoning,http://arxiv.org/abs/2502.04329v1,"Topology reasoning is crucial for autonomous driving as it enablescomprehensive understanding of connectivity and relationships between lanes andtraffic elements. While recent approaches have shown success in perceivingdriving topology using vehicle-mounted sensors, their scalability is hinderedby the reliance on training data captured by consistent sensor configurations.We identify that the key factor in scalable lane perception and topologyreasoning is the elimination of this sensor-dependent feature. To address this,we propose SMART, a scalable solution that leverages easily availablestandard-definition (SD) and satellite maps to learn a map prior model,supervised by large-scale geo-referenced high-definition (HD) maps independentof sensor settings. Attributed to scaled training, SMART alone achievessuperior offline lane topology understanding using only SD and satelliteinputs. Extensive experiments further demonstrate that SMART can be seamlesslyintegrated into any online topology reasoning methods, yielding significantimprovements of up to 28% on the OpenLane-V2 benchmark.",Junjie Ye,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.RO']"
2502.04328v1,Ola: Pushing the Frontiers of Omni-Modal Language Model with Progressive Modality Alignment,http://arxiv.org/abs/2502.04328v1,"Recent advances in large language models, particularly following GPT-4o, havesparked increasing interest in developing omni-modal models capable ofunderstanding more modalities. While some open-source alternatives haveemerged, there is still a notable lag behind specialized single-modality modelsin performance. In this paper, we present Ola, an Omni-modal language modelthat achieves competitive performance across image, video, and audiounderstanding compared to specialized counterparts. The core design of Ola liesin its progressive modality alignment strategy that extends the supportingmodality of the language model progressively. Our training pipeline begins withthe most distinct modalities: image and text, then gradually expands the skillsets of the model using speech data that connects language and audio knowledge,and video data that connects all modalities. The progressive learning pipelinealso enables us to maintain a relatively small size of the cross-modalalignment data, making developing omni-modal from existing vision-languagemodels easy and less costly. Moreover, to unlock an advanced interactiveexperience like GPT-4o, we further design a sentence-wise decoding solution forstreaming speech generation. Extensive experiments demonstrate that Olasurpasses existing open omni-modal LLMs across all modalities while achievinghighly competitive performance compared to state-of-the-art specialized modelsof similar sizes. We aim to make Ola a fully open omni-modal understandingsolution to advance future research in this emerging field. Model weights,code, and data are open-sourced at https://github.com/Ola-Omni/Ola.",Zuyan Liu,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.CL', 'cs.MM', 'cs.SD', 'eess.AS', 'eess.IV']"
2502.04327v1,Value-Based Deep RL Scales Predictably,http://arxiv.org/abs/2502.04327v1,"Scaling data and compute is critical to the success of machine learning.However, scaling demands predictability: we want methods to not only performwell with more compute or data, but also have their performance be predictablefrom small-scale runs, without running the large-scale experiment. In thispaper, we show that value-based off-policy RL methods are predictable despitecommunity lore regarding their pathological behavior. First, we show that dataand compute requirements to attain a given performance level lie on a Paretofrontier, controlled by the updates-to-data (UTD) ratio. By estimating thisfrontier, we can predict this data requirement when given more compute, andthis compute requirement when given more data. Second, we determine the optimalallocation of a total resource budget across data and compute for a givenperformance and use it to determine hyperparameters that maximize performancefor a given budget. Third, this scaling behavior is enabled by first estimatingpredictable relationships between hyperparameters, which is used to manageeffects of overfitting and plasticity loss unique to RL. We validate ourapproach using three algorithms: SAC, BRO, and PQL on DeepMind Control, OpenAIgym, and IsaacGym, when extrapolating to higher levels of data, compute,budget, or performance.",Oleh Rybkin,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04326v1,WorldSense: Evaluating Real-world Omnimodal Understanding for Multimodal LLMs,http://arxiv.org/abs/2502.04326v1,"In this paper, we introduce WorldSense, the first benchmark to assess themulti-modal video understanding, that simultaneously encompasses visual, audio,and text inputs. In contrast to existing benchmarks, our WorldSense has severalfeatures: (i) collaboration of omni-modality, we design the evaluation tasks tofeature a strong coupling of audio and video, requiring models to effectivelyutilize the synergistic perception of omni-modality; (ii) diversity of videosand tasks, WorldSense encompasses a diverse collection of 1,662 audio-visualsynchronised videos, systematically categorized into 8 primary domains and 67fine-grained subcategories to cover the broad scenarios, and 3,172 multi-choiceQA pairs across 26 distinct tasks to enable the comprehensive evaluation; (iii)high-quality annotations, all the QA pairs are manually labeled by 80 expertannotators with multiple rounds of correction to ensure quality. Based on ourWorldSense, we extensively evaluate various state-of-the-art models. Theexperimental results indicate that existing models face significant challengesin understanding real-world scenarios (48.0% best accuracy). We hope ourWorldSense can provide a platform for evaluating the ability in constructingand understanding coherent contexts from omni-modality.",Jack Hong,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.AI']"
2502.04324v1,Can Grammarly and ChatGPT accelerate language change? AI-powered technologies and their impact on the English language: wordiness vs. conciseness,http://arxiv.org/abs/2502.04324v1,"The proliferation of NLP-powered language technologies, AI-based naturallanguage generation models, and English as a mainstream means of communicationamong both native and non-native speakers make the output of AI-powered toolsespecially intriguing to linguists. This paper investigates how Grammarly andChatGPT affect the English language regarding wordiness vs. conciseness. A casestudy focusing on the purpose subordinator in order to is presented toillustrate the way in which Grammarly and ChatGPT recommend shorter grammaticalstructures instead of longer and more elaborate ones. Although the analysedsentences were produced by native speakers, are perfectly correct, and wereextracted from a language corpus of contemporary English, both Grammarly andChatGPT suggest more conciseness and less verbosity, even for relatively shortsentences. The present article argues that technologies such as Grammarly notonly mirror language change but also have the potential to facilitate oraccelerate it.",Karolina Rudnicka,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.CY']"
2502.04323v1,The Uniformly Rotated Mondrian Kernel,http://arxiv.org/abs/2502.04323v1,"First proposed by Rahimi and Recht, random features are used to decrease thecomputational cost of kernel machines in large-scale problems. The Mondriankernel is one such example of a fast random feature approximation of theLaplace kernel, generated by a computationally efficient hierarchical randompartition of the input space known as the Mondrian process. In this work, westudy a variation of this random feature map by using uniformly randomlyrotated Mondrian processes to approximate a kernel that is invariant underrotations. We obtain a closed-form expression for this isotropic kernel, aswell as a uniform convergence rate of the uniformly rotated Mondrian kernel tothis limit. To this end, we utilize techniques from the theory of stationaryrandom tessellations in stochastic geometry and prove a new result on thegeometry of the typical cell of the superposition of uniformly random rotationsof Mondrian tessellations. Finally, we test the empirical performance of thisrandom feature map on both synthetic and real-world datasets, demonstrating itsimproved performance over the Mondrian kernel on a debiased dataset.",Calvin Osborne,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'math.PR']"
2502.04321v1,Variation of sentence length across time and genre,http://arxiv.org/abs/2502.04321v1,"The goal of this paper is threefold: i) to present some practical aspects ofusing full-text version of Corpus of Historical American English (COHA), thelargest diachronic multi-genre corpus of the English language, in theinvestigation of a linguistic trend of change; ii) to test a widely heldassumption that sentence length in written English has been steadily decreasingover the past few centuries; iii) to point to a possible link between thechanges in sentence length and changes in the English syntactic usage. Theempirical proof of concept for iii) is provided by the decline in the frequencyof the non-finite purpose subordinator in order to. Sentence length, genre andthe likelihood of occurrence of in order to are shown to be interrelated.",Karolina Rudnicka,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04322v1,Speak Easy: Eliciting Harmful Jailbreaks from LLMs with Simple Interactions,http://arxiv.org/abs/2502.04322v1,"Despite extensive safety alignment efforts, large language models (LLMs)remain vulnerable to jailbreak attacks that elicit harmful behavior. Whileexisting studies predominantly focus on attack methods that require technicalexpertise, two critical questions remain underexplored: (1) Are jailbrokenresponses truly useful in enabling average users to carry out harmful actions?(2) Do safety vulnerabilities exist in more common, simple human-LLMinteractions? In this paper, we demonstrate that LLM responses most effectivelyfacilitate harmful actions when they are both actionable and informative--twoattributes easily elicited in multi-step, multilingual interactions. Using thisinsight, we propose HarmScore, a jailbreak metric that measures how effectivelyan LLM response enables harmful actions, and Speak Easy, a simple multi-step,multilingual attack framework. Notably, by incorporating Speak Easy into directrequest and jailbreak baselines, we see an average absolute increase of 0.319in Attack Success Rate and 0.426 in HarmScore in both open-source andproprietary LLMs across four safety benchmarks. Our work reveals a critical yetoften overlooked vulnerability: Malicious users can easily exploit commoninteraction patterns for harmful intentions.",Yik Siu Chan,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI', 'cs.CL', 'cs.CY']"
2502.04320v1,ConceptAttention: Diffusion Transformers Learn Highly Interpretable Features,http://arxiv.org/abs/2502.04320v1,"Do the rich representations of multi-modal diffusion transformers (DiTs)exhibit unique properties that enhance their interpretability? We introduceConceptAttention, a novel method that leverages the expressive power of DiTattention layers to generate high-quality saliency maps that precisely locatetextual concepts within images. Without requiring additional training,ConceptAttention repurposes the parameters of DiT attention layers to producehighly contextualized concept embeddings, contributing the major discovery thatperforming linear projections in the output space of DiT attention layersyields significantly sharper saliency maps compared to commonly usedcross-attention mechanisms. Remarkably, ConceptAttention even achievesstate-of-the-art performance on zero-shot image segmentation benchmarks,outperforming 11 other zero-shot interpretability methods on theImageNet-Segmentation dataset and on a single-class subset of PascalVOC. Ourwork contributes the first evidence that the representations of multi-modal DiTmodels like Flux are highly transferable to vision tasks like segmentation,even outperforming multi-modal foundation models like CLIP.",Alec Helbling,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.LG']"
2502.04319v1,On the origin of the $Σ_1$-$M_\star$ quenching boundary,http://arxiv.org/abs/2502.04319v1,"We have considered a phenomenologically motivated model in which galaxies arequenched when the energy output of the central black hole exceeds a hundredtimes the gravitational binding energy of the baryons in the host halo. Themodel reproduces the mass functions of star-forming and quiescent galaxies at0<z<2.5 and the quenching boundary on a $\Sigma_1$-stellar mass diagram. Thequenching boundary arises because of the colour-morphology relation. Thestellar surface density $\Sigma_1$ in the central kiloparsec is a morphologicalindicator. Galaxies becomes redder as $\Sigma_1$ increases until they cross thequenching boundary and enter the passive population. Mergers drive the growthof supermassive black holes and the morphological evolution that accompany themigration to the red sequence. That is the origin of the population ofhigh-mass passive galaxies. At lower masses, passive galaxies are mainlysatellites that ceased to form stars because of environmental effects.",Andrea Cattaneo,2025-02-06,2025-02-06,,N/A,['astro-ph.GA']
2502.04318v1,sshELF: Single-Shot Hierarchical Extrapolation of Latent Features for 3D Reconstruction from Sparse-Views,http://arxiv.org/abs/2502.04318v1,"Reconstructing unbounded outdoor scenes from sparse outward-facing viewsposes significant challenges due to minimal view overlap. Previous methodsoften lack cross-scene understanding and their primitive-centric formulationsoverload local features to compensate for missing global context, resulting inblurriness in unseen parts of the scene. We propose sshELF, a fast, single-shotpipeline for sparse-view 3D scene reconstruction via hierarchal extrapolationof latent features. Our key insights is that disentangling informationextrapolation from primitive decoding allows efficient transfer of structuralpatterns across training scenes. Our method: (1) learns cross-scene priors togenerate intermediate virtual views to extrapolate to unobserved regions, (2)offers a two-stage network design separating virtual view generation from 3Dprimitive decoding for efficient training and modular model design, and (3)integrates a pre-trained foundation model for joint inference of latentfeatures and texture, improving scene understanding and generalization. sshELFcan reconstruct 360 degree scenes from six sparse input views and achievescompetitive results on synthetic and real-world datasets. We find that sshELFfaithfully reconstructs occluded regions, supports real-time rendering, andprovides rich latent features for downstream applications. The code will bereleased.",Eyvaz Najafli,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04317v1,Factorized Implicit Global Convolution for Automotive Computational Fluid Dynamics Prediction,http://arxiv.org/abs/2502.04317v1,"Computational Fluid Dynamics (CFD) is crucial for automotive design,requiring the analysis of large 3D point clouds to study how vehicle geometryaffects pressure fields and drag forces. However, existing deep learningapproaches for CFD struggle with the computational complexity of processinghigh-resolution 3D data. We propose Factorized Implicit Global Convolution(FIGConv), a novel architecture that efficiently solves CFD problems for verylarge 3D meshes with arbitrary input and output geometries. FIGConv achievesquadratic complexity $O(N^2)$, a significant improvement over existing 3Dneural CFD models that require cubic complexity $O(N^3)$. Our approach combinesFactorized Implicit Grids to approximate high-resolution domains, efficientglobal convolutions through 2D reparameterization, and a U-shaped architecturefor effective information gathering and integration. We validate our approachon the industry-standard Ahmed body dataset and the large-scale DrivAerNetdataset. In DrivAerNet, our model achieves an $R^2$ value of 0.95 for dragprediction, outperforming the previous state-of-the-art by a significantmargin. This represents a 40% improvement in relative mean squared error and a70% improvement in absolute mean squared error over previous methods.",Chris Choy,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04316v1,Shape-asymmetry and flexibility in active cross-stream migration in nonuniform shear,http://arxiv.org/abs/2502.04316v1,"We show that the interplay of activity and broken fore-aft symmetry of shapeshelps microswimmers to migrate across streamlines in nonuniform shear,emphasizing a hitherto overlooked fundamental cause of active cross-streammigration in imposed flows. Using a framework on model flagellatedmicroswimmers in a microchannel flow, we find that besides the broken head-tailshape symmetry, extended hydrodynamic coupling is vital for cross-streammigration, whereas flagellar flexibility significantly affects the same.Furthermore, by simplifying the problem to a basic analytical model, we areable to identify the fundamental factors affecting the observed rich nonlineardynamics and predict the sorting and control of microswimmer populations insidea microchannel. Our predictions are general and apply to both living andartificial microswimmers, whereas the hydrodynamic framework developed here isnecessary to probe other scenarios, such as in dense suspensions, wherenon-uniform shear and near-field flows become important.",Derek C. Gomes,2025-02-06,2025-02-06,,N/A,"['cond-mat.soft', 'physics.bio-ph']"
2502.04315v1,ChamaleonLLM: Batch-Aware Dynamic Low-Rank Adaptation via Inference-Time Clusters,http://arxiv.org/abs/2502.04315v1,"Recent advances in large language models (LLMs) have shown remarkableperformance across diverse tasks. However, these models are typically deployedwith fixed weights, which limits their ability to adapt dynamically to thevariability inherent in real-world data during inference. This paper introducesChamaleonLLM, a novel framework that enables inference-time adaptation of LLMsby leveraging batch-aware clustering and on-the-fly generation of low-rankupdates. Unlike traditional fine-tuning approaches such as Low-Rank Adaptation(LoRA) or methods that rely on a fixed set of pre-learned uniforms (changeablemasks), our method dynamically generates adaptive modifications to the decoderweights based on the aggregated statistics of clustered batches. Byintelligently grouping similar inputs and computing context-aware low-rankupdates via a hyper-network, ChamaleonLLM achieves significant performancegains, outperforming conventional LoRA methods while eliminating the overheadof maintaining multiple expert models. Our experiments highlight the potentialof our approach to serve as a versatile and highly adaptive solution forlanguage model inference. ChamaleonLLM is open-sourced to ensure thereproducibility of our experiments:https://anonymous.4open.science/r/ChamaleonLLM/",Kamer Ali Yuksel,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI', 'cs.LG']"
2502.04314v1,"BOUQuET: dataset, Benchmark and Open initiative for Universal Quality Evaluation in Translation",http://arxiv.org/abs/2502.04314v1,"This paper presents BOUQuET, a multicentric and multi-register/domain datasetand benchmark, and its broader collaborative extension initiative. This datasetis handcrafted in non-English languages first, each of these source languagesbeing represented among the 23 languages commonly used by half of the world'spopulation and therefore having the potential to serve as pivot languages thatwill enable more accurate translations. The dataset is specially designed toavoid contamination and be multicentric, so as to enforce representation ofmultilingual language features. In addition, the dataset goes beyond thesentence level, as it is organized in paragraphs of various lengths. Comparedwith related machine translation (MT) datasets, we show that BOUQuET has abroader representation of domains while simplifying the translation task fornon-experts. Therefore, BOUQuET is specially suitable for the open initiativeand call for translation participation that we are launching to extend it to amulti-way parallel corpus to any written language.",The Omnilingual MT Team,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'I.2.7']"
2502.04313v1,Great Models Think Alike and this Undermines AI Oversight,http://arxiv.org/abs/2502.04313v1,"As Language Model (LM) capabilities advance, evaluating and supervising themat scale is getting harder for humans. There is hope that other language modelscan automate both these tasks, which we refer to as ""AI Oversight"". We studyhow model similarity affects both aspects of AI oversight by proposing aprobabilistic metric for LM similarity based on overlap in model mistakes.Using this metric, we first show that LLM-as-a-judge scores favor modelssimilar to the judge, generalizing recent self-preference results. Then, westudy training on LM annotations, and find complementary knowledge between theweak supervisor and strong student model plays a crucial role in gains from""weak-to-strong generalization"". As model capabilities increase, it becomesharder to find their mistakes, and we might defer more to AI oversight.However, we observe a concerning trend -- model mistakes are becoming moresimilar with increasing capabilities, pointing to risks from correlatedfailures. Our work underscores the importance of reporting and correcting formodel similarity, especially in the emerging paradigm of AI oversight.",Shashwat Goel,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI', 'cs.CL']"
2502.04312v1,Consistency of augmentation graph and network approximability in contrastive learning,http://arxiv.org/abs/2502.04312v1,"Contrastive learning leverages data augmentation to develop featurerepresentation without relying on large labeled datasets. However, despite itsempirical success, the theoretical foundations of contrastive learning remainincomplete, with many essential guarantees left unaddressed, particularly therealizability assumption concerning neural approximability of an optimalspectral contrastive loss solution. In this work, we overcome these limitationsby analyzing the pointwise and spectral consistency of the augmentation graphLaplacian. We establish that, under specific conditions for data generation andgraph connectivity, as the augmented dataset size increases, the augmentationgraph Laplacian converges to a weighted Laplace-Beltrami operator on thenatural data manifold. These consistency results ensure that the graphLaplacian spectrum effectively captures the manifold geometry. Consequently,they give way to a robust framework for establishing neural approximability,directly resolving the realizability assumption in a current paradigm.",Chenghui Li,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'math.AP', 'math.SP']"
2502.04309v1,Targeted Learning for Data Fairness,http://arxiv.org/abs/2502.04309v1,"Data and algorithms have the potential to produce and perpetuatediscrimination and disparate treatment. As such, significant effort has beeninvested in developing approaches to defining, detecting, and eliminatingunfair outcomes in algorithms. In this paper, we focus on performingstatistical inference for fairness. Prior work in fairness inference haslargely focused on inferring the fairness properties of a given predictivealgorithm. Here, we expand fairness inference by evaluating fairness in thedata generating process itself, referred to here as data fairness. We performinference on data fairness using targeted learning, a flexible framework fornonparametric inference. We derive estimators demographic parity, equalopportunity, and conditional mutual information. Additionally, we find that ourestimators for probabilistic metrics exploit double robustness. To validate ourapproach, we perform several simulations and apply our estimators to real data.",Alexander Asemota,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'stat.ML']"
2502.04308v1,HOG-Diff: Higher-Order Guided Diffusion for Graph Generation,http://arxiv.org/abs/2502.04308v1,"Graph generation is a critical yet challenging task as empirical analysesrequire a deep understanding of complex, non-Euclidean structures. Althoughdiffusion models have recently made significant achievements in graphgeneration, these models typically adapt from the frameworks designed for imagegeneration, making them ill-suited for capturing the topological properties ofgraphs. In this work, we propose a novel Higher-order Guided Diffusion(HOG-Diff) model that follows a coarse-to-fine generation curriculum and isguided by higher-order information, enabling the progressive generation ofplausible graphs with inherent topological structures. We further prove thatour model exhibits a stronger theoretical guarantee than classical diffusionframeworks. Extensive experiments on both molecular and generic graphgeneration tasks demonstrate that our method consistently outperforms orremains competitive with state-of-the-art baselines. Our code is available athttps://github.com/Yiminghh/HOG-Diff.",Yiming Huang,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI', 'cs.SI', 'physics.soc-ph']"
2502.04307v1,DexterityGen: Foundation Controller for Unprecedented Dexterity,http://arxiv.org/abs/2502.04307v1,"Teaching robots dexterous manipulation skills, such as tool use, presents asignificant challenge. Current approaches can be broadly categorized into twostrategies: human teleoperation (for imitation learning) and sim-to-realreinforcement learning. The first approach is difficult as it is hard forhumans to produce safe and dexterous motions on a different embodiment withouttouch feedback. The second RL-based approach struggles with the domain gap andinvolves highly task-specific reward engineering on complex tasks. Our keyinsight is that RL is effective at learning low-level motion primitives, whilehumans excel at providing coarse motion commands for complex, long-horizontasks. Therefore, the optimal solution might be a combination of bothapproaches. In this paper, we introduce DexterityGen (DexGen), which uses RL topretrain large-scale dexterous motion primitives, such as in-hand rotation ortranslation. We then leverage this learned dataset to train a dexterousfoundational controller. In the real world, we use human teleoperation as aprompt to the controller to produce highly dexterous behavior. We evaluate theeffectiveness of DexGen in both simulation and real world, demonstrating thatit is a general-purpose controller that can realize input dexterousmanipulation commands and significantly improves stability by 10-100x measuredas duration of holding objects across diverse tasks. Notably, with DexGen wedemonstrate unprecedented dexterous skills including diverse objectreorientation and dexterous tool use such as pen, syringe, and screwdriver forthe first time.",Zhao-Heng Yin,2025-02-06,2025-02-06,,N/A,"['cs.RO', 'cs.AI', 'cs.LG', 'cs.SY', 'eess.SY']"
2502.04306v1,ScoreFlow: Mastering LLM Agent Workflows via Score-based Preference Optimization,http://arxiv.org/abs/2502.04306v1,"Recent research has leveraged large language model multi-agent systems forcomplex problem-solving while trying to reduce the manual effort required tobuild them, driving the development of automated agent workflow optimizationmethods. However, existing methods remain inflexible due to representationallimitations, a lack of adaptability, and poor scalability when relying ondiscrete optimization techniques. We address these challenges with ScoreFlow, asimple yet high-performance framework that leverages efficient gradient-basedoptimization in a continuous space. ScoreFlow incorporates Score-DPO, a novelvariant of the direct preference optimization method that accounts forquantitative feedback. Across six benchmarks spanning question answering,coding, and mathematical reasoning, ScoreFlow achieves an 8.2% improvement overexisting baselines. Moreover, it empowers smaller models to outperform largerones with lower inference costs. Project:https://github.com/Gen-Verse/ScoreFlow",Yinjie Wang,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04304v1,Almost toric fibrations on K3 surfaces,http://arxiv.org/abs/2502.04304v1,"For K\""ahler K3 surfaces we consider Kulikov models of type III tamed by asymplectic form. Our main result shows that the generic smooth fiber admits analmost toric fibration over the intersection complex, which inherits a naturalnodal integral affine structure from almost toric fibrations of the boundarydivisors. We prove that a smooth anti-canonical hypersurface in a smooth toricFano threefold, equipped with a toric K\""ahler form, admits a symplecticKulikov model. Moreover, we demonstrate that the induced integral affinestructure on the intersection complex is integral affine isomorphic (up tonodal slides) nodal integral affine structure considered by Gross and Sieberton the boundary of the moment polytope.",Pranav Chakravarthy,2025-02-06,2025-02-06,,N/A,"['math.SG', 'Primary 14H70, Secondary 14J28, 14J32, 14D06']"
2502.04302v1,Strong Equivalence in Answer Set Programming with Constraints,http://arxiv.org/abs/2502.04302v1,"We investigate the concept of strong equivalence within the extendedframework of Answer Set Programming with constraints. Two groups of rules areconsidered strongly equivalent if, informally speaking, they have the samemeaning in any context. We demonstrate that, under certain assumptions, strongequivalence between rule sets in this extended setting can be preciselycharacterized by their equivalence in the logic of Here-and-There withconstraints. Furthermore, we present a translation from the language of severalclingo-based answer set solvers that handle constraints into the language ofHere-and-There with constraints. This translation enables us to leverage thelogic of Here-and-There to reason about strong equivalence within the contextof these solvers. We also explore the computational complexity of determiningstrong equivalence in this context.",Pedro Cabalar,2025-02-06,2025-02-06,,N/A,"['cs.AI', 'cs.LO', 'I.2.4; I.2.8']"
2502.04301v1,Type II Degenerations of K3 Surfaces of Degree 4,http://arxiv.org/abs/2502.04301v1,We study Type II degenerations of K3 surfaces of degree 4 where the centralfiber consists of two rational components glued along an elliptic curve. Suchdegenerations are called Tyurin degenerations. We construct explicit Tyurindegenerations corresponding to each of the 1-dimensional boundary components ofthe Baily-Borel compactification of the moduli space of K3 surfaces of degree4. For every such boundary component we also construct an 18-dimensional familyof Tyurin degenerations of K3 surfaces of degree 4 and compute the stablemodels of these degenerations.,James Matthew Jones,2025-02-06,2025-02-06,,N/A,"['math.AG', '14D06, 14J10, 14J26, 14J28']"
2502.04300v1,CMB-S4: Foreground-Cleaning Pipeline Comparison for Measuring Primordial Gravitational Waves,http://arxiv.org/abs/2502.04300v1,"We compare multiple foreground-cleaning pipelines for estimating thetensor-to-scalar ratio, $r$, using simulated maps of the planned CMB-S4experiment within the context of the South Pole Deep Patch. To evaluaterobustness, we analyze bias and uncertainty on $r$ across various foregroundsuites using map-based simulations. The foreground-cleaning methods include: aparametric maximum likelihood approach applied to auto- and cross-power spectrabetween frequency maps; a map-based parametric maximum-likelihood method; and aharmonic-space internal linear combination using frequency maps. We summarizethe conceptual basis of each method to highlight their similarities anddifferences. To better probe the impact of foreground residuals, we implementan iterative internal delensing step, leveraging a map-based pipeline togenerate a lensing $B$-mode template from the Large Aperture Telescopefrequency maps. Our results show that the performance of the three approachesis comparable for simple and intermediate-complexity foregrounds, with$\sigma(r)$ ranging from 3 to 5 $\times 10^{-4}$. However, biases at the$1-2\sigma$ level appear when analyzing more complex forms of foregroundemission. By extending the baseline pipelines to marginalize over foregroundresiduals, we demonstrate that contamination can be reduced to withinstatistical uncertainties, albeit with a pipeline-dependent impact on$\sigma(r)$, which translates to a detection significance between 2 and4$\sigma$ for an input value of $r = 0.003$. These findings suggest varyinglevels of maturity among the tested pipelines, with the auto- andcross-spectra-based approach demonstrating the best stability and overallperformance. Moreover, given the extremely low noise levels, mutual validationof independent foreground-cleaning pipelines is essential to ensure therobustness of any potential detection.",Federico Bianchini,2025-02-06,2025-02-06,,N/A,['astro-ph.CO']
2502.04299v1,MotionCanvas: Cinematic Shot Design with Controllable Image-to-Video Generation,http://arxiv.org/abs/2502.04299v1,"This paper presents a method that allows users to design cinematic videoshots in the context of image-to-video generation. Shot design, a criticalaspect of filmmaking, involves meticulously planning both camera movements andobject motions in a scene. However, enabling intuitive shot design in modernimage-to-video generation systems presents two main challenges: first,effectively capturing user intentions on the motion design, where both cameramovements and scene-space object motions must be specified jointly; and second,representing motion information that can be effectively utilized by a videodiffusion model to synthesize the image animations. To address thesechallenges, we introduce MotionCanvas, a method that integrates user-drivencontrols into image-to-video (I2V) generation models, allowing users to controlboth object and camera motions in a scene-aware manner. By connecting insightsfrom classical computer graphics and contemporary video generation techniques,we demonstrate the ability to achieve 3D-aware motion control in I2V synthesiswithout requiring costly 3D-related training data. MotionCanvas enables usersto intuitively depict scene-space motion intentions, and translates them intospatiotemporal motion-conditioning signals for video diffusion models. Wedemonstrate the effectiveness of our method on a wide range of real-world imagecontent and shot-design scenarios, highlighting its potential to enhance thecreative workflows in digital content creation and adapt to various image andvideo editing applications.",Jinbo Xing,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04298v1,Mutual Multilinearity of Nonequilibrium Network Currents,http://arxiv.org/abs/2502.04298v1,"Continuous-time Markov chains have been successful in modelling systemsacross numerous fields, with currents being fundamental entities that describethe flows of energy, particles, individuals, chemical species, information, orother quantities. They apply to systems described by agents transitioningbetween vertices along the edges of a network (at some rate in each direction).It has recently been shown by the authors that, at stationarity, a hiddenlinearity exists between currents that flow along edges: if one controls thecurrent of a specific ""input"" edge (by tuning transition rates along it), anyother current is a linear-affine function of the input current [PRL 133, 047401(2024)]. In this paper, we extend this result to the situation where onecontrols the currents of several edges, and prove that other currents are inlinear-affine relation with the input ones. Two proofs with distinct insightsare provided: the first relies on Kirchhoff's current law and reduces the inputset inductively through graph analysis, while the second utilizes the resolventapproach via a Laplace transform in time. We obtain explicit expressions forthe current-to-current susceptibilities, which allow one to map currentdependencies through the network. We also verify from our expression thatKirchhoff's current law is recovered as a limiting case of our mutuallinearity. Last, we uncover that susceptibilities can be obtained fromfluctuations when the reference system is originally at equilibrium.",Sara Dal Cengio,2025-02-06,2025-02-06,,N/A,"['cond-mat.stat-mech', 'math-ph', 'math.MP']"
2502.04296v1,Learning Real-World Action-Video Dynamics with Heterogeneous Masked Autoregression,http://arxiv.org/abs/2502.04296v1,"We propose Heterogeneous Masked Autoregression (HMA) for modelingaction-video dynamics to generate high-quality data and evaluation in scalingrobot learning. Building interactive video world models and policies forrobotics is difficult due to the challenge of handling diverse settings whilemaintaining computational efficiency to run in real time. HMA usesheterogeneous pre-training from observations and action sequences acrossdifferent robotic embodiments, domains, and tasks. HMA uses maskedautoregression to generate quantized or soft tokens for video predictions.\ourshort achieves better visual fidelity and controllability than the previousrobotic video generation models with 15 times faster speed in the real world.After post-training, this model can be used as a video simulator from low-levelaction inputs for evaluating policies and generating synthetic data. See thislink https://liruiw.github.io/hma for more information.",Lirui Wang,2025-02-06,2025-02-06,,N/A,"['cs.RO', 'cs.CV', 'cs.LG']"
2502.04295v1,Beyond Prompt Content: Enhancing LLM Performance via Content-Format Integrated Prompt Optimization,http://arxiv.org/abs/2502.04295v1,"Large Language Models (LLMs) have shown significant capability across varioustasks, with their real-world effectiveness often driven by prompt design. Whilerecent research has focused on optimizing prompt content, the role of promptformatting, a critical but often overlooked dimension, has received limitedsystematic investigation. In this paper, we introduce Content-Format IntegratedPrompt Optimization (CFPO), an innovative methodology that jointly optimizesboth prompt content and formatting through an iterative refinement process.CFPO leverages natural language mutations to explore content variations andemploys a dynamic format exploration strategy that systematically evaluatesdiverse format options. Our extensive evaluations across multiple tasks andopen-source LLMs demonstrate that CFPO demonstrates measurable performanceimprovements compared to content-only optimization methods. This highlights theimportance of integrated content-format optimization and offers a practical,model-agnostic approach to enhancing LLM performance. Code will be available athttps://github.com/HenryLau7/CFPO.",Yuanye Liu,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04294v1,Prediction-Powered E-Values,http://arxiv.org/abs/2502.04294v1,"Quality statistical inference requires a sufficient amount of data, which canbe missing or hard to obtain. To this end, prediction-powered inference hasrisen as a promising methodology, but existing approaches are largely limitedto Z-estimation problems such as inference of means and quantiles. In thispaper, we apply ideas of prediction-powered inference to e-values. By doing so,we inherit all the usual benefits of e-values -- such as anytime-validity,post-hoc validity and versatile sequential inference -- as well as greatlyexpand the set of inferences achievable in a prediction-powered manner. Inparticular, we show that every inference procedure that can be framed in termsof e-values has a prediction-powered counterpart, given by our method. Weshowcase the effectiveness of our framework across a wide range of inferencetasks, from simple hypothesis testing and confidence intervals to more involvedprocedures for change-point detection and causal discovery, which were out ofreach of previous techniques. Our approach is modular and easily integrableinto existing algorithms, making it a compelling choice for practicalapplications.",Daniel Csillag,2025-02-06,2025-02-06,,N/A,"['stat.ML', 'cs.LG', 'stat.ME']"
2502.04293v1,GCE-Pose: Global Context Enhancement for Category-level Object Pose Estimation,http://arxiv.org/abs/2502.04293v1,"A key challenge in model-free category-level pose estimation is theextraction of contextual object features that generalize across varyinginstances within a specific category. Recent approaches leverage foundationalfeatures to capture semantic and geometry cues from data. However, theseapproaches fail under partial visibility. We overcome this with afirst-complete-then-aggregate strategy for feature extraction utilizing classpriors. In this paper, we present GCE-Pose, a method that enhances poseestimation for novel instances by integrating category-level global contextprior. GCE-Pose performs semantic shape reconstruction with a proposed SemanticShape Reconstruction (SSR) module. Given an unseen partial RGB-D objectinstance, our SSR module reconstructs the instance's global geometry andsemantics by deforming category-specific 3D semantic prototypes through alearned deep Linear Shape Model. We further introduce a Global Context Enhanced(GCE) feature fusion module that effectively fuses features from partial RGB-Dobservations and the reconstructed global context. Extensive experimentsvalidate the impact of our global context prior and the effectiveness of theGCE fusion module, demonstrating that GCE-Pose significantly outperformsexisting methods on challenging real-world datasets HouseCat6D andNOCS-REAL275. Our project page is available athttps://colin-de.github.io/GCE-Pose/.",Weihang Li,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04288v1,Leveraging Geolocation in Clinical Records to Improve Alzheimer's Disease Diagnosis Using DMV Framework,http://arxiv.org/abs/2502.04288v1,"Alzheimer's Disease (AD) early detection is critical for enabling timelyintervention and improving patient outcomes. This paper presents a DMVframework using Llama3-70B and GPT-4o as embedding models to analyze clinicalnotes and predict a continuous risk score associated with early AD onset.Framing the task as a regression problem, we model the relationship betweenlinguistic features in clinical notes (inputs) and a target variable (datavalue) that answers specific questions related to AD risk within certain topiccategories. By leveraging a multi-faceted feature set that includes geolocationdata, we capture additional environmental context potentially linked to AD. Ourresults demonstrate that the integration of the geolocation informationsignificantly decreases the error of predicting early AD risk scores over priormodels by 28.57% (Llama3-70B) and 33.47% (GPT4-o). Our findings suggest thatthis combined approach can enhance the predictive accuracy of AD riskassessment, supporting early diagnosis and intervention in clinical settings.Additionally, the framework's ability to incorporate geolocation data providesa more comprehensive risk assessment model that could help healthcare providersbetter understand and address environmental factors contributing to ADdevelopment.",Peng Zhang,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04287v1,Breaking the Vault: A Case Study of the 2022 LastPass Data Breach,http://arxiv.org/abs/2502.04287v1,"Managing the security of employee work computers has become increasinglyimportant as today's work model shifts to remote and hybrid work plans. In thispaper, we explore the recent 2022 LastPass data breach, in which the attackerobtained sensitive customer data by exploiting a software vulnerability on aDevSecOps engineer's computer. We discuss the methodology of the attacker aswell as the impact this incident had on LastPass and its customers. Next, weexpand upon the impact the breach had on LastPass as well as its customers.From this, we propose solutions for preparing for and mitigating similarattacks in the future. The aim of this paper is to shed light on the LastPassincident and provide methods for companies to secure their employee base, bothnationally and internationally. With a strong security structure, companies canvastly reduce the chances of falling victim to a similar attack.",Jessica Gentles,2025-02-06,2025-02-06,,N/A,['cs.CR']
2502.04286v1,"A Methodology for Studying Linguistic and Cultural Change in China, 1900-1950",http://arxiv.org/abs/2502.04286v1,"This paper presents a quantitative approach to studying linguistic andcultural change in China during the first half of the twentieth century, aperiod that remains understudied in computational humanities research. Thedramatic changes in Chinese language and culture during this time call forgreater reflection on the tools and methods used for text analysis. Thispreliminary study offers a framework for analyzing Chinese texts from the latenineteenth and twentieth centuries, demonstrating how established methods suchas word counts and word embeddings can provide new historical insights into thecomplex negotiations between Western modernity and Chinese cultural discourse.",Spencer Dean Stewart,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04283v1,The Young Ages of 70 μm-dark Clumps Inferred from Carbon Chain Chemistry,http://arxiv.org/abs/2502.04283v1,"The physical conditions of the earliest environment of high-mass starformation are currently poorly understood. To that end, we present observationsof the carbon chain molecules HC$_5$N , CCS, and HC$_7$N in the 22-25 GHz bandtowards 12 high-mass 70 micron-dark clumps (SMDC) with the Jansky Very LargeArray (VLA). We detect HC$_5$N and CCS towards 11 of these SMDC sources. Wecalculate column densities and abundances relative to H$_2$ for HC$_5$N andCCS. We do not find any clear HC$_7$N detections in the 11 sourcesindividually, but by stacking the HC$_7$N spectra, we do detect HC$_7$N onaverage in these sources. We also calculate the ratio of the column densitiesof HC$_5$N to HC$_7$N using the stacked spectra of both species. We compare ourmeasured abundances of HC$_5$N and our measured ratio of HC$_5$N to HC$_7$N tothe UMIST dark cloud chemistry models to constrain an age for the gas assuminga fixed volume density and temperature. The chemical models favor a chemicalevolutionary age less than 1 Myr at densities of n(H2) = 2 x 10$^4$ cm$^{-3}$.The consistent carbon-chain detections and young model-derived ages support theconclusion that these 11 70 micron-dark clumps lack high mass protostarsbecause they are young and not because they are inefficient and incapable ofhigh mass star formation.",Kadin Worthen,2025-02-06,2025-02-06,,N/A,"['astro-ph.GA', 'astro-ph.SR']"
2502.04282v1,Isolating the hard core of phaseless inference: the Phase selection formulation,http://arxiv.org/abs/2502.04282v1,"Real-valued Phase retrieval is a non-convex continuous inference problem,where a high-dimensional signal is to be reconstructed from a dataset ofsignless linear measurements. Focusing on the noiseless case, we aim todisentangle the two distinct sub-tasks entailed in the Phase retrieval problem:the hard combinatorial problem of retrieving the missing signs of themeasurements, and the nested convex problem of regressing the input-outputobservations to recover the hidden signal. To this end, we introduce andanalytically characterize a two-level formulation of the problem, called``Phase selection''. Within the Replica Theory framework, we perform a largedeviation analysis to characterize the minimum mean squared error achievablewith different guesses for the hidden signs. Moreover, we study the free-energylandscape of the problem when both levels are optimized simultaneously, as afunction of the dataset size. At low temperatures, in proximity to theBayes-optimal threshold -- previously derived in the context of Phase retrieval-- we detect the coexistence of two free-energy branches, one connected to therandom initialization condition and a second to the signal. We derive the phasediagram for a first-order transition after which the two branches merge.Interestingly, introducing an $L_2$ regularization in the regression sub-taskcan anticipate the transition to lower dataset sizes, at the cost of a bias inthe signal reconstructions which can be removed by annealing the regularizationintensity. Finally, we study the inference performance of three meta-heuristicsin the context of Phase selection: Simulated Annealing, Approximate MessagePassing, and Langevin Dynamics on the continuous relaxation of the signvariables. With simultaneous annealing of the temperature and the $L_2$regularization, they are shown to approach the Bayes-optimal sample efficiency.",Davide Straziota,2025-02-06,2025-02-06,,N/A,['cond-mat.dis-nn']
2502.04280v1,Mean-Field Analysis of Latent Variable Process Models on Dynamically Evolving Graphs with Feedback Effects,http://arxiv.org/abs/2502.04280v1,"In this paper, we study the asymptotic behavior of a class of dynamicco-evolving latent space networks. The model we study is subject tobi-directional feedback effects, meaning that at any given time, the latentprocess depends on its own value and the graph structure at the previous timestep, and the graph structure at the current time depends on the value of thelatent processes at the current time but also on the graph structure at theprevious time instance (sometimes called a persistence effect). We constructthe mean-field limit of this model, which we use to characterize the limitingbehavior of a random sample taken from the latent space network in the limit asthe number of nodes in the network diverges. From this limiting model, we canderive the limiting behavior of the empirical measure of the latent process andestablish the related graphon limit of the latent particle network process. Wealso provide a description of the rich conditional probabilistic structure ofthe limiting model. The inherent dependence structure complicates themathematical analysis significantly. In the process of proving our mainresults, we derive a general conditional propagation of chaos result, which isof independent interest. In addition, our novel approach of studying thelimiting behavior of random samples proves to be a very useful methodology forfully grasping the asymptotic behavior of co-evolving particle systems.Numerical results are included to illustrate the theoretical findings.",Ankan Ganguly,2025-02-06,2025-02-06,,N/A,"['math.PR', '60K35, 60J05, 91D30 (Primary) 60B10, 60G57, 62D05 (Secondary)']"
2502.04278v1,Probing Spin-Orbit Resonances with the Binary Black Hole Population,http://arxiv.org/abs/2502.04278v1,"Measurements of the binary black hole spin distribution from the growingcatalog of gravitational-wave observations can help elucidate the astrophysicalprocesses shaping the formation and evolution of these systems. Spin-orbitresonances are one process of interest, in which the component spin vectors andthe orbital angular momentum align into a common plane and jointly precessabout the total angular momentum of the system. These resonances, which occurpreferentially in systems formed via isolated binary evolution with strongtidal effects, lead to excesses in the distribution of the azimuthal anglebetween the projections of the component spin vectors onto the orbital plane at$\phi_{12}=0,\pm\pi$. Previous analyses have demonstrated that this parameteris particularly difficult to constrain for individual binaries. In this work,we conduct the first hierarchical analysis modeling the population-leveldistribution of $\phi_{12}$ simultaneously with the other mass and spinparameters for simulated binary black hole populations to determine whetherspin-orbit resonances can be reliably constrained. While we are unlikely tofind definitive evidence for spin-orbit resonances with a population of thesize expected by the end of the ongoing LIGO-Virgo-KAGRA fourth observing run,we correctly recover the various $\phi_{12}$ distributions we simulate withinuncertainties. We find that we can place meaningful constraints on the relativeexcesses at $\phi_{12}=0,\pm\pi$, which encodes information about mass transferin the formation of the binary. We can also distinguish between fully isotropicspin angle distributions and those with features in the spin azimuth and tiltdistributions. Thus, we show that population-level measurements of the$\phi_{12}$ distribution offer a reliable, novel way to probe binary formationchannels, dynamics, and mass transfer with gravitational-wave observations.",Sylvia Biscoveanu,2025-02-06,2025-02-06,,N/A,"['astro-ph.HE', 'gr-qc']"
2502.04276v1,Gaussian Process Regression for Inverse Problems in Linear PDEs,http://arxiv.org/abs/2502.04276v1,"This paper introduces a computationally efficient algorithm in system theoryfor solving inverse problems governed by linear partial differential equations(PDEs). We model solutions of linear PDEs using Gaussian processes with priorsdefined based on advanced commutative algebra and algebraic analysis. Theimplementation of these priors is algorithmic and achieved using the Macaulay2computer algebra software. An example application includes identifying the wavespeed from noisy data for classical wave equations, which are widely used inphysics. The method achieves high accuracy while enhancing computationalefficiency.",Xin Li,2025-02-06,2025-02-06,,N/A,"['stat.ML', 'cs.LG', 'math.AC']"
2502.04273v1,Electrical Impedance Tomography for Anisotropic Media: a Machine Learning Approach to Classify Inclusions,http://arxiv.org/abs/2502.04273v1,"We consider the problem in Electrical Impedance Tomography (EIT) ofidentifying one or multiple inclusions in a background-conducting body$\Omega\subset\mathbb{R}^2$, from the knowledge of a finite number ofelectrostatic measurements taken on its boundary $\partial\Omega$ and modelledby the Dirichlet-to-Neumann (D-N) matrix. Once the presence of one inclusion in$\Omega$ is established, our model, combined with the machine learningtechniques of Artificial Neural Networks (ANN) and Support Vector Machines(SVM), may be used to determine the size of the inclusion, the presence ofmultiple inclusions, and also that of anisotropy within the inclusion(s).Utilising both real and simulated datasets within a 16-electrode setup, weachieve a high rate of inclusion detection and show that two measurements aresufficient to achieve a good level of accuracy when predicting the size of aninclusion. This underscores the substantial potential of integrating machinelearning approaches with the more classical analysis of EIT and the inverseinclusion problem to extract critical insights, such as the presence ofanisotropy.",Romina Gaburro,2025-02-06,2025-02-06,,N/A,"['math.NA', 'cs.LG', 'cs.NA', '65N21, 35R30, 68T99']"
2502.04270v1,PILAF: Optimal Human Preference Sampling for Reward Modeling,http://arxiv.org/abs/2502.04270v1,"As large language models increasingly drive real-world applications, aligningthem with human values becomes paramount. Reinforcement Learning from HumanFeedback (RLHF) has emerged as a key technique, translating preference datainto reward models when oracle human values remain inaccessible. In practice,RLHF mostly relies on approximate reward models, which may not consistentlyguide the policy toward maximizing the underlying human values. We proposePolicy-Interpolated Learning for Aligned Feedback (PILAF), a novel responsesampling strategy for preference labeling that explicitly aligns preferencelearning with maximizing the underlying oracle reward. PILAF is theoreticallygrounded, demonstrating optimality from both an optimization and a statisticalperspective. The method is straightforward to implement and demonstrates strongperformance in iterative and online RLHF settings where feedback curation iscritical.",Yunzhen Feng,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'stat.ML']"
2502.04269v1,How does a Multilingual LM Handle Multiple Languages?,http://arxiv.org/abs/2502.04269v1,"Multilingual language models have significantly advanced due to rapidprogress in natural language processing. Models like BLOOM 1.7B, trained ondiverse multilingual datasets, aim to bridge linguistic gaps. However, theireffectiveness in capturing linguistic knowledge, particularly for low-resourcelanguages, remains an open question. This study critically examines MLMscapabilities in multilingual understanding, semantic representation, andcross-lingual knowledge transfer. While these models perform well forhigh-resource languages, they struggle with less-represented ones.Additionally, traditional evaluation methods often overlook their internalsyntactic and semantic encoding.  This research addresses key limitations through three objectives. First, itassesses semantic similarity by analyzing multilingual word embeddings forconsistency using cosine similarity. Second, it examines BLOOM-1.7B and Qwen2through Named Entity Recognition and sentence similarity tasks to understandtheir linguistic structures. Third, it explores cross-lingual knowledgetransfer by evaluating generalization from high-resource to low-resourcelanguages in sentiment analysis and text classification.  By leveraging linguistic probing, performance metrics, and visualizations,this study provides insights into the strengths and limitations of MLMs. Thefindings aim to enhance multilingual NLP models, ensuring better support forboth high- and low-resource languages, thereby promoting inclusivity inlanguage technologies.",Santhosh Kakarla,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.04265v1,Fermion Dark Matter Effect on Electroweak Phase Transition,http://arxiv.org/abs/2502.04265v1,"The addition of extra scalars to the Standard Model (SM) of particle physicsenriches the vacuum structure and consequently gives rise to strong first-orderphase transitions (EWPT) in the early universe. We raise the question that howthe EWPT is affected by the addition of fermions in models beyond the SM, andaddress this question by studying the EWPT in a dark matter model comprising asinglet scalar and two Dirac fermions. The singlet scalar develops a nonzerovacuum expectation value (VEV), and the lighter fermion plays the role of thedark matter. The model evades the stringent direct detection bounds due to thepresence of two fermions. We first show that applying the high-temperatureapproximation, no first-order phase transition is found. Then we demonstratethat when including the full finite temperature corrections to the effectivepotential, the first-order phase transition becomes possible, nevertheless, allthe phase transitions will be weak. We therefore deduce that the addition offermions reduces the strength of the EWPT.",Soudeh Mirzaie,2025-02-06,2025-02-06,,N/A,['hep-ph']
2502.04264v1,Fundamental Oscillation Modes in Neutron Stars with Hyperons and Delta Baryons,http://arxiv.org/abs/2502.04264v1,"For a new parameterization of the modified effective chiral model, developedprimarily to regulate the density content of the symmetry energy and its higherorder terms, equations of state (EoSs) for hyperon-rich matter ($H$) and deltabaryon matter ($\Delta$) were obtained. The models were used to investigate theemission of gravitational waves (GWs) through $f$-mode oscillations in thecorresponding neutron stars. We obtained the stellar structure, $f$-modefrequency and tidal deformability $\Lambda$ for our models. We report that the$\Delta$ EoS is stiffer compared to the $H$ EoS. We also analyzed the velocityof sound in these media. The corresponding mass--radius relationships wereobtained and compared with various observations. We studied the dependence of$f$-mode frequencies on the stellar mass, redshift and tidal deformability. Weemployed the well known Cowling approximation to obtain the $f$-modefrequencies for $l=2,\,3$ and $4$ modes of oscillation. We found that the$f$-mode frequencies of the $H$ and $\Delta$ EoSs were almost the same in thelower mass region, while we observed a substantial difference between them inthe high-mass region. We also obtained an empirical relation for the EoSsconsidered. The various attributes obtained for our models showed closeagreement with various observational constraints from pulsars and GW events.",O. P. Jyothilakshmi,2025-02-06,2025-02-06,,N/A,"['astro-ph.HE', 'nucl-th']"
2502.04263v1,Cross the Gap: Exposing the Intra-modal Misalignment in CLIP via Modality Inversion,http://arxiv.org/abs/2502.04263v1,"Pre-trained multi-modal Vision-Language Models like CLIP are widely usedoff-the-shelf for a variety of applications. In this paper, we show that thecommon practice of individually exploiting the text or image encoders of thesepowerful multi-modal models is highly suboptimal for intra-modal tasks likeimage-to-image retrieval. We argue that this is inherently due to theCLIP-style inter-modal contrastive loss that does not enforce any intra-modalconstraints, leading to what we call intra-modal misalignment. To demonstratethis, we leverage two optimization-based modality inversion techniques that maprepresentations from their input modality to the complementary one without anyneed for auxiliary data or additional trained adapters. We empirically showthat, in the intra-modal tasks of image-to-image and text-to-text retrieval,approaching these tasks inter-modally significantly improves performance withrespect to intra-modal baselines on more than fifteen datasets. Additionally,we demonstrate that approaching a native inter-modal task (e.g. zero-shot imageclassification) intra-modally decreases performance, further validating ourfindings. Finally, we show that incorporating an intra-modal term in thepre-training objective or narrowing the modality gap between the text and imagefeature embedding spaces helps reduce the intra-modal misalignment. The code ispublicly available at: https://github.com/miccunifi/Cross-the-Gap.",Marco Mistretta,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.AI', 'cs.LG']"
2502.04262v1,Efficient Randomized Experiments Using Foundation Models,http://arxiv.org/abs/2502.04262v1,"Randomized experiments are the preferred approach for evaluating the effectsof interventions, but they are costly and often yield estimates withsubstantial uncertainty. On the other hand, in silico experiments leveragingfoundation models offer a cost-effective alternative that can potentiallyattain higher statistical precision. However, the benefits of in silicoexperiments come with a significant risk: statistical inferences are not validif the models fail to accurately predict experimental responses tointerventions. In this paper, we propose a novel approach that integrates thepredictions from multiple foundation models with experimental data whilepreserving valid statistical inference. Our estimator is consistent andasymptotically normal, with asymptotic variance no larger than the standardestimator based on experimental data alone. Importantly, these statisticalproperties hold even when model predictions are arbitrarily biased. Empiricalresults across several randomized experiments show that our estimator offerssubstantial precision gains, equivalent to a reduction of up to 20% in thesample size needed to match the same precision as the standard estimator basedon experimental data alone.",Piersilvio De Bartolomeis,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'stat.ME', 'stat.ML']"
2502.04260v1,Realistic Image-to-Image Machine Unlearning via Decoupling and Knowledge Retention,http://arxiv.org/abs/2502.04260v1,"Machine Unlearning allows participants to remove their data from a trainedmachine learning model in order to preserve their privacy, and security.However, the machine unlearning literature for generative models is ratherlimited. The literature for image-to-image generative model (I2I model)considers minimizing the distance between Gaussian noise and the output of I2Imodel for forget samples as machine unlearning. However, we argue that themachine learning model performs fairly well on unseen data i.e., a retrainedmodel will be able to catch generic patterns in the data and hence will notgenerate an output which is equivalent to Gaussian noise. In this paper, weconsider that the model after unlearning should treat forget samples asout-of-distribution (OOD) data, i.e., the unlearned model should no longerrecognize or encode the specific patterns found in the forget samples. Toachieve this, we propose a framework which decouples the model parameters withgradient ascent, ensuring that forget samples are OOD for unlearned model withtheoretical guarantee. We also provide $(\epsilon, \delta)$-unlearningguarantee for model updates with gradient ascent. The unlearned model isfurther fine-tuned on the remaining samples to maintain its performance. Wealso propose an attack model to ensure that the unlearned model has effectivelyremoved the influence of forget samples. Extensive empirical evaluation on twolarge-scale datasets, ImageNet-1K and Places365 highlights the superiority ofour approach. To show comparable performance with retrained model, we also showthe comparison of a simple AutoEncoder on various baselines on CIFAR-10dataset.",Ayush K. Varshney,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04259v1,Cognitive AI framework: advances in the simulation of human thought,http://arxiv.org/abs/2502.04259v1,"The Human Cognitive Simulation Framework represents a significant advancementin integrating human cognitive capabilities into artificial intelligencesystems. By merging short-term memory (conversation context), long-term memory(interaction context), advanced cognitive processing, and efficient knowledgemanagement, it ensures contextual coherence and persistent data storage,enhancing personalization and continuity in human-AI interactions. Theframework employs a unified database that synchronizes these contexts whileincorporating logical, creative, and analog processing modules inspired byhuman brain hemispheric functions to perform structured tasks and complexinferences. Dynamic knowledge updates enable real-time integration, improvingadaptability and fostering applications in education, behavior analysis, andknowledge management. Despite its potential to process vast data volumes andenhance user experience, challenges remain in scalability, cognitive biasmitigation, and ethical compliance. This framework lays the foundation forfuture research in continuous learning algorithms, sustainability, andmultimodal adaptability, positioning Cognitive AI as a transformative model inemerging fields.",Rommel Salas-Guerra,2025-02-06,2025-02-06,,N/A,"['cs.HC', 'cs.CY']"
2502.04257v1,Probability Bracket Notation for Probability Modeling,http://arxiv.org/abs/2502.04257v1,"Following the Dirac Notation in Quantum Mechanics (QM), we propose theBracket Notation (PBN) by defining a probability-bra (P-bra), P-ket, P-bracket,P-identity, etc. Using the PBN, many formulae, such as normalizations andexpectations in systems of one or more random variables, can now be written inabstract basis-independent expressions, which are easy to expand by inserting aproper P-identity. The time evolution of homogeneous Markov processes can alsobe formatted in such a way. Our system P-kets are identified with probabilityvectors, and our system P-bra is comparable to the Doi state function or thePeliti standard bra. In the Heisenberg picture of the PBN, a random variablebecomes a stochastic process, and the Chapman-Kolmogorov equations are obtainedby inserting a time-dependent P-identity. Also, some QM expressions in theDirac notation are naturally transformed into probability expressions in PBN bya special Wick rotation. Potential applications show the usefulness of the PBNbeyond the constrained domain and range of Hermitian operators on HilbertSpaces in QM all the way to IT.",Xing M. Wang,2025-02-06,2025-02-06,,N/A,"['math.PR', 'math-ph', 'math.MP', 'quant-ph']"
2502.04251v1,Combining Language and App UI Analysis for the Automated Assessment of Bug Reproduction Steps,http://arxiv.org/abs/2502.04251v1,"Bug reports are essential for developers to confirm software problems,investigate their causes, and validate fixes. Unfortunately, reports often missimportant information or are written unclearly, which can cause delays,increased issue resolution effort, or even the inability to solve issues. Oneof the most common components of reports that are problematic is the steps toreproduce the bug(s) (S2Rs), which are essential to replicate the describedprogram failures and reason about fixes. Given the proclivity for deficienciesin reported S2Rs, prior work has proposed techniques that assist reporters inwriting or assessing the quality of S2Rs. However, automated understanding ofS2Rs is challenging, and requires linking nuanced natural language phrases withspecific, semantically related program information. Prior techniques oftenstruggle to form such language to program connections - due to issues inlanguage variability and limitations of information gleaned from programanalyses.  To more effectively tackle the problem of S2R quality annotation, we proposea new technique called AstroBR, which leverages the language understandingcapabilities of LLMs to identify and extract the S2Rs from bug reports and mapthem to GUI interactions in a program state model derived via dynamic analysis.We compared AstroBR to a related state-of-the-art approach and we found thatAstroBR annotates S2Rs 25.2% better (in terms of F1 score) than the baseline.Additionally, AstroBR suggests more accurate missing S2Rs than the baseline (by71.4% in terms of F1 score).",Junayed Mahmud,2025-02-06,2025-02-06,,N/A,"['cs.SE', 'cs.LG']"
2502.04249v1,Free Energy Risk Metrics for Systemically Safe AI: Gatekeeping Multi-Agent Study,http://arxiv.org/abs/2502.04249v1,"We investigate the Free Energy Principle as a foundation for measuring riskin agentic and multi-agent systems. From these principles we introduce aCumulative Risk Exposure metric that is flexible to differing contexts andneeds. We contrast this to other popular theories for safe AI that hinge onmassive amounts of data or describing arbitrarily complex world models. In ourframework, stakeholders need only specify their preferences over systemoutcomes, providing straightforward and transparent decision rules for riskgovernance and mitigation. This framework naturally accounts for uncertainty inboth world model and preference model, allowing for decision-making that isepistemically and axiologically humble, parsimonious, and future-proof. Wedemonstrate this novel approach in a simplified autonomous vehicle environmentwith multi-agent vehicles whose driving policies are mediated by gatekeepersthat evaluate, in an online fashion, the risk to the collective safety in theirneighborhood, and intervene through each vehicle's policy when appropriate. Weshow that the introduction of gatekeepers in an AV fleet, even at lowpenetration, can generate significant positive externalities in terms ofincreased system safety.",Michael Walters,2025-02-06,2025-02-06,,N/A,"['cs.AI', 'cs.LG', 'cs.MA', 'physics.data-an', 'stat.ML']"
2502.04248v1,Adapting to Evolving Adversaries with Regularized Continual Robust Training,http://arxiv.org/abs/2502.04248v1,"Robust training methods typically defend against specific attack types, suchas Lp attacks with fixed budgets, and rarely account for the fact thatdefenders may encounter new attacks over time. A natural solution is to adaptthe defended model to new adversaries as they arise via fine-tuning, a methodwhich we call continual robust training (CRT). However, when implementednaively, fine-tuning on new attacks degrades robustness on previous attacks.This raises the question: how can we improve the initial training andfine-tuning of the model to simultaneously achieve robustness against previousand new attacks? We present theoretical results which show that the gap in amodel's robustness against different attacks is bounded by how far each attackperturbs a sample in the model's logit space, suggesting that regularizing withrespect to this logit space distance can help maintain robustness againstprevious attacks. Extensive experiments on 3 datasets (CIFAR-10, CIFAR-100, andImageNette) and over 100 attack combinations demonstrate that the proposedregularization improves robust accuracy with little overhead in training time.Our findings and open-source code lay the groundwork for the deployment ofmodels robust to evolving attacks.",Sihui Dai,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04247v1,Student-t processes as infinite-width limits of posterior Bayesian neural networks,http://arxiv.org/abs/2502.04247v1,"The asymptotic properties of Bayesian Neural Networks (BNNs) have beenextensively studied, particularly regarding their approximations by Gaussianprocesses in the infinite-width limit. We extend these results by showing thatposterior BNNs can be approximated by Student-t processes, which offer greaterflexibility in modeling uncertainty. Specifically, we show that, if theparameters of a BNN follow a Gaussian prior distribution, and the variance ofboth the last hidden layer and the Gaussian likelihood function follows anInverse-Gamma prior distribution, then the resulting posterior BNN converges toa Student-t process in the infinite-width limit. Our proof leverages theWasserstein metric to establish control over the convergence rate of theStudent-t process approximation.",Francesco Caporali,2025-02-06,2025-02-06,,N/A,"['stat.ML', 'cs.LG', 'math.PR']"
2502.04246v1,Multi-fidelity emulator for large-scale 21 cm lightcone images: a few-shot transfer learning approach with generative adversarial network,http://arxiv.org/abs/2502.04246v1,"Emulators using machine learning techniques have emerged to efficientlygenerate mock data matching the large survey volume for upcoming experiments,as an alternative approach to large-scale numerical simulations. However,high-fidelity emulators have become computationally expensive as the simulationvolume grows to hundreds of megaparsecs. Here, we present a {\itmulti-fidelity} emulation of large-scale 21~cm lightcone images from the epochof reionization, which is realized by applying the {\it few-shot transferlearning} to training generative adversarial networks (GAN) from small-scale tolarge-scale simulations. Specifically, a GAN emulator is first trained with ahuge number of small-scale simulations, and then transfer-learned with only alimited number of large-scale simulations, to emulate large-scale 21~cmlightcone images. We test the precision of our transfer-learned GAN emulator interms of representative statistics including global 21~cm brightnesstemperature history, 2D power spectrum, and scattering transform coefficients.We demonstrate that the lightcone images generated by the transfer-learned GANemulator can reach the percentage level precision in most cases on smallscales, and the error on large scales only increases mildly to the level of afew tens of per cent. Nevertheless, our multi-fidelity emulation techniquesaves a significant portion of computational resources that are mostly consumedfor generating training samples for GAN. On estimate, the computationalresource by training GAN completely with large-scale simulations would be oneto two orders of magnitude larger than using our multi-fidelity technique. Thisimplies that our technique allows for emulating high-fidelity, traditionallycomputationally prohibitive, images in an economic manner.",Kangning Diao,2025-02-06,2025-02-06,,N/A,"['astro-ph.IM', 'astro-ph.CO']"
2502.04245v1,"TriNER: A Series of Named Entity Recognition Models For Hindi, Bengali & Marathi",http://arxiv.org/abs/2502.04245v1,"India's rich cultural and linguistic diversity poses various challenges inthe domain of Natural Language Processing (NLP), particularly in Named EntityRecognition (NER). NER is a NLP task that aims to identify and classify tokensinto different entity groups like Person, Location, Organization, Number, etc.This makes NER very useful for downstream tasks like context-awareanonymization. This paper details our work to build a multilingual NER modelfor the three most spoken languages in India - Hindi, Bengali & Marathi. Wetrain a custom transformer model and fine tune a few pretrained models,achieving an F1 Score of 92.11 for a total of 6 entity groups. Through thispaper, we aim to introduce a single model to perform NER and significantlyreduce the inconsistencies in entity groups and tag names, across the threelanguages.",Mohammed Amaan Dhamaskar,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI', 'cs.LG']"
2502.04244v1,An object detection approach for lane change and overtake detection from motion profiles,http://arxiv.org/abs/2502.04244v1,"In the application domain of fleet management and driver monitoring, it isvery challenging to obtain relevant driving events and activities from dashcamfootage while minimizing the amount of information stored and analyzed. In thispaper, we address the identification of overtake and lane change maneuvers witha novel object detection approach applied to motion profiles, a compactrepresentation of driving video footage into a single image. To train and testour model we created an internal dataset of motion profile images obtained froma heterogeneous set of dashcam videos, manually labeled with overtake and lanechange maneuvers by the ego-vehicle. In addition to a standard object-detectionapproach, we show how the inclusion of CoordConvolution layers further improvesthe model performance, in terms of mAP and F1 score, yielding state-of-the artperformance when compared to other baselines from the literature. The extremelylow computational requirements of the proposed solution make it especiallysuitable to run in device.",Andrea Benericetti,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04243v1,FedOptimus: Optimizing Vertical Federated Learning for Scalability and Efficiency,http://arxiv.org/abs/2502.04243v1,"Federated learning (FL) is a collaborative machine learning paradigm whichensures data privacy by training models across distributed datasets withoutcentralizing sensitive information. Vertical Federated Learning (VFL), a kindof FL training method, facilitates collaboration among participants with eachclient having received a different feature space of a shared user set. VFLthus, proves invaluable in privacy-sensitive domains such as finance andhealthcare. Despite its inherent advantages, VFL faced challenges includingcommunication bottlenecks, computational inefficiency, and slow convergence dueto non-IID data distributions. This paper introduces FedOptimus, a robustMulti-VFL framework integrating advanced techniques for improved modelefficiency and scalability. FedOptimus leverages a Mutual Information(MI)-based client selection to prioritize high-contribution participants,reducing computational overhead. Further, it incorporates server-side momentumtechniques like FedAvgM and SLOWMO to stabilize updates and accelerateconvergence on heterogeneous data. Additionally, performing K-Step Averagingminimizes communication costs while maintaining model performance. FedOptimusproves to be superior in performance on benchmark datasets such as CIFAR-10,MNIST, and FMNIST, showcasing its scalability and effectiveness in real-worldmulti-server, multi-client settings. By unifying advanced optimization methods,FedOptimus sets a new standard for efficient and scalable Vertical FederatedLearning frameworks, paving the way for broader adoption in complex,privacy-sensitive domains.",Nikita Shrivastava,2025-02-06,2025-02-06,,N/A,['cs.DC']
2502.04242v1,A Theoretical Framework for Data Efficient Multi-Source Transfer Learning Based on Cramér-Rao Bound,http://arxiv.org/abs/2502.04242v1,"Multi-source transfer learning provides an effective solution to datascarcity in real-world supervised learning scenarios by leveraging multiplesource tasks. In this field, existing works typically use all available samplesfrom sources in training, which constrains their training efficiency and maylead to suboptimal results. To address this, we propose a theoretical frameworkthat answers the question: what is the optimal quantity of source samplesneeded from each source task to jointly train the target model? Specifically,we introduce a generalization error measure that aligns with cross-entropyloss, and minimize it based on the Cram\'er-Rao Bound to determine the optimaltransfer quantity for each source task. Additionally, we develop anarchitecture-agnostic and data-efficient algorithm OTQMS to implement ourtheoretical results for training deep multi-source transfer learning models.Experimental studies on diverse architectures and two real-world benchmarkdatasets show that our proposed algorithm significantly outperformsstate-of-the-art approaches in both accuracy and data efficiency. The code andsupplementary materials are available inhttps://anonymous.4open.science/r/Materials.",Qingyue Zhang,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI']"
2502.04241v1,Search for hadronic decays of feebly-interacting particles at NA62,http://arxiv.org/abs/2502.04241v1,"The NA62 experiment at CERN has the capability to collect data in a beam-dumpmode, where 400 GeV protons are dumped on an absorber. In this configuration,New Physics particles, including dark photons, dark scalars, and axion-likeparticles, may be produced in the absorber and decay in the instrumented volumebeginning approximately 80 m downstream of the dump. A search for theseparticles decaying in flight to hadronic final states is reported, based on ananalysis of a sample of $1.4 \times 10^{17}$ protons on dump collected in 2021.No evidence of a New Physics signal is observed, excluding new regions ofparameter spaces of multiple models.",NA62 Collaboration,2025-02-06,2025-02-06,,N/A,"['hep-ex', 'hep-ph']"
2502.04240v1,Memory-dependent abstractions of stochastic systems through the lens of transfer operators,http://arxiv.org/abs/2502.04240v1,"With the increasing ubiquity of safety-critical autonomous systems operatingin uncertain environments, there is a need for mathematical methods for formalverification of stochastic models. Towards formally verifying properties ofstochastic systems, methods based on discrete, finite Markov approximations --abstractions -- thereof have surged in recent years. These are found incontexts where: either a) one only has partial, discrete observations of theunderlying continuous stochastic process, or b) the original system is toocomplex to analyze, so one partitions the continuous state-space of theoriginal system to construct a handleable, finite-state model thereof. In bothcases, the abstraction is an approximation of the discrete stochastic processthat arises precisely from the discretization of the underlying continuousprocess. The fact that the abstraction is Markov and the discrete process isnot (even though the original one is) leads to approximation errors. Towardsaccounting for non-Markovianity, we introduce memory-dependent abstractions forstochastic systems, capturing dynamics with memory effects. Our contribution istwofold. First, we provide a formalism for memory-dependent abstractions basedon transfer operators. Second, we quantify the approximation error by upperbounding the total variation distance between the true continuous statedistribution and its discrete approximation.",Adrien Banse,2025-02-06,2025-02-06,,N/A,"['eess.SY', 'cs.SY']"
2502.04238v1,Multitype Lévy trees as scaling limits of multitype Bienaymé-Galton-Watson trees,http://arxiv.org/abs/2502.04238v1,"We establish sufficient conditions for a sequence of metric spaces equippedwith vector-valued measures glued via an iterative operation to converge in theGromov-Hausdorff-Prohorov topology. We use this to show that under mildconditions multitype Bienaym\'e-Galton-Watson trees, conditioned in some senseto be large, converge to a limiting compact metric space which we call amultitype L\'{e}vy tree. More precisely we condition on the size of the maximalsubtree of vertices of the same type generated by the root to be large.Although under a different conditioning, our result can be seen as ageneralization to the multitype setting, of the Continuum Random Tree definedby Aldous in (Aldous 1991, 1993).",Osvaldo Angtuncio Hernández,2025-02-06,2025-02-06,,N/A,['math.PR']
2502.04235v1,MAGA: MAssive Genre-Audience Reformulation to Pretraining Corpus Expansion,http://arxiv.org/abs/2502.04235v1,"Despite the remarkable capabilities of large language models across varioustasks, their continued scaling faces a critical challenge: the scarcity ofhigh-quality pretraining data. While model architectures continue to evolve,the natural language data struggles to scale up. To tackle this bottleneck, wepropose \textbf{MA}ssive \textbf{G}enre-\textbf{A}udience~(MAGA) reformulationmethod, which systematic synthesizes diverse, contextually-rich pretrainingdata from existing corpus. This work makes three main contributions: (1) Wepropose MAGA reformulation method, a lightweight and scalable approach forpretraining corpus expansion, and build a 770B tokens MAGACorpus. (2) Weevaluate MAGACorpus with different data budget scaling strategies,demonstrating consistent improvements across various model sizes (134M-13B),establishing the necessity for next-generation large-scale syntheticpretraining language models. (3) Through comprehensive analysis, we investigateprompt engineering's impact on synthetic training collapse and reveallimitations in conventional collapse detection metrics using validation losses.Our work shows that MAGA can substantially expand training datasets whilemaintaining quality, offering a reliably pathway for scaling models beyond datalimitations.",Xintong Hao,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04234v1,A Classification System Approach in Predicting Chinese Censorship,http://arxiv.org/abs/2502.04234v1,"This paper is dedicated to using a classifier to predict whether a Weibo postwould be censored under the Chinese internet. Through randomized sampling from\citeauthor{Fu2021} and Chinese tokenizing strategies, we constructed a cleanedChinese phrase dataset with binary censorship markings. Utilizing variousprobability-based information retrieval methods on the data, we were able toderive 4 logistic regression models for classification. Furthermore, weexperimented with pre-trained transformers to perform similar classificationtasks. After evaluating both the macro-F1 and ROC-AUC metrics, we concludedthat the Fined-Tuned BERT model exceeds other strategies in performance.",Matt Prodani,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.LG', 'cs.SI']"
2502.04233v1,Graph machine learning for flight delay prediction due to holding manouver,http://arxiv.org/abs/2502.04233v1,"Flight delays due to holding maneuvers are a critical and costly phenomenonin aviation, driven by the need to manage air traffic congestion and ensuresafety. Holding maneuvers occur when aircraft are instructed to circle indesignated airspace, often due to factors such as airport congestion, adverseweather, or air traffic control restrictions. This study models the predictionof flight delays due to holding maneuvers as a graph problem, leveragingadvanced Graph Machine Learning (Graph ML) techniques to capture complexinterdependencies in air traffic networks. Holding maneuvers, while crucial forsafety, cause increased fuel usage, emissions, and passenger dissatisfaction,making accurate prediction essential for operational efficiency. Traditionalmachine learning models, typically using tabular data, often overlookspatial-temporal relations within air traffic data. To address this, we modelthe problem of predicting holding as edge feature prediction in a directed(multi)graph where we apply both CatBoost, enriched with graph featurescapturing network centrality and connectivity, and Graph Attention Networks(GATs), which excel in relational data contexts. Our results indicate thatCatBoost outperforms GAT in this imbalanced dataset, effectively predictingholding events and offering interpretability through graph-based featureimportance. Additionally, we discuss the model's potential operational impactthrough a web-based tool that allows users to simulate real-time delaypredictions. This research underscores the viability of graph-based approachesfor predictive analysis in aviation, with implications for enhancing fuelefficiency, reducing delays, and improving passenger experience.",Jorge L. Franco,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.SI']"
2502.04232v1,$D_1$ and $D_2$ resonances in coupled-channel scattering amplitudes from lattice QCD,http://arxiv.org/abs/2502.04232v1,"Isospin-1/2 charmed axial-vector $D^*\pi-D^*\eta-D^*_s\bar{K}$ scatteringamplitudes are computed, along with interactions in several other $I=1/2$ $J^P$channels. Using lattice QCD, we work at a light-quark mass corresponding to$m_\pi\approx 391$ MeV, where the lowest three-hadron threshold ($D\pi\pi$)lies high enough to enable a rigorous treatment of this system considering onlytwo-hadron scattering channels. At this light-quark mass, an axial-vector $D_1$bound state is observed just below $D^*\pi$ threshold, that is strongly coupledto $D^*\pi$ in a relative $S$-wave and influences a wide energy region up tothe $D^*\eta$ threshold. An axial-vector $D_1^\prime$ resonance is observed inthe elastic $D^*\pi$ energy-region, which is coupled more strongly to $D$-wave$D^*\pi$. A single narrow tensor state is seen in $J^P=2^+$ coupled to both$D\pi$ and $D^*\pi$. In the region where $D^*\eta$ and $D^*_s\bar{K}$ arekinematically open, the available energy levels indicate significant $S$-waveinteractions. Upon searching this region for poles, several possibilities existwith large uncertainties. One additional state consistently arises,predominantly coupled to the $S$-wave $D^*\pi-D^*\eta-D^*_s\bar{K}$ amplitudesaround the upper energy limit of this analysis.",Nicolas Lang,2025-02-06,2025-02-06,,N/A,"['hep-lat', 'hep-ph']"
2502.04229v1,Dark Distillation: Backdooring Distilled Datasets without Accessing Raw Data,http://arxiv.org/abs/2502.04229v1,"Dataset distillation (DD) enhances training efficiency and reduces bandwidthby condensing large datasets into smaller synthetic ones. It enables models toachieve performance comparable to those trained on the raw full dataset and hasbecome a widely adopted method for data sharing. However, security concerns inDD remain underexplored. Existing studies typically assume that maliciousbehavior originates from dataset owners during the initial distillationprocess, where backdoors are injected into raw datasets. In contrast, this workis the first to address a more realistic and concerning threat: attackers mayintercept the dataset distribution process, inject backdoors into the distilleddatasets, and redistribute them to users. While distilled datasets werepreviously considered resistant to backdoor attacks, we demonstrate that theyremain vulnerable to such attacks. Furthermore, we show that attackers do noteven require access to any raw data to inject the backdoors successfully.Specifically, our approach reconstructs conceptual archetypes for each classfrom the model trained on the distilled dataset. Backdoors are then injectedinto these archetypes to update the distilled dataset. Moreover, we ensure theupdated dataset not only retains the backdoor but also preserves the originaloptimization trajectory, thus maintaining the knowledge of the raw dataset. Toachieve this, a hybrid loss is designed to integrate backdoor information alongthe benign optimization trajectory, ensuring that previously learnedinformation is not forgotten. Extensive experiments demonstrate that distilleddatasets are highly vulnerable to backdoor attacks, with risks pervasive acrossvarious raw datasets, distillation methods, and downstream training strategies.Moreover, our attack method is efficient, capable of synthesizing a maliciousdistilled dataset in under one minute in certain cases.",Ziyuan Yang,2025-02-06,2025-02-06,,N/A,"['cs.CR', 'cs.AI']"
2502.04227v1,Can LLMs Hack Enterprise Networks? Autonomous Assumed Breach Penetration-Testing Active Directory Networks,http://arxiv.org/abs/2502.04227v1,"We explore the feasibility and effectiveness of using LLM-driven autonomoussystems for Assumed Breach penetration testing in enterprise networks. Weintroduce a novel prototype that, driven by Large Language Models (LLMs), cancompromise accounts within a real-life Active Directory testbed. Our researchprovides a comprehensive evaluation of the prototype's capabilities, andhighlights both strengths and limitations while executing attack. Theevaluation uses a realistic simulation environment (Game of Active Directory,GOAD) to capture intricate interactions, stochastic outcomes, and timingdependencies that characterize live network scenarios. The study concludes thatautonomous LLMs are able to conduct Assumed Breach simulations, potentiallydemocratizing access to penetration testing for organizations facing budgetaryconstraints.  The prototype's source code, traces, and analyzed logs are released asopen-source to enhance collective cybersecurity and facilitate future researchin LLM-driven cybersecurity automation.",Andreas Happe,2025-02-06,2025-02-06,,N/A,['cs.CR']
2502.04226v1,Keep It Light! Simplifying Image Clustering Via Text-Free Adapters,http://arxiv.org/abs/2502.04226v1,"Many competitive clustering pipelines have a multi-modal design, leveraginglarge language models (LLMs) or other text encoders, and text-image pairs,which are often unavailable in real-world downstream applications.Additionally, such frameworks are generally complicated to train and requiresubstantial computational resources, making widespread adoption challenging. Inthis work, we show that in deep clustering, competitive performance with morecomplex state-of-the-art methods can be achieved using a text-free and highlysimplified training pipeline. In particular, our approach, Simple Clusteringvia Pre-trained models (SCP), trains only a small cluster head while leveragingpre-trained vision model feature representations and positive data pairs.Experiments on benchmark datasets including CIFAR-10, CIFAR-20, CIFAR-100,STL-10, ImageNet-10, and ImageNet-Dogs, demonstrate that SCP achieves highlycompetitive performance. Furthermore, we provide a theoretical resultexplaining why, at least under ideal conditions, additional text-basedembeddings may not be necessary to achieve strong clustering performance invision.",Yicen Li,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.LG', 'cs.NE', 'stat.CO', 'stat.ML']"
2502.04225v1,Stochastic SIR model with individual heterogeneity and infection-age dependent infectivity on large non-homogeneous random graphs,http://arxiv.org/abs/2502.04225v1,"We study an individual-based stochastic SIR epidemic model with infection-agedependent infectivity on a large random graph, capturing individualheterogeneity and non-homogeneous connectivity. Each individual is associatedwith particular characteristics (for example, spatial location and agestructure), which may not be i.i.d., and represented by a particular node. Theconnectivities among the individuals are given by a non-homogeneous randomgraph, whose connecting probabilities may depend on the individualcharacteristics of the edge. Each individual is associated with a randomvarying infectivity function, which is also associated with the individualcharacteristics. We use measure-valued processes to describe the epidemicevolution dynamics, tracking the infection age of all individuals, and theirassociated characteristics. We consider the epidemic dynamics as the populationsize grows to infinity under a specific scaling of the connectivity graphrelated to the convergence to a graphon. In the limit, we obtain a system ofmeasure-valued equations, which can be also represented as a PDE model ongraphon, which reflects the heterogeneities in individual characteristics andsocial connectivity.",Guodong Pang,2025-02-06,2025-02-06,,N/A,"['math.PR', '60F17, 05C80, 92D30 (Primary), 60J76, 60G57, 35Q70 (Secondary)']"
2502.04224v1,Provably Robust Explainable Graph Neural Networks against Graph Perturbation Attacks,http://arxiv.org/abs/2502.04224v1,"Explaining Graph Neural Network (XGNN) has gained growing attention tofacilitate the trust of using GNNs, which is the mainstream method to learngraph data. Despite their growing attention, Existing XGNNs focus on improvingthe explanation performance, and its robustness under attacks is largelyunexplored. We noticed that an adversary can slightly perturb the graphstructure such that the explanation result of XGNNs is largely changed. Suchvulnerability of XGNNs could cause serious issues particularly insafety/security-critical applications. In this paper, we take the first step tostudy the robustness of XGNN against graph perturbation attacks, and proposeXGNNCert, the first provably robust XGNN. Particularly, our XGNNCert canprovably ensure the explanation result for a graph under the worst-case graphperturbation attack is close to that without the attack, while not affectingthe GNN prediction, when the number of perturbed edges is bounded. Evaluationresults on multiple graph datasets and GNN explainers show the effectiveness ofXGNNCert.",Jiate Li,2025-02-06,2025-02-06,,N/A,['cs.CR']
2502.04223v1,Éclair -- Extracting Content and Layout with Integrated Reading Order for Documents,http://arxiv.org/abs/2502.04223v1,"Optical Character Recognition (OCR) technology is widely used to extract textfrom images of documents, facilitating efficient digitization and dataretrieval. However, merely extracting text is insufficient when dealing withcomplex documents. Fully comprehending such documents requires an understandingof their structure -- including formatting, formulas, tables, and the readingorder of multiple blocks and columns across multiple pages -- as well assemantic information for detecting elements like footnotes and image captions.This comprehensive understanding is crucial for downstream tasks such asretrieval, document question answering, and data curation for training LargeLanguage Models (LLMs) and Vision Language Models (VLMs). To address this, weintroduce \'Eclair, a general-purpose text-extraction tool specificallydesigned to process a wide range of document types. Given an image, \'Eclair isable to extract formatted text in reading order, along with bounding boxes andtheir corresponding semantic classes. To thoroughly evaluate these novelcapabilities, we introduce our diverse human-annotated benchmark fordocument-level OCR and semantic classification. \'Eclair achievesstate-of-the-art accuracy on this benchmark, outperforming other methods acrosskey metrics. Additionally, we evaluate \'Eclair on established benchmarks,demonstrating its versatility and strength across several evaluation standards.",Ilia Karmanov,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04222v1,Separation Property for the Nonlocal Cahn Hilliard Brinkman System with Singular Potential and Degenerate Mobility,http://arxiv.org/abs/2502.04222v1,"This work studies the nonlocal Cahn Hilliard Brinkman system, which modelsthe phase separation of a binary fluid in a bounded domain and porous media. Wefocus on a system with a singular potential namely logarithmic form and adegenerate mobility function. The singular potential introduces challenges dueto the blow up of its derivatives near pure phases, while the degeneratemobility complicates the analysis. Our main result is the separation property,which ensures that the solution eventually stays away from the pure phases. Weadopt a new method, inspired by the De Giorgi iteration, introduced for the twodimensional Cahn Hilliard equation with constant mobility. This work extendsprevious results and provides a general approach for proving the separationproperty for similar systems.",Sheetal Dharmatti,2025-02-06,2025-02-06,,N/A,"['math.AP', '35B40, 35B45, 35K55, 76S05, 76D99, 76T99']"
2502.04220v1,Dimension estimation in PCA model using high-dimensional data augmentation,http://arxiv.org/abs/2502.04220v1,"We propose a modified, high-dimensional version of a recent dimensionestimation procedure that determines the dimension via the introduction ofaugmented noise variables into the data. Our asymptotic results show that theproposal is consistent in wide high-dimensional scenarios, and further shedlight on why the original method breaks down when the dimension of either thedata or the augmentation becomes too large. Simulations are used to demonstratethe superiority of the proposal to competitors both under and outside of thetheoretical model.",Una Radojicic,2025-02-06,2025-02-06,,N/A,"['math.ST', 'stat.ME', 'stat.TH']"
2502.04219v1,NLP-Based .NET CLR Event Logs Analyzer,http://arxiv.org/abs/2502.04219v1,"In this paper, we present a tool for analyzing .NET CLR event logs based on anovel method inspired by Natural Language Processing (NLP) approach. Ourresearch addresses the growing need for effective monitoring and optimizationof software systems through detailed event log analysis. We utilize aBERT-based architecture with an enhanced tokenization process customized toevent logs. The tool, developed using Python, its libraries, and an SQLitedatabase, allows both conducting experiments for academic purposes andefficiently solving industry-emerging tasks. Our experiments demonstrate theefficacy of our approach in compressing event sequences, detecting recurringpatterns, and identifying anomalies. The trained model shows promising results,with a high accuracy rate in anomaly detection, which demonstrates thepotential of NLP methods to improve the reliability and stability of softwaresystems.",Maxim Stavtsev,2025-02-06,2025-02-06,,N/A,"['cs.SE', 'cs.AI']"
2502.04218v1,Sports and Women's Sports: Gender Bias in Text Generation with Olympic Data,http://arxiv.org/abs/2502.04218v1,"Large Language Models (LLMs) have been shown to be biased in prior work, asthey generate text that is in line with stereotypical views of the world orthat is not representative of the viewpoints and values of historicallymarginalized demographic groups. In this work, we propose using data fromparallel men's and women's events at the Olympic Games to investigate differentforms of gender bias in language models. We define three metrics to measurebias, and find that models are consistently biased against women when thegender is ambiguous in the prompt. In this case, the model frequently retrievesonly the results of the men's event with or without acknowledging them as such,revealing pervasive gender bias in LLMs in the context of athletics.",Laura Biester,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04217v1,Recovering sparse DFT from missing signals via interior point method on GPU,http://arxiv.org/abs/2502.04217v1,"We propose a method to recover the sparse discrete Fourier transform (DFT) ofa signal that is both noisy and potentially incomplete, with missing values.The problem is formulated as a penalized least-squares minimization based onthe inverse discrete Fourier transform (IDFT) with an $\ell_1$-penalty term,reformulated to be solvable using a primal-dual interior point method (IPM).Although Krylov methods are not typically used to solve Karush-Kuhn-Tucker(KKT) systems arising in IPMs due to their ill-conditioning, we employ atailored preconditioner and establish new asymptotic bounds on the conditionnumber of preconditioned KKT matrices. Thanks to this dedicated preconditioner-- and the fact that FFT and IFFT operate as linear operators without requiringexplicit matrix materialization -- KKT systems can be solved efficiently atlarge scales in a matrix-free manner. Numerical results from a Juliaimplementation leveraging GPU-accelerated interior point methods, Krylovmethods, and FFT toolkits demonstrate the scalability of our approach onproblems with hundreds of millions of variables, inclusive of real dataobtained from the diffuse scattering from a slightly disordered MolybdenumVanadium Dioxide crystal.",Wei Kuang,2025-02-06,2025-02-06,,N/A,['math.OC']
2502.04216v1,Resolving shortwave and longwave irradiation distributions across the human body in outdoor built environments,http://arxiv.org/abs/2502.04216v1,"Outdoor built environments can be designed to enhance thermal comfort, yetthe relationship between the two is often assessed in whole-body terms,overlooking the asymmetric nature of thermal interactions between the humanbody and its surroundings. Moreover, the radiative component of heatexchange-dominant in hot and dry climates-is typically lumped into a singleartificial metric, the mean radiant temperature, rather than being resolvedinto its shortwave and longwave spectral components. The shortwave irradiationdistribution on the human body is often highly anisotropic, causing localizedthermal discomfort in outdoor environments. However, no existing methodseffectively quantify shortwave and longwave irradiation distributions on thehuman body. To address this gap, we developed two methods to quantify theseprocesses. The first approach uses an outdoor thermal manikin with awhite-coated side, enabling the separation of spectral components bysubtracting measurements from symmetrically corresponding surface zones of tancolor. The second hybrid approach converts radiometer measurements in sixdirections into boundary conditions for computational thermal manikinsimulations. We evaluated irradiation distributions for various body partsusing both methods during outdoor measurements across sunny, partially shaded,and fully shaded sites under warm to extremely hot conditions. In most cases,the two methods produced closely aligned results, with divergences highlightingtheir respective strengths and limitations. Additionally, we used the manikinto quantify irradiation attenuation provided by five long-sleeve shirts withcolors ranging from white to black. These advanced methods can be integratedwith airflow and thermoregulatory modeling to optimize outdoor builtenvironments for enhanced human thermal comfort.",Kambiz Sadeghi,2025-02-06,2025-02-06,,N/A,['physics.bio-ph']
2502.04212v1,The DESI 2024 hint for dynamical dark energy is biased by low-redshift supernovae,http://arxiv.org/abs/2502.04212v1,"Recently, a $\sim3.9\sigma$ preference for dynamical dark energy from theDark Energy Spectroscopic Instrument (DESI) collaboration inspired hot debateson new physics or systematics. In this letter, we reveal this significantpreference is dominated by an external low-redshift supernova (low-$z$ SN)sample that combines with the Dark Energy Survey SN program (DES-SN) in theirYear 5 data release (DESY5). Further implementing the $a_B$ (the intercept ofthe SN magnitude-redshift relation) diagnosis between low-$z$ and DES-SNsamples, we find large dispersions in the low-$z$ SN sample with a $\sim0.043$magnitude discrepancy in $-5a_B$ from the high-$z$ DES-SN sample, suggestingpotential systematics in DESY5. Correcting for this low-$z$ systematics ordirectly ignoring the low-$z$ sample can largely reduce the preference fordynamical DE to be $<2\sigma$. Therefore, the DESI preference for dynamical DEmight be a mirage of low-$z$ SN systematics with a mismatch intercept. Ouradditional test demonstrates the currently available data cannot providedecisive evidence for dynamical DE.",Lu Huang,2025-02-06,2025-02-06,,N/A,['astro-ph.CO']
2502.04211v1,Exploring the limits of nucleonic metamodelling using different relativistic density functionals,http://arxiv.org/abs/2502.04211v1,"In this work, we explore two classes of density dependent relativisticmean-field models, their predictions of proton fractions at high densities andneutron star structure. We have used a metamodelling approach to theserelativistic density functionals. We have generated a large ensemble of modelswith these classes and then applied constraints from theoretical andexperimental nuclear physics and astrophysical observations. We find that bothmodels produce similar equations of state and neutron star mass-radiussequences. But, their underlying compositions, denoted by the proton fractionin this case, are vastly different. This reinstates previous findings thatinformation on composition gets masqueraded in $\beta$-equilibrium. Additionalobservations of non-equilibrium phenomena are necessary to pin it down.",Prasanta Char,2025-02-06,2025-02-06,,N/A,"['nucl-th', 'astro-ph.HE']"
2502.04210v1,Algorithmic causal structure emerging through compression,http://arxiv.org/abs/2502.04210v1,"We explore the relationship between causality, symmetry, and compression. Webuild on and generalize the known connection between learning and compressionto a setting where causal models are not identifiable. We propose a frameworkwhere causality emerges as a consequence of compressing data across multipleenvironments. We define algorithmic causality as an alternative definition ofcausality when traditional assumptions for causal identifiability do not hold.We demonstrate how algorithmic causal and symmetric structures can emerge fromminimizing upper bounds on Kolmogorov complexity, without knowledge ofintervention targets. We hypothesize that these insights may also provide anovel perspective on the emergence of causality in machine learning models,such as large language models, where causal relationships may not be explicitlyidentifiable.",Liang Wendong,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI', 'cs.CC', 'cs.IT', 'math.IT']"
2502.04209v1,Radon Removal in XENONnT down to the Solar Neutrino Level,http://arxiv.org/abs/2502.04209v1,"The XENONnT experiment has achieved an unprecedented reduction of the$^\text{222}$Rn activity concentration within its liquid xenon dual-phase timeprojection chamber to a level of (0.90$\,\pm\,$0.01$\,$stat.$\,\pm\,$0.07sys.)$\,\mu$Bq/kg, equivalent to about 1200 $^\text{222}$Rn atoms per cubicmeter of liquid xenon. This represents a 15-fold improvement over the$^\text{222}$Rn levels encountered during XENON1T's main science runs and is afactor five lower compared to other currently operational multi-tonne liquidxenon detectors engaged in dark matter searches. This breakthrough enables thepursuit of various rare event searches that lie beyond the confines of thestandard model of particle physics, with world-leading sensitivity. Theultra-low $^\text{222}$Rn levels have diminished the radon-induced backgroundrate in the detector to a point where it is for the first time lower than thesolar neutrino-induced background, which is poised to become the primaryirreducible background in liquid xenon-based detectors.",E. Aprile,2025-02-06,2025-02-06,,N/A,"['physics.ins-det', 'hep-ex']"
2502.04206v1,Ensuring Reliability via Hyperparameter Selection: Review and Advances,http://arxiv.org/abs/2502.04206v1,"Hyperparameter selection is a critical step in the deployment of artificialintelligence (AI) models, particularly in the current era of foundational,pre-trained, models. By framing hyperparameter selection as a multiplehypothesis testing problem, recent research has shown that it is possible toprovide statistical guarantees on population risk measures attained by theselected hyperparameter. This paper reviews the Learn-Then-Test (LTT)framework, which formalizes this approach, and explores several extensionstailored to engineering-relevant scenarios. These extensions encompassdifferent risk measures and statistical guarantees, multi-objectiveoptimization, the incorporation of prior knowledge and dependency structuresinto the hyperparameter selection process, as well as adaptivity. The paperalso includes illustrative applications for communication systems.",Amirmohammad Farzaneh,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.IT', 'math.IT']"
2502.04205v1,Beyond 2050: From deployment to renewal of the global solar PV system,http://arxiv.org/abs/2502.04205v1,"The global energy transition relies heavily on the large-scale deployment ofPV capacity with deployment targets typically defined for 2050. However,sustaining the PV system beyond 2050 will require continuous renewal. Thisresearch explores the overlooked industrial transition from the initialimplementation phase to the long-term renewal phase, emphasizing theconsequences of this dynamic shift. Using streamlined modelling we estimate theannual production needed to both expand and maintain the global PV system. Ourresults indicate that PV panel production dynamics during this transition arevery sensitive to two key factors: deployment speed and panel lifespan. Ifdeployment occurs over a shorter period than the average panel lifespan,production initially overshoots and exhibits an endogenous damped oscillatorybehavior due to a succession of installation and replacement cycles.Conversely, if deployment is more gradual, production increases smoothly beforestabilizing at the renewal rate. Given the current deployment scenarios andlifespan estimates, the PV industry is likely to face significant productiondamped oscillations, up to 60%. These oscillations, corresponding toover/underproduction, are further amplified by the increasingly ambitiousenergy transition targets, which accelerate deployment rates. Panel lifespanconversly remains a less flexible parameter. This study discusses oscillationsfrom a systemic perspective and how they could exacerbate challenges for thelong-term sustainability of PV, including industrial, workforce, economic andgeopolitical dimensions. Beyond the case of PV, this study underscores abroader issue in the energy transition: the shift from infrastructure expansionto long-term maintenance through renewal. Addressing this often-overlookedphase is essential for ensuring the sustainability of renewable energy systemsbeyond 2050.",Joseph Le Bihan,2025-02-06,2025-02-06,,N/A,"['physics.soc-ph', '93-10, 91B74']"
2502.04204v1,"""Short-length"" Adversarial Training Helps LLMs Defend ""Long-length"" Jailbreak Attacks: Theoretical and Empirical Evidence",http://arxiv.org/abs/2502.04204v1,"Jailbreak attacks against large language models (LLMs) aim to induce harmfulbehaviors in LLMs through carefully crafted adversarial prompts. To mitigateattacks, one way is to perform adversarial training (AT)-based alignment, i.e.,training LLMs on some of the most adversarial prompts to help them learn how tobehave safely under attacks. During AT, the length of adversarial prompts playsa critical role in the robustness of aligned LLMs. This paper focuses onadversarial suffix jailbreak attacks and unveils that to defend against ajailbreak attack with an adversarial suffix of length $\Theta(M)$, it is enoughto align LLMs on prompts with adversarial suffixes of length$\Theta(\sqrt{M})$. Theoretically, we analyze the adversarial in-contextlearning of linear transformers on linear regression tasks and prove a robustgeneralization bound for trained transformers. The bound depends on the term$\Theta(\sqrt{M_{\text{test}}}/M_{\text{train}})$, where $M_{\text{train}}$ and$M_{\text{test}}$ are the number of adversarially perturbed in-context samplesduring training and testing. Empirically, we conduct AT on popular open-sourceLLMs and evaluate their robustness against jailbreak attacks of differentadversarial suffix lengths. Results confirm a positive correlation between theattack success rate and the ratio of the square root of the adversarial suffixduring jailbreaking to the length during AT. Our findings show that it ispractical to defend ""long-length"" jailbreak attacks via efficient""short-length"" AT. The code is available at https://github.com/fshp971/adv-icl.",Shaopeng Fu,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.CR', 'stat.ML']"
2502.04203v1,Large Negative Magnetoresistance in off-Stochiometric Topological Material PrSbTe,http://arxiv.org/abs/2502.04203v1,"Magnetic topological materials LnSbTe (Ln = lanthanide) have attractedintensive attention because of the presence of interplay between magnetism,topological, and electron correlations depending on the choices of magnetic Lnelements. Varying Sb and Te composition is an efficient approach to controlstructural, magnetic, and electronic properties. Here we report thecomposition-dependent properties in PrSbxTe2-x. We identified thetetragonal-to-orthorhombic structure transitions in this material system, andvery large negative magnetoresistance in the x = 0.3 composition, which mightbe ascribed to the coupling between magnetism and transport. Such unusualmagnetotransport enables PrSbxTe2-x topological materials as a promisingplatform for device applications.",Gokul Acharya,2025-02-06,2025-02-06,,N/A,['cond-mat.mtrl-sci']
2502.04200v1,Characterizing Bugs in Login Processes of Android Applications: An Empirical Study,http://arxiv.org/abs/2502.04200v1,"The login functionality, being the gateway to app usage, plays a criticalrole in both user experience and application security. As Android appsincreasingly incorporate login functionalities, they support a variety ofauthentication methods with complicated login processes, catering topersonalized user experiences. However, the complexities in managing differentoperations in login processes make it difficult for developers to handle themcorrectly. In this paper, we present the first empirical study of login issuesin Android apps. We analyze 361 issues from 44 popular open-source Androidrepositories, examining the root causes, symptoms, and trigger conditions ofthese issues. Our findings indicate that the vast majority of the login issuesare induced by the improper handling of complex state transitions during thelogin process, which can prevent users from logging in or misdirect them toincorrect subsequent actions. Additionally, we observed that issues related tothis cause typically require the convergence of multiple trigger conditions tomanifest. These findings can help developers to model the login processes whichcan help them to identify the causes of issues and design targeted test casesand precise test oracles. Our dataset has been made openly available tofacilitate future research in this area.",Zixu Zhou,2025-02-06,2025-02-06,,N/A,['cs.SE']
2502.04199v1,Expanding Training Data for Endoscopic Phenotyping of Eosinophilic Esophagitis,http://arxiv.org/abs/2502.04199v1,"Eosinophilic esophagitis (EoE) is a chronic esophageal disorder marked byeosinophil-dominated inflammation. Diagnosing EoE usually involves endoscopicinspection of the esophageal mucosa and obtaining esophageal biopsies forhistologic confirmation. Recent advances have seen AI-assisted endoscopicimaging, guided by the EREFS system, emerge as a potential alternative toreduce reliance on invasive histological assessments. Despite theseadvancements, significant challenges persist due to the limited availability ofdata for training AI models - a common issue even in the development of AI formore prevalent diseases. This study seeks to improve the performance of deeplearning-based EoE phenotype classification by augmenting our training datawith a diverse set of images from online platforms, public datasets, andelectronic textbooks increasing our dataset from 435 to 7050 images. Weutilized the Data-efficient Image Transformer for image classification andincorporated attention map visualizations to boost interpretability. Thefindings show that our expanded dataset and model enhancements improveddiagnostic accuracy, robustness, and comprehensive analysis, enhancing patientoutcomes.",Juming Xiong,2025-02-06,2025-02-06,,N/A,"['eess.IV', 'cs.CV']"
2502.04195v1,Integration of Prior Knowledge into Direct Learning for Safe Control of Linear Systems,http://arxiv.org/abs/2502.04195v1,"This paper integrates prior knowledge into direct learning of safecontrollers for linear uncertain systems under disturbances. To this end, wecharacterize the set of all closed-loop systems that can be explained byavailable prior knowledge of the system model and the disturbances. We leveragematrix zonotopes for data-based characterization of closed-loop systems andshow that the explainability of closed-loop systems by prior knowledge can beformalized by adding an equality conformity constraint to the matrix zonotope.We then leverage the resulting constraint matrix zonotope and design safecontrollers that conform with both data and prior knowledge. This is achievedby ensuring the inclusion of a constrained zonotope of all possible next statesin a {\lambda}-scaled level set of the safe set. We consider both polytope andzonotope safe sets and provide set inclusion conditions using linearprogramming.",Amir Modares,2025-02-06,2025-02-06,,N/A,"['eess.SY', 'cs.SY']"
2502.04194v1,The Best Instruction-Tuning Data are Those That Fit,http://arxiv.org/abs/2502.04194v1,"High-quality supervised fine-tuning (SFT) data are crucial for elicitingstrong capabilities from pretrained large language models (LLMs). Typically,instructions are paired with multiple responses sampled from other LLMs, whichare often out of the distribution of the target model to be fine-tuned. This,at scale, can lead to diminishing returns and even hurt the models' performanceand robustness. We propose **GRAPE**, a novel SFT framework that accounts forthe unique characteristics of the target model. For each instruction, itgathers responses from various LLMs and selects the one with the highestprobability measured by the target model, indicating that it aligns mostclosely with the target model's pretrained distribution; it then proceeds withstandard SFT training.  We first evaluate GRAPE with a controlled experiment, where we sample varioussolutions for each question in UltraInteract from multiple models and fine-tunecommonly used LMs like LLaMA3.1-8B, Mistral-7B, and Qwen2.5-7B onGRAPE-selected data. GRAPE significantly outperforms strong baselines,including distilling from the strongest model with an absolute gain of up to13.8%, averaged across benchmarks, and training on 3x more data with a maximumperformance improvement of 17.3%. GRAPE's strong performance generalizes torealistic settings. We experiment with the post-training data used for Tulu3and Olmo-2. GRAPE outperforms strong baselines trained on 4.5 times more databy 6.1% and a state-of-the-art data selection approach by 3% on averageperformance. Remarkably, using 1/3 of the data and half the number of epochs,GRAPE enables LLaMA3.1-8B to surpass the performance of Tulu3-SFT by 3.5%.",Dylan Zhang,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI', 'cs.LG']"
2502.04192v1,PixFoundation: Are We Heading in the Right Direction with Pixel-level Vision Foundation Models?,http://arxiv.org/abs/2502.04192v1,"Multiple works have emerged to push the boundaries on multi-modal largelanguage models (MLLMs) towards pixel-level understanding. Such approaches haveshown strong performance on benchmarks for referring expression segmentationand grounded conversation generation. The current trend in pixel-level MLLMs isto train with pixel-level grounding supervision on large-scale labelled data.However, we show that such MLLMs when evaluated on recent challenging visioncentric benchmarks, exhibit a weak ability in visual question answering.Surprisingly, some of these methods even downgrade the grounding ability ofMLLMs that were never trained with such supervision. In this work, we proposetwo novel challenging benchmarks and show that MLLMs without pixel-levelgrounding supervision can outperform the state of the art in such tasks whenevaluating both the pixel-level grounding and visual question answering. Wepropose simple baselines to extract the grounding information that can beplugged into any MLLM, which we call as PixFoundation. More importantly, westudy the research question of ``When does grounding emerge in MLLMs that arenot trained with pixel-level grounding supervision?'' We show that groundingcan coincide with object parts or location/appearance information. Coderepository is at https://github.com/MSiam/PixFoundation/.",Mennatullah Siam,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04191v1,Systematic Analysis of $B_s \to SP$ Decays in Perturbative QCD Approach,http://arxiv.org/abs/2502.04191v1,"Within the perturbative QCD (PQCD) framework, we present a systematicinvestigation of charmless $B_s \to SP$ decays, where $S$ and $P$ denote scalarand pseudoscalar mesons, respectively. By employing two distinct structuralscenarios for scalar mesons, we calculate the branching fractions and direct$CP$ asymmetries for these processes. Our results reveal branching fractionsranging from $10^{-7}$ to $10^{-5}$, values that are well within the measurablerange of current experiments. A striking contrast emerges between penguin- andtree-dominated decays: while penguin-dominated processes yield larger branchingfractions, tree-dominated decays exhibit significantly enhanced direct $CP$asymmetries. In particular, the decays $B_s \to f_0(1370) \eta$ and $B_s \toa_0(1450) K$ demonstrate marked sensitivity to the choice of scalar mesonscenario, offering critical constraints for identifying the optimal model onceexperimental data are available. Furthermore, we calculate the branchingfractions of $B_s \to f_0(980)(\sigma)P$ decays in two distinct ranges of themixing angle of $f_0(980)-\sigma$. The dependencies of both branching fractionsand $CP$ asymmetries on this mixing angle are rigorously analyzed, establishinga framework essential for determining its value with future experimentalresults. These findings provide a robust theoretical foundation for advancingthe understanding of nonleptonic $B_s$decays in QCD-based formalisms, as wellas the nature of scalar mesons.",Zhi-Tian Zou,2025-02-06,2025-02-06,,N/A,"['hep-ph', 'hep-ex']"
2502.04188v1,Automated Microservice Pattern Instance Detection Using Infrastructure-as-Code Artifacts and Large Language Models,http://arxiv.org/abs/2502.04188v1,"Documenting software architecture is essential to preserve architectureknowledge, even though it is frequently costly. Architecture pattern instances,including microservice pattern instances, provide important structural softwareinformation. Practitioners should document this information to preventknowledge vaporization. However, architecture patterns may not be detectable byanalyzing source code artifacts, requiring the analysis of other types ofartifacts. Moreover, many existing pattern detection instance approaches arecomplex to extend. This article presents our ongoing PhD research, earlyexperiments, and a prototype for a tool we call MicroPAD for automating thedetection of microservice pattern instances. The prototype uses Large LanguageModels (LLMs) to analyze Infrastructure-as-Code (IaC) artifacts to aiddetection, aiming to keep costs low and maximize the scope of detectablepatterns. Early experiments ran the prototype thrice in 22 GitHub projects. Weverified that 83\% of the patterns that the prototype identified were in theproject. The costs of detecting the pattern instances were minimal. Theseresults indicate that the approach is likely viable and, by lowering the entrybarrier to automating pattern instance detection, could help democratizedeveloper access to this category of architecture knowledge. Finally, wepresent our overall research methodology, planned future work, and an overviewof MicroPAD's potential industrial impact.",Carlos Eduardo Duarte,2025-02-06,2025-02-06,,N/A,"['cs.SE', 'D.2.11']"
2502.04186v1,Model-based reconstruction of real-world fractal complex networks,http://arxiv.org/abs/2502.04186v1,"This paper presents a versatile model for generating fractal complex networksthat closely mirror the properties of real-world systems. By combining featuresof reverse renormalization and evolving network models, the proposed approachintroduces several tunable parameters, offering exceptional flexibility incapturing the diverse topologies and scaling behaviors found in both naturaland man-made networks. The model effectively replicates their keycharacteristics such as fractal dimensions, power-law degree distributions, anddensities. Unlike traditional deterministic models, it incorporatesstochasticity into the network growth process, overcoming limitations likediscontinuities in degree distributions and rigid size constraints. The model'sapplicability is demonstrated through its ability to reproduce the structuralfeatures of real-world fractal networks, including the Internet, the World WideWeb, and co-authorship networks.",Kordian Makulski,2025-02-06,2025-02-06,,N/A,"['physics.soc-ph', 'cond-mat.dis-nn']"
2502.04182v1,Fast In-Spectrum Graph Watermarks,http://arxiv.org/abs/2502.04182v1,"We address the problem of watermarking graph objects, which consists inhiding information within them, to prove their origin. The two existing methodsto watermark graphs use subgraph matching or graph isomorphism techniques,which are known to be intractable for large graphs. To reduce the operationalcomplexity, we propose FFG, a new graph watermarking scheme adapted from animage watermarking scheme, since graphs and images can be represented asmatrices. We analyze and compare FFG, whose novelty lies in embedding thewatermark in the Fourier transform of the adjacency matrix of a graph. Ourtechnique enjoys a much lower complexity than that of related works (i.e. in$\mathcal{O}\left(N^2 \log N\right)$), while performing better or at least aswell as the two state-of-the-art methods.",Jade Garcia Bourrée,2025-02-06,2025-02-06,,N/A,['cs.DS']
2502.04180v1,Multi-agent Architecture Search via Agentic Supernet,http://arxiv.org/abs/2502.04180v1,"Large Language Model (LLM)-empowered multi-agent systems extend the cognitiveboundaries of individual agents through disciplined collaboration andinteraction, while constructing these systems often requires labor-intensivemanual designs. Despite the availability of methods to automate the design ofagentic workflows, they typically seek to identify a static, complex,one-size-fits-all system, which, however, fails to dynamically allocateinference resources based on the difficulty and domain of each query. Toaddress this challenge, we shift away from the pursuit of a monolithic agenticsystem, instead optimizing the \textbf{agentic supernet}, a probabilistic andcontinuous distribution of agentic architectures. We introduce MaAS, anautomated framework that samples query-dependent agentic systems from thesupernet, delivering high-quality solutions and tailored resource allocation(\textit{e.g.}, LLM calls, tool calls, token cost). Comprehensive evaluationacross six benchmarks demonstrates that MaAS \textbf{(I)} requires only$6\sim45\%$ of the inference costs of existing handcrafted or automatedmulti-agent systems, \textbf{(II)} surpasses them by $0.54\%\sim11.82\%$, and\textbf{(III)} enjoys superior cross-dataset and cross-LLM-backbonetransferability.",Guibin Zhang,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.CL', 'cs.MA']"
2502.04179v1,The Maximum Likelihood Degree of Gumbel's Type-I Bivariate Exponential Distribution,http://arxiv.org/abs/2502.04179v1,"In algebraic statistics, the maximum likelihood degree of a statistical modelrefers to the number of solutions (counted with multiplicity) of the scoreequations over the complex field. In this paper, the maximum likelihood degreeof the association parameter of Gumbels Type-I bivariate exponentialdistribution is investigated using algebraic techniques.",Pooja Yadav,2025-02-06,2025-02-06,,N/A,"['math.ST', 'math.AC', 'stat.TH']"
2502.04176v1,MRAMG-Bench: A BeyondText Benchmark for Multimodal Retrieval-Augmented Multimodal Generation,http://arxiv.org/abs/2502.04176v1,"Recent advancements in Retrieval-Augmented Generation (RAG) have shownremarkable performance in enhancing response accuracy and relevance byintegrating external knowledge into generative models. However, existing RAGmethods primarily focus on providing text-only answers, even in multimodalretrieval-augmented generation scenarios. In this work, we introduce theMultimodal Retrieval-Augmented Multimodal Generation (MRAMG) task, which aimsto generate answers that combine both text and images, fully leveraging themultimodal data within a corpus. Despite the importance of this task, there isa notable absence of a comprehensive benchmark to effectively evaluate MRAMGperformance. To bridge this gap, we introduce the MRAMG-Bench, a carefullycurated, human-annotated dataset comprising 4,346 documents, 14,190 images, and4,800 QA pairs, sourced from three categories: Web Data, Academic Papers, andLifestyle. The dataset incorporates diverse difficulty levels and complexmulti-image scenarios, providing a robust foundation for evaluating multimodalgeneration tasks. To facilitate rigorous evaluation, our MRAMG-Benchincorporates a comprehensive suite of both statistical and LLM-based metrics,enabling a thorough analysis of the performance of popular generative models inthe MRAMG task. Besides, we propose an efficient multimodal answer generationframework that leverages both LLMs and MLLMs to generate multimodal responses.Our datasets are available at: https://huggingface.co/MRAMG.",Qinhan Yu,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.IR']"
2502.04174v1,Dense Fixed-Wing Swarming using Receding-Horizon NMPC,http://arxiv.org/abs/2502.04174v1,"In this paper, we present an approach for controlling a team of agilefixed-wing aerial vehicles in close proximity to one another. Our approachrelies on receding-horizon nonlinear model predictive control (NMPC) to planmaneuvers across an expanded flight envelope to enable inter-agent collisionavoidance. To facilitate robust collision avoidance and characterize thelikelihood of inter-agent collisions, we compute a statistical bound on theprobability of the system leaving a tube around the planned nominal trajectory.Finally, we propose a metric for evaluating highly dynamic swarms and use thismetric to evaluate our approach. We successfully demonstrated our approachthrough both simulation and hardware experiments, and to our knowledge, thisthe first time close-quarters swarming has been achieved with physicalaerobatic fixed-wing vehicles.",Varun Madabushi,2025-02-06,2025-02-06,,N/A,"['cs.RO', 'cs.SY', 'eess.SY']"
2502.04173v1,Lexical Substitution is not Synonym Substitution: On the Importance of Producing Contextually Relevant Word Substitutes,http://arxiv.org/abs/2502.04173v1,"Lexical Substitution is the task of replacing a single word in a sentencewith a similar one. This should ideally be one that is not necessarily onlysynonymous, but also fits well into the surrounding context of the target word,while preserving the sentence's grammatical structure. Recent advances inLexical Substitution have leveraged the masked token prediction task ofPre-trained Language Models to generate replacements for a given word in asentence. With this technique, we introduce ConCat, a simple augmented approachwhich utilizes the original sentence to bolster contextual information sent tothe model. Compared to existing approaches, it proves to be very effective inguiding the model to make contextually relevant predictions for the targetword. Our study includes a quantitative evaluation, measured via sentencesimilarity and task performance. In addition, we conduct a qualitative humananalysis to validate that users prefer the substitutions proposed by ourmethod, as opposed to previous methods. Finally, we test our approach on theprevailing benchmark for Lexical Substitution, CoInCo, revealing potentialpitfalls of the benchmark. These insights serve as the foundation for acritical discussion on the way in which Lexical Substitution is evaluated.",Juraj Vladika,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04171v1,Cyclic functional causal models beyond unique solvability with a graph separation theorem,http://arxiv.org/abs/2502.04171v1,"Functional causal models (fCMs) specify functional dependencies betweenrandom variables associated to the vertices of a graph. In directed acyclicgraphs (DAGs), fCMs are well-understood: a unique probability distribution onthe random variables can be easily specified, and a crucial graph-separationresult called the d-separation theorem allows one to characterize conditionalindependences between the variables. However, fCMs on cyclic graphs posechallenges due to the absence of a systematic way to assign a uniqueprobability distribution to the fCM's variables, the failure of thed-separation theorem, and lack of a generalization of this theorem that isapplicable to all consistent cyclic fCMs. In this work, we develop a causalmodeling framework applicable to all cyclic fCMs involving finite-cardinalityvariables, except inconsistent ones admitting no solutions. Our probabilityrule assigns a unique distribution even to non-uniquely solvable cyclic fCMsand reduces to the known rule for uniquely solvable fCMs. We identify a classof fCMs, called averagely uniquely solvable, that we show to be the largestclass where the probabilities admit a Markov factorization. Furthermore, weintroduce a new graph-separation property, p-separation, and prove this to besound and complete for all consistent finite-cardinality cyclic fCMs whilerecovering the d-separation theorem for DAGs. These results are obtained byconsidering classical post-selected teleportation protocols inspired byanalogous protocols in quantum information theory. We discuss further avenuesfor exploration, linking in particular problems in cyclic fCMs and in quantumcausality.",Carla Ferradini,2025-02-06,2025-02-06,,N/A,"['math.ST', 'quant-ph', 'stat.ML', 'stat.TH']"
2502.04169v1,The Effects of Kinematic MHD on the Atmospheric Circulation of Eccentric Hot Jupiters,http://arxiv.org/abs/2502.04169v1,"Hot Jupiters are typically considered to be tidally locked due to their shortorbital periods. The extreme irradiation can result in atmospheric speciesbecoming thermally ionized on the dayside, which then interact with theplanet's magnetic field by resisting flow across magnetic field lines, shapingthe atmospheric structure. However, an eccentric orbit results in temporallydependent irradiation and a non-permanent dayside, as the planet-star distancecan change drastically during its orbit. In this paper, we present 3Datmospheric models of TOI-150b, an eccentric (e=0.26), Jupiter-mass 1.75 M_Jupplanet whose equilibrium temperature varies from 1300K to 1700K. We conductsimulations for magnetic field strengths ranging from 0-30 Gauss using thekinematic magnetohydrodynamics (MHD) approach. When compared to simulations ofthe planet assuming a circular orbit, we find that the eccentric orbit resultsin a strengthened and narrowed equatorial jet, westward winds at mid-latitudes,and a phase-dependent thermal inversion. The strength and magnitude of theseeffects scale with the chosen global magnetic field strength. We also generatehigh-resolution (R=100,000) emission spectra to study net Doppler shifts andfind inter-orbit spectroscopic variability at moderate magnetic fieldstrengths, as well as decreased Doppler broadening as magnetic field strengthsincrease. This work represents the first time that the kinematic MHD approachhas been applied to an eccentric hot Jupiter and highlights the importance of alocally calculated, temperature dependent magnetic drag prescription forpredicting atmospheric structure and resulting spectra.",Hayley Beltz,2025-02-06,2025-02-06,,N/A,['astro-ph.EP']
2502.04168v1,Cyclic quantum causal modelling with a graph separation theorem,http://arxiv.org/abs/2502.04168v1,"Causal modelling frameworks link observable correlations to causalexplanations, which is a crucial aspect of science. These models representcausal relationships through directed graphs, with vertices and edges denotingsystems and transformations within a theory. Most studies focus on acycliccausal graphs, where well-defined probability rules and powerfulgraph-theoretic properties like the d-separation theorem apply. However,understanding complex feedback processes and exotic fundamental scenarios withcausal loops requires cyclic causal models, where such results do not generallyhold. While progress has been made in classical cyclic causal models,challenges remain in uniquely fixing probability distributions and identifyinggraph-separation properties applicable in general cyclic models. In cyclicquantum scenarios, existing frameworks have focussed on a subset of possiblecyclic causal scenarios, with graph-separation properties yet unexplored. Thiswork proposes a framework applicable to all consistent quantum and classicalcyclic causal models on finite-dimensional systems. We address these challengesby introducing a robust probability rule and a novel graph-separation property,p-separation, which we prove to be sound and complete for all such models. Ourapproach maps cyclic causal models to acyclic ones with post-selection,leveraging the post-selected quantum teleportation protocol. We characterizethese protocols and their success probabilities along the way. We alsoestablish connections between this formalism and other classical and quantumframeworks to inform a more unified perspective on causality. This provides afoundation for more general cyclic causal discovery algorithms and tosystematically extend open problems and techniques from acyclic informationalnetworks (e.g., certification of non-classicality) to cyclic causal structuresand networks.",Carla Ferradini,2025-02-06,2025-02-06,,N/A,"['quant-ph', 'math.ST', 'stat.ML', 'stat.TH']"
2502.04165v1,Continuously varying critical exponents in an exactly solvable long-range cluster XY mode,http://arxiv.org/abs/2502.04165v1,"We investigate a generalized antiferromagnetic cluster XY model in atransverse magnetic field, where long-range interactions decay algebraicallywith distance. This model can be exactly solvable within a free fermionframework. By analyzing the gap, we explicitly derive the critical exponents$\nu$ and $z$, finding that the relationship $\nu z = 1$ still holds. However,the values of $\nu$ and $z$ depend on the decaying exponent $\alpha$, incontrast to those for the quantum long-range antiferromagnetic Ising chain. Tooptimize scaling behavior, we verify these critical exponents using correlationfunctions and fidelity susceptibility, achieving excellent data collapse acrossvarious system sizes by adjusting fitting parameters. Finally, we compute theentanglement entropy at the critical point to determine the central charge $c$,and find it also varies with $\alpha$. This study provides insights into theunique effect of long-range cluster interactions on the critical properties ofquantum spin systems.",Tian-Cheng Yi,2025-02-06,2025-02-06,,N/A,"['cond-mat.str-el', 'cond-mat.stat-mech']"
2502.04164v1,Efficient Distributed Optimization under Heavy-Tailed Noise,http://arxiv.org/abs/2502.04164v1,"Distributed optimization has become the default training paradigm in modernmachine learning due to the growing scale of models and datasets. To mitigatecommunication overhead, local updates are often applied before globalaggregation, resulting in a nested optimization approach with inner and outersteps. However, heavy-tailed stochastic gradient noise remains a significantchallenge, particularly in attention-based models, hindering effectivetraining. In this work, we propose TailOPT, an efficient framework designed toaddress heavy-tailed noise by leveraging adaptive optimization or clippingtechniques. We establish convergence guarantees for the TailOPT framework underheavy-tailed noise with potentially unbounded gradient variance and localupdates. Among its variants, we highlight a memory and communication efficientinstantiation which we call $Bi^2Clip$, which performs coordinate-wise clippingat both the inner and outer optimizers, achieving adaptive-like performance(e.g., Adam) without the cost of maintaining or transmitting additionalgradient statistics. Empirically, TailOPT, including $Bi^2Clip$, demonstratessuperior performance on several language tasks and models, outperformingstate-of-the-art methods.",Su Hyeong Lee,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04162v1,A Pseudo Markov-Chain Model and Time-Elapsed Measures of Mobility from Collective Data,http://arxiv.org/abs/2502.04162v1,"In this paper we develop a pseudo Markov-chain model to understandtime-elapsed flows, over multiple intervals, from time and space aggregatedcollective inter-location trip data, given as a time-series. Building on themodel, we develop measures of mobility that parallel those known for individualmobility data, such as the radius of gyration. We apply these measures to theNetMob 2024 Data Challenge data, and obtain interesting results that areconsistent with published statistics and commuting patterns in cities. Besidesbuilding a new framework, we foresee applications of this approach to animproved understanding of human mobility in the context of environmentalchanges and sustainable development.",Alisha Foster,2025-02-06,2025-02-06,,N/A,"['stat.AP', 'cs.LG', 'cs.SI', 'stat.ML', '60J20, 91D10']"
2502.04160v1,Lotka-Volterra-type kinetic equations for competing species,http://arxiv.org/abs/2502.04160v1,"In this work, we examine a kinetic framework for modeling the time evolutionof size distribution densities of two populations governed by predator-preyinteractions. The model builds upon the classical Boltzmann-type equations,where the dynamics arise from elementary binary interactions between thepopulations. The model uniquely incorporates a linear redistribution operatorto quantify the birth rates in both populations, inspired by wealthredistribution operators. We prove that, under a suitable scaling regime, theBoltzmann formulation transitions to a system of coupled Fokker-Planck-typeequations. These equations describe the evolution of the distribution densitiesand link the macroscopic dynamics of their mean values to a Lotka-Volterrasystem of ordinary differential equations, with parameters explicitly derivedfrom the microscopic interaction rules. We then determine the local equilibriaof the Fokker-Planck system, which are Gamma-type densities, and investigatethe problem of relaxation of its solutions toward these kinetic equilibria, interms of their moments' dynamics. The results establish a bridge betweenkinetic modeling and classical population dynamics, offering a multiscaleperspective on predator-prey systems.",Andrea Bondesan,2025-02-06,2025-02-06,,N/A,"['math.AP', 'nlin.AO', 'q-bio.PE', '35Q20, 35Q84, 92D25']"
2502.04158v1,Diffusion-based mass map reconstruction from weak lensing data,http://arxiv.org/abs/2502.04158v1,"Diffusion models have been used in cosmological applications as a generativemodel for fast simulations and to reconstruct underlying cosmological fields orastrophysical images from noisy data. These two tasks are often treated asseparate: diffusion models trained for one purpose do not generalize to performthe other task. In this paper, we develop a single diffusion model that can beused for both tasks. By using the Diffusion Posterior Sampling (DPS) approach,we use a diffusion model trained to simulate weak lensing maps for the inverseproblem of reconstructing mass maps from noisy weak lensing data. We find thatthe standard DPS method leads to biased inference but we correct this bias bydown weighting the likelihood term at early sampling time steps of thediffusion. Our method give us a way to reconstruct accurate high-resolution(sub-arcminute) mass maps that have the correct power spectrum and a range ofnon-Gaussian summary statistics. We discuss several applications enabled by thecomputational efficiency and accuracy of our model. These include generation ofsimulation quality mass maps, aiding covariance estimation for higher orderstatistics, and for finding filaments, voids and clusters from noisy lensingshear data.",Supranta S. Boruah,2025-02-06,2025-02-06,,N/A,"['astro-ph.CO', 'astro-ph.IM']"
2502.04157v1,Sensor Resistant Instruction Independent Obfuscation for Multiple Programs,http://arxiv.org/abs/2502.04157v1,"This work builds upon and optimizes our prior research on obfuscation asinstruction decorrelation which achieves multiple program obfuscation.Leveraging this infrastructure, we further achieve the property ofsensor-resistant computation.",Ali Ajorian,2025-02-06,2025-02-06,,N/A,"['cs.CR', 'cs.PL']"
2502.04156v1,Estimation of backgrounds from jets misidentified as $τ$-leptons using the Universal Fake Factor method with the ATLAS detector,http://arxiv.org/abs/2502.04156v1,"Processes with $\tau$-leptons in the final state are important for StandardModel measurements and searches for physics beyond the Standard Model. TheATLAS experiment at the Large Hadron Collider observes $\tau$-leptons producedin proton-proton collisions only through their decay products. Data analysesinvolving hadronically decaying $\tau$-leptons face challenges due tobackgrounds from jets misidentified as $\tau$-leptons. These fake$\tau$-leptons are not modelled reliably by Monte Carlo simulations.Data-driven methods such as the fake-factor method allow such 'fake'backgrounds to be predicted by measuring transfer factors, known as fakefactors, in data from control regions. This paper describes a new technique fordetermining the fake factors, the Universal Fake Factor method. It evaluatesthe fake factors for any signal region by using fake factors from samplesenriched in different sources of fake $\tau$-leptons (light-quark, gluon,$b$-quark, and pile-up jets). Each fake factor is calculated as a linearcombination of fake factors measured in these different enriched samples. Forthe full Run 2 data set, the systematic uncertainty of the calculated fakefactors ranges from 15% to 35% depending on the $\tau$-lepton's transversemomentum and charged-particle decay multiplicity.",ATLAS Collaboration,2025-02-06,2025-02-06,,N/A,['hep-ex']
2502.04155v1,User-Friendly Game-Theoretic Modeling and Analysis of Multi-Modal Transportation Systems,http://arxiv.org/abs/2502.04155v1,"The evolution of existing transportation systems, mainly driven byurbanization and increased availability of mobility options, such as private,profit-maximizing ride-hailing companies, calls for tools to reason about theirdesign and regulation. To study this complex socio-technical problem, one needsto account for the strategic interactions of the stakeholders involved in themobility ecosystem. In this paper, we present a game-theoretic framework tomodel multi-modal mobility systems, focusing on municipalities, serviceproviders, and travelers. Through a user-friendly, Graphical User Interface,one can visualize system dynamics and compute equilibria for various scenarios.The framework enables stakeholders to assess the impact of local decisions(e.g., fleet size for services or taxes for private companies) on the fullmobility system. Furthermore, this project aims to foster STEM interest amonghigh school students (e.g., in the context of prior activities in Switzerland,and planned activities with the MIT museum). This initiative combinestheoretical advancements, practical applications, and educational outreach toimprove mobility system design.",Margarita Zambrano,2025-02-06,2025-02-06,,N/A,"['cs.CY', 'math.OC']"
2502.04154v1,Searching for Internal Absorption Signatures in High-Redshift Blazars,http://arxiv.org/abs/2502.04154v1,"The gamma-ray emission from Flat Spectrum Radio Quasars (FSRQs), a sub-classof blazars, is believed to be generated through interactions of high-energyleptons and/or hadrons in the jet with the ambient photon fields, includingthose from the accretion disk, the broad line region (BLR), and the dustytorus. However, these same photon fields can also attenuate gamma-rays throughinternal photon-photon (gamma-gamma) absorption, imprinting characteristicspectral features. Investigating the internal absorption is crucial forunraveling the complex structure of FSRQs and constraining the poorly knownlocation of the gamma-ray emission region. In this study, we select a sample ofgamma-ray detected FSRQs with high redshift (z >= 3), to search for absorptionfeatures appearing at lower photon energies due to a substantial redshift. Weextract the Fermi-LAT gamma-ray spectra of these sources and perform physicalmodeling using a detailed gamma-gamma opacity model, assuming that the BLRphoton field dominates the absorption and focusing on the energy range ~25GeV/(1+z), where the absorption feature due to Ly{\alpha} photons is expected.Our analysis reveals a hint of internal absorption for one source (the lowestredshift object in our sample, z~3) and provides constraints on the location ofits gamma-ray emitting region along the jet. For the remaining, higher-redshiftsources, the limited photon statistics prevent a reliable detection of internalopacity features.",Anton Dmytriiev,2025-02-06,2025-02-06,,N/A,['astro-ph.HE']
2502.04153v1,UltraIF: Advancing Instruction Following from the Wild,http://arxiv.org/abs/2502.04153v1,"Instruction-following made modern large language models (LLMs) helpfulassistants. However, the key to taming LLMs on complex instructions remainsmysterious, for that there are huge gaps between models trained by open-sourcecommunity and those trained by leading companies. To bridge the gap, we proposea simple and scalable approach UltraIF for building LLMs that can followcomplex instructions with open-source data. UltraIF first decomposes real-worlduser prompts into simpler queries, constraints, and corresponding evaluationquestions for the constraints. Then, we train an UltraComposer to composeconstraint-associated prompts with evaluation questions. This prompt composerallows us to synthesize complicated instructions as well as filter responseswith evaluation questions. In our experiment, for the first time, wesuccessfully align LLaMA-3.1-8B-Base to catch up with its instruct version on 5instruction-following benchmarks without any benchmark information, using only8B model as response generator and evaluator. The aligned model also achievedcompetitive scores on other benchmarks. Moreover, we also show that UltraIFcould further improve LLaMA-3.1-8B-Instruct through self-alignment, motivatingbroader use cases for the method. Our code will be available athttps://github.com/kkk-an/UltraIF.",Kaikai An,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.04150v1,How large are the gaps in phase space?,http://arxiv.org/abs/2502.04150v1,"Given a sampling measure for the wavelet transform (resp. the short-timeFourier transform) with the wavelet (resp. window) being chosen from the familyof Laguerre (resp. Hermite) functions, we provide quantitative upper bounds onthe radius of any ball that does not intersect the support of the measure. Theestimates depend on the condition number, i.e., the ratio of the samplingconstants, but are independent of the structure of the measure. Our proofs arecompletely elementary and rely on explicit formulas for the respectivetransforms.",Michael Speckbacher,2025-02-06,2025-02-06,,N/A,['math.FA']
2502.04147v1,SPRINT: An Assistant for Issue Report Management,http://arxiv.org/abs/2502.04147v1,"Managing issue reports is essential for the evolution and maintenance ofsoftware systems. However, manual issue management tasks such as triaging,prioritizing, localizing, and resolving issues are highly resource-intensivefor projects with large codebases and users. To address this challenge, wepresent SPRINT, a GitHub application that utilizes state-of-the-art deeplearning techniques to streamline issue management tasks. SPRINT assistsdevelopers by: (i) identifying existing issues similar to newly reported ones,(ii) predicting issue severity, and (iii) suggesting code files that likelyrequire modification to solve the issues. We evaluated SPRINT using existingdatasets and methodologies, measuring its predictive performance, and conducteda user study with five professional developers to assess its usability andusefulness. The results show that SPRINT is accurate, usable, and useful,providing evidence of its effectiveness in assisting developers in managingissue reports. SPRINT is an open-source tool available athttps://github.com/sea-lab-wm/sprint.",Ahmed Adnan,2025-02-06,2025-02-06,,N/A,['cs.SE']
2502.04143v1,A data-driven two-microphone method for in-situ sound absorption measurements,http://arxiv.org/abs/2502.04143v1,"This work presents a data-driven approach to estimating the sound absorptioncoefficient of an infinite porous slab using a neural network and atwo-microphone measurement on a finite porous sample. A 1D-convolutionalnetwork predicts the sound absorption coefficient from the complex-valuedtransfer function between the sound pressure measured at the two microphonepositions. The network is trained and validated with numerical data generatedby a boundary element model using the Delany-Bazley-Miki model, demonstratingaccurate predictions for various numerical samples. The method isexperimentally validated with baffled rectangular samples of a fibrousmaterial, where sample size and source height are varied. The results show thatthe neural network offers the possibility to reliably predict the in-situ soundabsorption of a porous material using the traditional two-microphone method asif the sample were infinite. The normal-incidence sound absorption coefficientobtained by the network compares well with that obtained theoretically and inan impedance tube. The proposed method has promising perspectives forestimating the sound absorption coefficient of acoustic materials afterinstallation and in realistic operational conditions.",Leon Emmerich,2025-02-06,2025-02-06,,N/A,"['cs.SD', 'cs.LG', 'eess.AS']"
2502.04140v1,Synthetic Datasets for Machine Learning on Spatio-Temporal Graphs using PDEs,http://arxiv.org/abs/2502.04140v1,"Many physical processes can be expressed through partial differentialequations (PDEs). Real-world measurements of such processes are often collectedat irregularly distributed points in space, which can be effectivelyrepresented as graphs; however, there are currently only a few existingdatasets. Our work aims to make advancements in the field of PDE-modelingaccessible to the temporal graph machine learning community, while addressingthe data scarcity problem, by creating and utilizing datasets based on PDEs. Inthis work, we create and use synthetic datasets based on PDEs to supportspatio-temporal graph modeling in machine learning for different applications.More precisely, we showcase three equations to model different types ofdisasters and hazards in the fields of epidemiology, atmospheric particles, andtsunami waves. Further, we show how such created datasets can be used bybenchmarking several machine learning models on the epidemiological dataset.Additionally, we show how pre-training on this dataset can improve modelperformance on real-world epidemiological data. The presented methods enableothers to create datasets and benchmarks customized to individual requirements.The source code for our methodology and the three created datasets can be foundon https://github.com/github-usr-ano/Temporal_Graph_Data_PDEs.",Jost Arndt,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI']"
2502.04134v1,The Order Effect: Investigating Prompt Sensitivity in Closed-Source LLMs,http://arxiv.org/abs/2502.04134v1,"As large language models (LLMs) become integral to diverse applications,ensuring their reliability under varying input conditions is crucial. One keyissue affecting this reliability is order sensitivity, wherein slightvariations in input arrangement can lead to inconsistent or biased outputs.Although recent advances have reduced this sensitivity, the problem remainsunresolved. This paper investigates the extent of order sensitivity inclosed-source LLMs by conducting experiments across multiple tasks, includingparaphrasing, relevance judgment, and multiple-choice questions. Our resultsshow that input order significantly affects performance across tasks, withshuffled inputs leading to measurable declines in output accuracy. Few-shotprompting demonstrates mixed effectiveness and offers partial mitigation,however, fails to fully resolve the problem. These findings highlightpersistent risks, particularly in high-stakes applications, and point to theneed for more robust LLMs or improved input-handling techniques in futuredevelopment.",Bryan Guan,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04132v1,Transfer Learning for Covert Speech Classification Using EEG Hilbert Envelope and Temporal Fine Structure,http://arxiv.org/abs/2502.04132v1,"Brain-Computer Interfaces (BCIs) can decode imagined speech from neuralactivity. However, these systems typically require extensive training sessionswhere participants imaginedly repeat words, leading to mental fatigue anddifficulties identifying the onset of words, especially when imaginingsequences of words. This paper addresses these challenges by transferring aclassifier trained in overt speech data to covert speech classification. Weused electroencephalogram (EEG) features derived from the Hilbert envelope andtemporal fine structure, and used them to train a bidirectional long-short-termmemory (BiLSTM) model for classification. Our method reduces the burden ofextensive training and achieves state-of-the-art classification accuracy:86.44% for overt speech and 79.82% for covert speech using the overt speechclassifier.",Saravanakumar Duraisamy,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04131v1,On the importance of structural identifiability for machine learning with partially observed dynamical systems,http://arxiv.org/abs/2502.04131v1,"The successful application of modern machine learning for time seriesclassification is often hampered by limitations in quality and quantity ofavailable training data. To overcome these limitations, available domain expertknowledge in the form of parametrised mechanistic dynamical models can be usedwhenever it is available and time series observations may be represented as anelement from a given class of parametrised dynamical models. This makes thelearning process interpretable and allows the modeller to deal with sparselyand irregularly sampled data in a natural way. However, the internal processesof a dynamical model are often only partially observed. This can lead toambiguity regarding which particular model realization best explains a giventime series observation. This problem is well-known in the literature, and adynamical model with this issue is referred to as structurally unidentifiable.Training a classifier that incorporates knowledge about a structurallyunidentifiable dynamical model can negatively influence classificationperformance. To address this issue, we employ structural identifiabilityanalysis to explicitly relate parameter configurations that are associated withidentical system outputs. Using the derived relations in classifier training,we demonstrate that this method significantly improves the classifier's abilityto generalize to unseen data on a number of example models from the biomedicaldomain. This effect is especially pronounced when the number of traininginstances is limited. Our results demonstrate the importance of accounting forstructural identifiability, a topic that has received relatively littleattention from the machine learning community.",Janis Norden,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04129v1,Discontinuous transition in 2D Potts: I. Order-Disorder Interface convergence,http://arxiv.org/abs/2502.04129v1,"It is known that the planar q-state Potts model undergoes a discontinuousphase transition when q > 4 and there are exactly q + 1 extremal Gibbs measuresat the transition point: q ordered (monochromatic) measures and one disordered(free). We focus on the Potts model under the Dobrushin order-disorder boundaryconditions on a finite $N\times N$ part of the square grid. Our main result isthat this interface is a well defined object, has $\sqrt{N}$ fluctuations, andconverges to a Brownian bridge under diffusive scaling. The same holds also forthe corresponding FK-percolation model for all q > 4. Our proofs rely on acoupling between FK-percolation, the six-vertex model, and the random-clusterrepresentation of an Ashkin-Teller model (ATRC), and on a detailed study of thelatter. The coupling relates the interface in FK-percolation to a longsubcritical cluster in the ATRC model. For this cluster, we develop a ``renewalpicture'' \`a la Ornstein-Zernike. This is based on fine mixing properties ofthe ATRC model that we establish using the link to the six-vertex model and itsheight function. Along the way, we derive various properties of theAshkin-Teller model, such as Ornstein-Zernike asymptotics for its two-pointfunction. In a companion work, we provide a detailed study of the Potts modelunder order-order Dobrushin conditions. We show emergence of a free layer ofwidth $\sqrt{N}$ between the two ordered phases (wetting) and establishconvergence of its boundaries to two Brownian bridges conditioned not tointersect.",Moritz Dober,2025-02-06,2025-02-06,,N/A,"['math.PR', 'math-ph', 'math.MP']"
2502.04128v1,Llasa: Scaling Train-Time and Inference-Time Compute for Llama-based Speech Synthesis,http://arxiv.org/abs/2502.04128v1,"Recent advances in text-based large language models (LLMs), particularly inthe GPT series and the o1 model, have demonstrated the effectiveness of scalingboth training-time and inference-time compute. However, currentstate-of-the-art TTS systems leveraging LLMs are often multi-stage, requiringseparate models (e.g., diffusion models after LLM), complicating the decisionof whether to scale a particular model during training or testing. This workmakes the following contributions: First, we explore the scaling of train-timeand inference-time compute for speech synthesis. Second, we propose a simpleframework Llasa for speech synthesis that employs a single-layer vectorquantizer (VQ) codec and a single Transformer architecture to fully align withstandard LLMs such as Llama. Our experiments reveal that scaling train-timecompute for Llasa consistently improves the naturalness of synthesized speechand enables the generation of more complex and accurate prosody patterns.Furthermore, from the perspective of scaling inference-time compute, we employspeech understanding models as verifiers during the search, finding thatscaling inference-time compute shifts the sampling modes toward the preferencesof specific verifiers, thereby improving emotional expressiveness, timbreconsistency, and content accuracy. In addition, we released the checkpoint andtraining code for our TTS model (1B, 3B, 8B) and codec model publiclyavailable.",Zhen Ye,2025-02-06,2025-02-06,,N/A,"['eess.AS', 'cs.AI', 'cs.CL', 'cs.MM', 'cs.SD']"
2502.04121v1,Optimizing Perturbations for Improved Training of Machine Learning Models,http://arxiv.org/abs/2502.04121v1,"Machine learning models have become indispensable tools in applicationsacross the physical sciences. Their training is often time-consuming, vastlyexceeding the inference timescales. Several protocols have been developed toperturb the learning process and improve the training, such as shrink andperturb, warm restarts, and stochastic resetting. For classifiers, theseperturbations have been shown to result in enhanced speedups or improvedgeneralization. However, the design of such perturbations is usually done\textit{ad hoc} by intuition and trial and error. To rationally optimizetraining protocols, we frame them as first-passage processes and consider theirresponse to perturbations. We show that if the unperturbed learning processreaches a quasi-steady state, the response at a single perturbation frequencycan predict the behavior at a wide range of frequencies. We demonstrate thatthis is the case when training a CIFAR-10 classifier using the ResNet-18 modeland use this approach to identify an optimal perturbation and frequency. Ourwork allows optimization of training protocols of machine learning models usinga statistical mechanical approach.",Sagi Meir,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'physics.chem-ph']"
2502.04117v1,A new perspective on the equivalence between Weak and Strong Spatial Mixing in two dimensions,http://arxiv.org/abs/2502.04117v1,"Weak mixing in lattice models is informally the property that ``informationdoes not propagate inside a system''. Strong mixing is the property that``information does not propagate inside and on the boundary of a system''. Indimension two, the boundary of reasonable systems is one dimensional, soinformation should not be able to propagate there. This led to the conjecturethat in 2D, weak mixing implies strong mixing. The question was investigated inseveral previous works, and proof of this conjecture is available in the caseof finite range Gibbsian specifications, and in the case of nearest-neighbourFK percolation (under some restrictions). The present work gives a new proof ofthese results, extends the family of models for which the implication holds,and, most interestingly, provides a ``percolative picture'' of the informationpropagation.",Sébastien Ott,2025-02-06,2025-02-06,,N/A,"['math.PR', 'math-ph', 'math.MP']"
2502.04116v1,Generative Adversarial Networks Bridging Art and Machine Intelligence,http://arxiv.org/abs/2502.04116v1,"This book begins with a detailed introduction to the fundamental principlesand historical development of GANs, contrasting them with traditionalgenerative models and elucidating the core adversarial mechanisms throughillustrative Python examples. The text systematically addresses themathematical and theoretical underpinnings including probability theory,statistics, and game theory providing a solid framework for understanding theobjectives, loss functions, and optimisation challenges inherent to GANtraining. Subsequent chapters review classic variants such as Conditional GANs,DCGANs, InfoGAN, and LAPGAN before progressing to advanced trainingmethodologies like Wasserstein GANs, GANs with gradient penalty, least squaresGANs, and spectral normalisation techniques. The book further examinesarchitectural enhancements and task-specific adaptations in generators anddiscriminators, showcasing practical implementations in high resolution imagegeneration, artistic style transfer, video synthesis, text to image generationand other multimedia applications. The concluding sections offer insights intoemerging research trends, including self-attention mechanisms,transformer-based generative models, and a comparative analysis with diffusionmodels, thus charting promising directions for future developments in bothacademic and applied settings.",Junhao Song,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.CV']"
2502.04115v1,A Neural Network-based Multi-timestep Command Governor for Nonlinear Systems with Constraints,http://arxiv.org/abs/2502.04115v1,"The multi-timestep command governor (MCG) is an add-on algorithm thatenforces constraints by modifying, at each timestep, the reference command to apre-stabilized control system. The MCG can be interpreted as a Model-PredictiveControl scheme operating on the reference command. The implementation of MCG onnonlinear systems carries a heavy computational burden as it requires solving anonlinear program with multiple decision variables at each timestep. This paperproposes a less computationally demanding alternative, based on approximatingthe MCG control law using a neural network (NN) trained on offline data.However, since the NN output may not always be constraint-admissible due totraining errors, its output is adjusted using a sensitivity-based method. Wethus refer to the resulting control strategy as the neural network-based MCG(NN-MCG). As validation, the proposed controller is applied as a load governorfor constraint management in an automotive fuel cell system. It is shown thatthe proposed strategy is significantly more computationally efficient than thetraditional MCG, while achieving nearly identical performance if the NN iswell-trained.",Mostafaali Ayubirad,2025-02-06,2025-02-06,,N/A,"['eess.SY', 'cs.SY']"
2502.04112v1,Quasi maximum likelihood estimation of high-dimensional approximate dynamic matrix factor models via the EM algorithm,http://arxiv.org/abs/2502.04112v1,"This paper considers an approximate dynamic matrix factor model that accountsfor the time series nature of the data by explicitly modelling the timeevolution of the factors. We study Quasi Maximum Likelihood estimation of themodel parameters based on the Expectation Maximization (EM) algorithm,implemented jointly with the Kalman smoother which gives estimates of thefactors. This approach allows to easily handle arbitrary patterns of missingdata. We establish the consistency of the estimated loadings and factormatrices as the sample size $T$ and the matrix dimensions $p_1$ and $p_2$diverge to infinity. The finite sample properties of the estimators areassessed through a large simulation study and an application to a financialdataset of volatility proxies.",Matteo Barigozzi,2025-02-06,2025-02-06,,N/A,"['stat.ME', 'econ.EM']"
2502.04111v1,Adaptive Margin Contrastive Learning for Ambiguity-aware 3D Semantic Segmentation,http://arxiv.org/abs/2502.04111v1,"In this paper, we propose an adaptive margin contrastive learning method for3D point cloud semantic segmentation, namely AMContrast3D. Most existingmethods use equally penalized objectives, which ignore per-point ambiguitiesand less discriminated features stemming from transition regions. However, ashighly ambiguous points may be indistinguishable even for humans, theirmanually annotated labels are less reliable, and hard constraints over thesepoints would lead to sub-optimal models. To address this, we design adaptiveobjectives for individual points based on their ambiguity levels, aiming toensure the correctness of low-ambiguity points while allowing mistakes forhigh-ambiguity points. Specifically, we first estimate ambiguities based onposition embeddings. Then, we develop a margin generator to shift decisionboundaries for contrastive feature embeddings, so margins are narrowed due toincreasing ambiguities with even negative margins for extremely high-ambiguitypoints. Experimental results on large-scale datasets, S3DIS and ScanNet,demonstrate that our method outperforms state-of-the-art methods.",Yang Chen,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04108v1,Can a secluded self-interacting dark sector generate detectable gravitational waves?,http://arxiv.org/abs/2502.04108v1,"In this work we study the possibility to detect the gravitational wavesgenerated by a secluded self-interacting dark sector. ``Secluded'' means thatthe dark sector has almost no portal to the visible sector and thus its entropyis conserved by itself, and ``self-interacting'' means that dark matter in thismodel has a significant interaction to itself, making it consistent with thesmall-scale structure observations. A spontaneously broken $U(1)'$ isintroduced for the interactions in the dark sector, and nearly massless darkradiation is also introduced to avoid the over-closure problem. Through aparameter space scan, we find that this model is highly constrained by thecurrent observed effective number of neutrinos ($N_{\text{eff}}$) and thelarge-scale structure observable Lyman-$\alpha$. Combined together, these twoconstraints make such a secluded self-interacting dark sector almost impossibleto generate gravitational waves accessible at future projects like SKA or LISA.",Song Li,2025-02-06,2025-02-06,,N/A,"['hep-ph', 'astro-ph.HE']"
2502.04106v1,The Gradient Puppeteer: Adversarial Domination in Gradient Leakage Attacks through Model Poisoning,http://arxiv.org/abs/2502.04106v1,"In Federated Learning (FL), clients share gradients with a central serverwhile keeping their data local. However, malicious servers could deliberatelymanipulate the models to reconstruct clients' data from shared gradients,posing significant privacy risks. Although such active gradient leakage attacks(AGLAs) have been widely studied, they suffer from several limitationsincluding incomplete attack coverage and poor stealthiness. In this paper, weaddress these limitations with two core contributions. First, we introduce anew theoretical analysis approach, which uniformly models AGLAs as backdoorpoisoning. This analysis approach reveals that the core principle of AGLAs isto bias the gradient space to prioritize the reconstruction of a small subsetof samples while sacrificing the majority, which theoretically explains theabove limitations of existing AGLAs. Second, we propose Enhanced GradientGlobal Vulnerability (EGGV), the first AGLA that achieves complete attackcoverage while evading client-side detection. In particular, EGGV employs agradient projector and a jointly optimized discriminator to assess gradientvulnerability, steering the gradient space toward the point most prone to dataleakage. Extensive experiments show that EGGV achieves complete attack coverageand surpasses SOTA with at least a 43% increase in reconstruction quality(PSNR) and a 45% improvement in stealthiness (D-SNR).",Kunlan Xiang,2025-02-06,2025-02-06,,N/A,['cs.CR']
2502.04105v1,Sensitivity of three-dimensional boundary-layer stability to intrinsic uncertainties of fluid properties: a study on supercritical CO2,http://arxiv.org/abs/2502.04105v1,"The intrinsic uncertainty of fluid properties, including the equation ofstate, viscosity, and thermal conductivity, on boundary layer stability hasscarcely been addressed. When a fluid is operating in the vicinity of the Widomline (defined as the maximum of isobaric specific heat) in supercritical state,its properties exhibit highly non-ideal behavior, which is an ongoing researchfield leading to refined and more accurate fluid property databases. Uponcrossing the Widom line, new mechanisms of flow instability emerge, feasiblyleading to changes in dominating modes that yield turbulence. The present workinvestigates the sensitivity of three-dimensional boundary-layer modalinstability to these intrinsic uncertainties in fluid properties. Theuncertainty, regardless of its source and the fluid regimes, gives rise todistortions of all profiles that constitute the inputs of the stabilityoperator. The effect of these distortions on flow stability is measured bysensitivity coefficients, which are formulated with the adjoint operator andvalidated against linear modal stability analysis. The results are presentedfor carbon dioxide at a representative supercritical pressure of about 80 bar.The sensitivity to different inputs of the stability operator across variousthermodynamic regimes show an immense range of sensitivity amplitude. Abalancing relationship between the density gradient and its perturbation leadsto a quadratic effect across the Widom line, provoking significant sensitivityto distortions of the second derivative of the pressure with respect to thedensity, $\partial^2 p/\partial \rho^2$. From an application-oriented point ofview, one important question is whether the correct baseflow profiles can bemeaningfully analyzed by the simplified ideal-fluid model...",Jie Ren,2025-02-06,2025-02-06,,N/A,['physics.flu-dyn']
2502.04104v1,Exploring Group Convolutional Networks for Sign Problem Mitigation via Contour Deformation,http://arxiv.org/abs/2502.04104v1,"The sign problem that arises in Hybrid Monte Carlo calculations can bemitigated by deforming the integration manifold. While simple transformationsare highly efficient for simulation, their efficacy systematically decreaseswith decreasing temperature and increasing interaction. Machine learning modelshave demonstrated the ability to push further, but require additionalcomputational effort and upfront training. While neural networks possess thecapacity to learn physical symmetries through proper training, there areanticipated advantages associated with encoding them into the network'sstructure. These include enhanced accuracy, accelerated training, and improvedstability. The objective of the present study is twofold. First, we investigatethe benefits of group convolutional models in comparison to fully connectednetworks, with a specific focus on the effects on the sign problem and oncomputational aspects. Second, we examine their capabilities for transferlearning, demonstrating the ability to further reduce training cost. We performour investigations on the Hubbard model on select low-dimensional systems.",Christoph Gäntgen,2025-02-06,2025-02-06,,N/A,"['cond-mat.dis-nn', 'cond-mat.str-el', 'hep-lat']"
2502.04103v1,VTutor: An Open-Source SDK for Generative AI-Powered Animated Pedagogical Agents with Multi-Media Output,http://arxiv.org/abs/2502.04103v1,"The rapid evolution of large language models (LLMs) has transformedhuman-computer interaction (HCI), but the interaction with LLMs is currentlymainly focused on text-based interactions, while other multi-model approachesremain under-explored. This paper introduces VTutor, an open-source SoftwareDevelopment Kit (SDK) that combines generative AI with advanced animationtechnologies to create engaging, adaptable, and realistic APAs for human-AImulti-media interactions. VTutor leverages LLMs for real-time personalizedfeedback, advanced lip synchronization for natural speech alignment, and WebGLrendering for seamless web integration. Supporting various 2D and 3D charactermodels, VTutor enables researchers and developers to design emotionallyresonant, contextually adaptive learning agents. This toolkit enhances learnerengagement, feedback receptivity, and human-AI interaction while promotingtrustworthy AI principles in education. VTutor sets a new standard fornext-generation APAs, offering an accessible, scalable solution for fosteringmeaningful and immersive human-AI interaction experiences. The VTutor projectis open-sourced and welcomes community-driven contributions and showcases.",Eason Chen,2025-02-06,2025-02-06,,N/A,"['cs.HC', 'cs.AI', 'cs.SE']"
2502.04102v1,Qualitative differences in the robust controllability of model two-qubit systems,http://arxiv.org/abs/2502.04102v1,"The precise implementation and manipulation of quantum gates is key toextracting advantages from future quantum technologies. Achieving this requiresvery accurate control over the quantum system. If one has complete knowledgeabout a Hamiltonian, accurate manipulation of the system is possible. However,in real scenarios, there will often be some uncertainty in the parameters ofthe Hamiltonian, which makes full control of the system either difficult orimpossible. In this paper we consider two model Hamiltonians with a continuousparameter that is partly unknown. We assess robust controllability against thisparameter uncertainty using existing theoretical frameworks and take anumerical route by discretizing the unknown parameter in the cases where wecannot predict controllability. Furthermore, we introduce a penalty term intothe fidelity function to optimize control pulses, enhancing robustness againstthe influence of parameter fluctuations. Within our framework, we analyze thequalitative differences in the robust controllability of the two systems.",Anirban Dey,2025-02-06,2025-02-06,,N/A,['quant-ph']
2502.04099v1,The Cabibbo-favored hadronic weak decays of the $Ξ_c$ in the quark model,http://arxiv.org/abs/2502.04099v1,"The Cabibbo-favored hadronic weak decay of the $\Xi_c^+\to \Xi^0\pi^+$,$\Xi_c^0\to \Xi^-\pi^+$, $\Xi_c^0\to \Xi^0\pi^0$, $\Xi_c^0\to \Xi^0\eta^{(')}$and $\Xi_c^0\to \Xi^+K^-$ are studied in the non-relativistic constituent quarkmodel. By analyzing their decay mechanisms at the quark level we show that thepole terms are essential for understanding the transition dynamics in additionto the usually considered direct meson emission process and color suppressedprocess in the charmed baryon hadronic weak decays. The experimentallymeasurable asymmetry parameters are also predicted in order to further pin downthe decay mechanism.",Peng-Yu Niu,2025-02-06,2025-02-06,,N/A,['hep-ph']
2502.04098v1,Efficient Few-Shot Continual Learning in Vision-Language Models,http://arxiv.org/abs/2502.04098v1,"Vision-language models (VLMs) excel in tasks such as visual questionanswering and image captioning. However, VLMs are often limited by their use ofpretrained image encoders, like CLIP, leading to image understanding errorsthat hinder overall performance. On top of that, real-world applications oftenrequire the model to be continuously adapted as new and often limited datacontinuously arrive. To address this, we propose LoRSU (Low-Rank Adaptationwith Structured Updates), a robust and computationally efficient method forselectively updating image encoders within VLMs. LoRSU introduces structuredand localized parameter updates, effectively correcting performance onpreviously error-prone data while preserving the model's general robustness.Our approach leverages theoretical insights to identify and update only themost critical parameters, achieving significant resource efficiency.Specifically, we demonstrate that LoRSU reduces computational overhead by over25x compared to full VLM updates, without sacrificing performance. Experimentalresults on VQA tasks in the few-shot continual learning setting, validateLoRSU's scalability, efficiency, and effectiveness, making it a compellingsolution for image encoder adaptation in resource-constrained environments.",Aristeidis Panos,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.AI']"
2502.04095v1,LLMs to Support a Domain Specific Knowledge Assistant,http://arxiv.org/abs/2502.04095v1,"This work presents a custom approach to developing a domain specificknowledge assistant for sustainability reporting using the InternationalFinancial Reporting Standards (IFRS). In this domain, there is no publiclyavailable question-answer dataset, which has impeded the development of ahigh-quality chatbot to support companies with IFRS reporting. The two keycontributions of this project therefore are:  (1) A high-quality synthetic question-answer (QA) dataset based on IFRSsustainability standards, created using a novel generation and evaluationpipeline leveraging Large Language Models (LLMs). This comprises 1,063 diverseQA pairs that address a wide spectrum of potential user queries insustainability reporting. Various LLM-based techniques are employed to createthe dataset, including chain-of-thought reasoning and few-shot prompting. Acustom evaluation framework is developed to assess question and answer qualityacross multiple dimensions, including faithfulness, relevance, and domainspecificity. The dataset averages a score range of 8.16 out of 10 on thesemetrics.  (2) Two architectures for question-answering in the sustainability reportingdomain - a RAG pipeline and a fully LLM-based pipeline. The architectures aredeveloped by experimenting, fine-tuning, and training on the QA dataset. Thefinal pipelines feature an LLM fine-tuned on domain specific data and anindustry classification component to improve the handling of complex queries.The RAG architecture achieves an accuracy of 85.32% on single-industry and72.15% on cross-industry multiple-choice questions, outperforming the baselineapproach by 4.67 and 19.21 percentage points, respectively. The LLM-basedpipeline achieves an accuracy of 93.45% on single-industry and 80.30% oncross-industry multiple-choice questions, an improvement of 12.80 and 27.36percentage points over the baseline, respectively.",Maria-Flavia Lovin,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.04094v1,Soft and Highly-Integrated Optical Fiber Bending Sensors for Proprioception in Multi-Material 3D Printed Fingers,http://arxiv.org/abs/2502.04094v1,"Accurate shape sensing, only achievable through distributed proprioception,is a key requirement for closed-loop control of soft robots. Low-cost powerefficient optoelectronic sensors manufactured from flexible materials representa natural choice as they can cope with the large deformations of soft robotswithout loss of performance. However, existing integration approaches arecumbersome and require manual steps and complex assembly. We propose asemi-automated printing process where plastic optical fibers are embedded withreadout electronics in 3D printed flexures. The fibers become locked in placeand the readout electronics remain optically coupled to them while the flexuresundergo large bending deformations, creating a repeatable, monolithicallymanufactured bending transducer with only 10 minutes required in total for themanual embedding steps. We demonstrate the process by manufacturingmulti-material 3D printed fingers and extensively evaluating the performance ofeach proprioceptive joint. The sensors achieve 70% linearity and 4.81{\deg} RMSerror on average. Furthermore, the distributed architecture allows formaintaining an average fingertip position estimation accuracy of 12 mm in thepresence of external static forces. To demonstrate the potential of thedistributed sensor architecture in robotics applications, we build adata-driven model independent of actuation feedback to detect contact withobjects in the environment.",Ellis Capp,2025-02-06,2025-02-06,,N/A,['cs.RO']
2502.04084v1,Modular Units on $X_{1}( p)$ and Quotients of the Cuspidal Group,http://arxiv.org/abs/2502.04084v1,"Modular units are functions on modular curves whose divisors are supported onthe cusps. They form a free abelian group of rank at most one less than thenumber of cusps. In this paper we study the group of modular units on $X_{1}( p)$, with prime level $p \ge 5$. We give an explicit basis for this group andstudy certain rational subgroups of it. We use the basis to numericallyinvestigate the structure of the cuspidal group of $X_{1}( p)$ and its rationalsubgroup. In the later stages of this paper we use our basis to determine aspecific large quotient of the cuspidal group.",Elvira Lupoian,2025-02-06,2025-02-06,,N/A,"['math.NT', '11G16, 11G18']"
2502.04083v1,Automatic quantification of breast cancer biomarkers from multiple 18F-FDG PET image segmentation,http://arxiv.org/abs/2502.04083v1,"Neoadjuvant chemotherapy (NAC) has become a standard clinical practice fortumor downsizing in breast cancer with 18F-FDG Positron Emission Tomography(PET). Our work aims to leverage PET imaging for the segmentation of breastlesions. The focus is on developing an automated system that accuratelysegments primary tumor regions and extracts key biomarkers from these areas toprovide insights into the evolution of breast cancer following the first courseof NAC. 243 baseline 18F-FDG PET scans (PET_Bl) and 180 follow-up 18F-FDG PETscans (PET_Fu) were acquired before and after the first course of NAC,respectively. Firstly, a deep learning-based breast tumor segmentation methodwas developed. The optimal baseline model (model trained on baseline exams) wasfine-tuned on 15 follow-up exams and adapted using active learning to segmenttumor areas in PET_Fu. The pipeline computes biomarkers such as maximumstandardized uptake value (SUVmax), metabolic tumor volume (MTV), and totallesion glycolysis (TLG) to evaluate tumor evolution between PET_Fu and PET_Bl.Quality control measures were employed to exclude aberrant outliers. The nnUNetdeep learning model outperformed in tumor segmentation on PET_Bl, achieved aDice similarity coefficient (DSC) of 0.89 and a Hausdorff distance (HD) of 3.52mm. After fine-tuning, the model demonstrated a DSC of 0.78 and a HD of 4.95 mmon PET_Fu exams. Biomarkers analysis revealed very strong correlations whateverthe biomarker between manually segmented and automatically predicted regions.The significant average decrease of SUVmax, MTV and TLG were 5.22, 11.79 cm3and 19.23 cm3, respectively. The presented approach demonstrates an automatedsystem for breast tumor segmentation from 18F-FDG PET. Thanks to the extractedbiomarkers, our method enables the automatic assessment of cancer progression.",Tewele W. Tareke,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.AI']"
2502.04082v1,Market-based insurance ratemaking: application to pet insurance,http://arxiv.org/abs/2502.04082v1,"This paper introduces a method for pricing insurance policies using marketdata. The approach is designed for scenarios in which the insurance companyseeks to enter a new market, in our case: pet insurance, lacking historicaldata. The methodology involves an iterative two-step process. First, a suitableparameter is proposed to characterize the underlying risk. Second, theresulting pure premium is linked to the observed commercial premium using anisotonic regression model. To validate the method, comprehensive testing isconducted on synthetic data, followed by its application to a dataset of actualpet insurance rates. To facilitate practical implementation, we have developedan R package called IsoPriceR. By addressing the challenge of pricing insurancepolicies in the absence of historical data, this method helps enhance pricingstrategies in emerging markets.",Pierre-Olivier Goffard,2025-02-06,2025-02-06,,N/A,"['stat.AP', '62P05, 91G70, 62F15']"
2502.04077v1,AttentionPredictor: Temporal Pattern Matters for Efficient LLM Inference,http://arxiv.org/abs/2502.04077v1,"With the development of large language models (LLMs), efficient inferencethrough Key-Value (KV) cache compression has attracted considerable attention,especially for long-context generation. To compress the KV cache, recentmethods identify critical KV tokens through heuristic ranking with attentionscores. However, these methods often struggle to accurately determine criticaltokens as they neglect the \textit{temporal patterns} in attention scores,resulting in a noticeable degradation in LLM performance. To address thischallenge, we propose AttentionPredictor, which is the first learning-basedcritical token identification approach. Specifically, AttentionPredictor learnsa lightweight convolution model to capture spatiotemporal patterns and predictthe next-token attention score. An appealing feature of AttentionPredictor isthat it accurately predicts the attention score while consuming negligiblememory. Moreover, we propose a cross-token critical cache prefetching frameworkthat hides the token estimation time overhead to accelerate the decoding stage.By retaining most of the attention information, AttentionPredictor achieves16$\times$ KV cache compression with comparable LLM performance, significantlyoutperforming the state-of-the-art.",Qingyue Yang,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.LG']"
2502.04076v1,Content-Rich AIGC Video Quality Assessment via Intricate Text Alignment and Motion-Aware Consistency,http://arxiv.org/abs/2502.04076v1,"The advent of next-generation video generation models like \textit{Sora}poses challenges for AI-generated content (AIGC) video quality assessment(VQA). These models substantially mitigate flickering artifacts prevalent inprior models, enable longer and complex text prompts and generate longer videoswith intricate, diverse motion patterns. Conventional VQA methods designed forsimple text and basic motion patterns struggle to evaluate these content-richvideos. To this end, we propose \textbf{CRAVE}(\underline{C}ontent-\underline{R}ich \underline{A}IGC \underline{V}ideo\underline{E}valuator), specifically for the evaluation of Sora-era AIGCvideos. CRAVE proposes the multi-granularity text-temporal fusion that alignslong-form complex textual semantics with video dynamics. Additionally, CRAVEleverages the hybrid motion-fidelity modeling to assess temporal artifacts.Furthermore, given the straightforward prompts and content in current AIGC VQAdatasets, we introduce \textbf{CRAVE-DB}, a benchmark featuring content-richvideos from next-generation models paired with elaborate prompts. Extensiveexperiments have shown that the proposed CRAVE achieves excellent results onmultiple AIGC VQA benchmarks, demonstrating a high degree of alignment withhuman perception. All data and code will be publicly available athttps://github.com/littlespray/CRAVE.",Shangkun Sun,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04075v1,Controllable Emotion Generation with Emotion Vectors,http://arxiv.org/abs/2502.04075v1,"In recent years, technologies based on large-scale language models (LLMs)have made remarkable progress in many fields, especially in customer service,content creation, and embodied intelligence, showing broad applicationpotential. However, The LLM's ability to express emotions with proper tone,timing, and in both direct and indirect forms is still insufficient butsignificant. Few works have studied on how to build the controlable emotionalexpression capability of LLMs. In this work, we propose a method for emotionexpression output by LLMs, which is universal, highly flexible, and wellcontrollable proved with the extensive experiments and verifications. Thismethod has broad application prospects in fields involving emotions output byLLMs, such as intelligent customer service, literary creation, and homecompanion robots. The extensive experiments on various LLMs with differentmodel-scales and architectures prove the versatility and the effectiveness ofthe proposed method.",Yurui Dong,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04074v1,3D Prior is All You Need: Cross-Task Few-shot 2D Gaze Estimation,http://arxiv.org/abs/2502.04074v1,"3D and 2D gaze estimation share the fundamental objective of capturing eyemovements but are traditionally treated as two distinct research domains. Inthis paper, we introduce a novel cross-task few-shot 2D gaze estimationapproach, aiming to adapt a pre-trained 3D gaze estimation network for 2D gazeprediction on unseen devices using only a few training images. This task ishighly challenging due to the domain gap between 3D and 2D gaze, unknown screenposes, and limited training data. To address these challenges, we propose anovel framework that bridges the gap between 3D and 2D gaze. Our frameworkcontains a physics-based differentiable projection module with learnableparameters to model screen poses and project 3D gaze into 2D gaze. Theframework is fully differentiable and can integrate into existing 3D gazenetworks without modifying their original architecture. Additionally, weintroduce a dynamic pseudo-labelling strategy for flipped images, which isparticularly challenging for 2D labels due to unknown screen poses. To overcomethis, we reverse the projection process by converting 2D labels to 3D space,where flipping is performed. Notably, this 3D space is not aligned with thecamera coordinate system, so we learn a dynamic transformation matrix tocompensate for this misalignment. We evaluate our method on MPIIGaze, EVE, andGazeCapture datasets, collected respectively on laptops, desktop computers, andmobile devices. The superior performance highlights the effectiveness of ourapproach, and demonstrates its strong potential for real-world applications.",Yihua Cheng,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04073v1,An Empirical Study on the Impact of Code Duplication-aware Refactoring Practices on Quality Metrics,http://arxiv.org/abs/2502.04073v1,"Context: Code refactoring is widely recognized as an essential softwareengineering practice that improves the understandability and maintainability ofsource code. Several studies attempted to detect refactoring activities throughmining software repositories, allowing one to collect, analyze, and getactionable data-driven insights about refactoring practices within softwareprojects. Objective: Our goal is to identify, among the various quality modelspresented in the literature, the ones that align with the developer's vision ofeliminating duplicates of code, when they explicitly mention that they refactorthe code to improve them. Method: We extract a corpus of 332 refactoringcommits applied and documented by developers during their daily changes from128 open-source Java projects. In particular, we extract 32 structural metricsfrom which we identify code duplicate removal commits with their correspondingrefactoring operations, as perceived by software engineers. Thereafter, weempirically analyze the impact of these refactoring operations on a set ofcommon state-of-the-art design quality metrics. Results: The statisticalanalysis of the results obtained shows that (i) some state-of-the-art metricsare capable of capturing the developer's intention of removing codeduplication; and (ii) some metrics are being more emphasized than others. Weconfirm that various structural metrics can effectively represent codeduplication, leading to different impacts on software quality. Some metricscontribute to improvements, while others may lead to degradation. Conclusion:Most of the mapped metrics associated with the main quality attributessuccessfully capture developers' intentions for removing code duplicates, as isevident from the commit messages. However, certain metrics do not fully capturethese intentions",Eman Abdullah AlOmar,2025-02-06,2025-02-06,,N/A,['cs.SE']
2502.04070v1,Performance studies of the CE-65v2 MAPS prototype structure,http://arxiv.org/abs/2502.04070v1,"With the next upgrade of the ALICE inner tracking system (ITS3) as itsprimary focus, a set of small MAPS test structures have been developed in the65 nm TPSCo CMOS process. The CE-65 focuses on the characterisation of theanalogue charge collection properties of this technology. The latest iteration,the CE-65v2, was produced in different processes (Standard, with a low-dosen-type blanket, and blanket with gap between pixels), pixel pitches (15, 18,22.5 $\mu$m) and pixel arrangements (square or staggered). The comparativelylarge pixel array size of $48\times24$ pixels in CE-65v2 allows, among otherbenefits, to study the uniformity of the pixel response.  The CE-65v2 chip was characterised in a test beam at the CERN SPS. A firstanalysis showed that hit efficiencies of $\geq 99\%$ and spatial resolutionbetter than 5 $\mu$m can be achieved for all pitches and process variants. Forthe Standard process, thanks to larger charge sharing, even spatial resolutionsbelow 3 $\mu$m are reached, in line with vertex detector requirements for theFCC-ee.  This contribution further investigates the data collected at the SPS testbeam. Thanks to the large sensor size and efficient data collection, a largeamount of statistics was collected, which allows for detailed in-pixel studiesto see the efficiency and spatial resolution as a function of the hit positionwithin the pixels. Again, different pitches and process variants are compared.",A. Ilg,2025-02-06,2025-02-06,,N/A,"['physics.ins-det', 'hep-ex']"
2502.04066v1,Predicting Large Language Model Capabilities on Closed-Book QA Tasks Using Only Information Available Prior to Training,http://arxiv.org/abs/2502.04066v1,"The GPT-4 technical report from OpenAI suggests that model performance onspecific tasks can be predicted prior to training, though methodologies remainunspecified. This approach is crucial for optimizing resource allocation andensuring data alignment with target tasks. To achieve this vision, we focus onpredicting performance on Closed-book Question Answering (CBQA) tasks, whichare closely tied to pre-training data and knowledge retention. We address threemajor challenges: 1) mastering the entire pre-training process, especially dataconstruction; 2) evaluating a model's knowledge retention; and 3) predictingtask-specific knowledge retention using only information available prior totraining. To tackle these challenges, we pre-train three large language models(i.e., 1.6B, 7B, and 13B) using 560k dollars and 520k GPU hours. We analyze thepre-training data with knowledge triples and assess knowledge retention usingestablished methods. Additionally, we introduce the SMI metric, aninformation-theoretic measure that quantifies the relationship betweenpre-training data, model size, and task-specific knowledge retention. Ourexperiments reveal a strong linear correlation ($\text{R}^2 > 0.84$) betweenthe SMI metric and the model's accuracy on CBQA tasks across models of varyingsizes (i.e., 1.1B, 1.6B, 7B, and 13B). The dataset, model, and code areavailable at https://github.com/yuhui1038/SMI.",Changhao Jiang,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.04065v1,Revisiting convolutive blind source separation for identifying spiking motor neuron activity: From theory to practice,http://arxiv.org/abs/2502.04065v1,"Objective: Identifying the activity of motor neurons (MNs) non-invasively ispossible by decomposing signals from muscles, e.g., surface electromyography(EMG) or ultrasound. The theoretical background of MN identification isconvolutive blind source separation (cBSS), and different algorithms have beendeveloped and validated. Yet, the existence and identifiability of inversesolutions and the corresponding estimation errors are not fully understood.Further, the guidelines for selecting appropriate parameters are often built onempirical observations, limiting the translation to clinical applications andother modalities. Approach: We revisited the cBSS model for MN identification,augmented it with new theoretical insights and derived a framework that canpredict the existence of inverse solutions. This framework allows thequantification of estimation errors due to the imperfect inversion of the motorunit action potentials (MUAP), noise sources, and the ill-conditioning of theinverse problem. To bridge the gap between theory and practice, we usedcomputer simulations. Main results: (1) Increasing the similarity of MUAPs orcorrelation between spike trains increases the bias for detecting highamplitude MUs. (2) The optimal objective function depends on the expected spikeamplitude, spike amplitude statistics and the amplitude of background spikes.(3) There is some wiggle room for MN detection given non-stationary MUAPs. (4)There is no connection between MUAP duration and extension factor, in contrastto previous guidelines. (5) Source quality metrics like the silhouette score(SIL) or the pulse-to-noise ratio (PNR) are highly correlated with a source'sobjective function output. (6) SIL is superior to PNR. Significance: Thesefindings will guide cBSS algorithm developments tailored to MN identificationand clinical application translation.",Thomas Klotz,2025-02-06,2025-02-06,,N/A,"['q-bio.QM', 'q-bio.CB', 'q-bio.NC', 'q-bio.TO']"
2502.04064v1,Inteligencia artificial para la multi-clasificación de fauna en fotografías automáticas utilizadas en investigación científica,http://arxiv.org/abs/2502.04064v1,"The management of natural environments, whether for conservation orproduction, requires a deep understanding of wildlife. The number, location,and behavior of wild animals are among the main subjects of study in ecologyand wildlife research. The use of camera traps offers the opportunity toquickly collect large quantities of photographs that capture wildlife in itsnatural habitat, avoiding factors that could alter their behavior. In Tierradel Fuego, Argentina, research is being conducted on forest use by differentherbivores (guanacos, cows, sheep) to optimize management and protect thesenatural ecosystems. Although camera traps allow for the collection of millionsof images, interpreting such photographs presents a scalability challenge formanual processing. As a result, much of the valuable knowledge stored in thesevast data repositories remains untapped. Neural Networks and Deep Learning areareas of study within Artificial Intelligence. Over the past decade, these twodisciplines have made significant contributions to image recognition on aglobal scale. Ecological and wildlife conservation studies can be combined withthese new technologies to extract important information from the photographsobtained by camera traps, contributing to the understanding of various naturalprocesses and improving the management of the involved wild areas. Our projectaims to develop neural network models to classify animal species in photographstaken with camera traps, addressing large-scale challenges in scientificresearch.",Federico Gonzalez,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04063v1,A Multi-level Compiler Backend for Accelerated Micro-kernels Targeting RISC-V ISA Extensions,http://arxiv.org/abs/2502.04063v1,"High-performance micro-kernels must fully exploit today's diverse andspecialized hardware to deliver peak performance to DNNs. While higher-leveloptimizations for DNNs are offered by numerous compilers (e.g., MLIR, TVM,OpenXLA), performance-critical micro-kernels are left to specialized codegenerators or handwritten assembly. Even though widely-adopted compilers (e.g.,LLVM, GCC) offer tuned backends, their CPU-focused input abstraction,unstructured IR, and general-purpose best-effort design inhibit tailored codegeneration for innovative hardware. We think it is time to widen the classicalhourglass backend and embrace progressive lowering across a diverse set ofstructured abstractions to bring domain-specific code generation to compilerbackends. We demonstrate this concept by implementing a custom backend for aRISC-V-based accelerator with hardware loops and streaming registers,leveraging knowledge about the hardware at levels of abstraction that match itscustom ISA. We use incremental register allocation over structured IRs, whiledropping classical spilling heuristics, and show up to 90% FPU utilizationacross key DNN kernels. By breaking the backend hourglass model, we reopen thepath from domain-specific abstractions to specialized hardware.",Alexandre Lopoukhine,2025-02-06,2025-02-06,,N/A,"['cs.PL', 'D.3.4']"
2502.04059v1,Fundamental Oscillations of Massive Boson Stars and Distinguishability,http://arxiv.org/abs/2502.04059v1,"Massive Boson Stars are self-gravitating configurations of self-interactingscalar fields. The equation of state of massive boson stars and their masses,radii, modeled by a self-interacting scalar field with potential of the form$V(\phi) = \frac{1}{2}m^2|\phi|^2 + \frac{1}{4}\lambda |\phi|^4$ are known tofollow scaling relations. The non-radial fundamental oscillations of suchmassive BSs have been studied only for a few select model parameters so far. Inthis work, we demonstrate for the first time that the $f$-mode characteristicsalso follow a scaling in the strong interaction limit ($\lambda \ggm^2/M_{Pl}^2$). This opens up the outstanding prospect of studying the$f$-modes of massive BSs throughout the scalar DM parameter space. We study theimplications of this finding by carrying out a detailed study of massive BS$f$-modes in a separate work. Here, having introduced this scaling, we use itto compare boson star oscillations with the neutron star and black holequasinormal modes, thus providing a smoking gun for the distinguishability ofBSs using gravitational waves.",Swarnim Shirke,2025-02-06,2025-02-06,,N/A,"['gr-qc', 'astro-ph.HE', 'hep-ph']"
2502.04058v1,Strategic Learning with Local Explanations as Feedback,http://arxiv.org/abs/2502.04058v1,"We investigate algorithmic decision problems where agents can respondstrategically to the decision maker's (DM) models. The demand for clear andactionable explanations from DMs to (potentially strategic) agents continues torise. While prior work often treats explanations as full model disclosures,explanations in practice might convey only partial information, which can leadto misinterpretations and harmful responses. When full disclosure of thepredictive model is neither feasible nor desirable, a key open question is howDMs can use explanations to maximise their utility without compromising agentwelfare. In this work, we explore well-known local and global explanationmethods, and establish a necessary condition to prevent explanations frommisleading agents into self-harming actions. Moreover, with conditionalhomogeneity, we establish that action recommendation (AR)-based explanationsare sufficient for non-harmful responses, akin to the revelation principle ininformation design. To operationalise AR-based explanations, we propose asimple algorithm to jointly optimise the predictive model and AR policy tobalance DM outcomes with agent welfare. Our empirical results demonstrate thebenefits of this approach as a more refined strategy for safe and effectivepartial model disclosure in algorithmic decision-making.",Kiet Q. H. Vo,2025-02-06,2025-02-06,,N/A,['cs.AI']
2502.04057v1,Smart IoT Security: Lightweight Machine Learning Techniques for Multi-Class Attack Detection in IoT Networks,http://arxiv.org/abs/2502.04057v1,"In the growing terrain of the Internet of Things (IoT), it is vital thatnetworks are secure to protect against a range of cyber threats. Based on thestrong machine learning framework, this study proposes novel lightweightensemble approaches for improving multi-class attack detection of IoT devices.Using the large CICIoT 2023 dataset with 34 attack types distributed amongst 10attack categories, we systematically evaluated the performance of a widevariety of modern machine learning methods with the aim of establishing thebest-performing algorithmic choice to secure IoT applications. In particular,we explore approaches based on ML classifiers to tackle the biochargescharacterized by the challenging and heterogeneous nature of attack vectors inIoT environments. The method that performed best was the Decision Tree, with anaccuracy of 99.56% and an F1 score of 99.62%, showing that this model iscapable of accurately and reliably detecting threats.The Random Forest modelwas the next best-performing model with 98.22% and an F1 score of 98.24%,suggesting that ML methods are quite effective in a situation ofhigh-dimensional data. Our results highlight the potential for using MLclassifiers in bolstering security for IoT devices and also serve asmotivations for future investigations targeting scalable, keystroke-basedattack detection systems. We believe that our method provides a new path todevelop complex machine learning algorithms for low-resource IoT devices,balancing both accuracy and time efficiency needs. In summary, thesecontributions enrich the state of the art of the IoT security literature,laying down solid ground and guidelines for the deployment of smart, adaptivesecurity in IoT settings.",Shahran Rahman Alve,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04056v1,TQ-DiT: Efficient Time-Aware Quantization for Diffusion Transformers,http://arxiv.org/abs/2502.04056v1,"Diffusion transformers (DiTs) combine transformer architectures withdiffusion models. However, their computational complexity imposes significantlimitations on real-time applications and sustainability of AI systems. In thisstudy, we aim to enhance the computational efficiency through modelquantization, which represents the weights and activation values with lowerprecision. Multi-region quantization (MRQ) is introduced to address theasymmetric distribution of network values in DiT blocks by allocating twoscaling parameters to sub-regions. Additionally, time-grouping quantization(TGQ) is proposed to reduce quantization error caused by temporal variation inactivations. The experimental results show that the proposed algorithm achievesperformance comparable to the original full-precision model with only a 0.29increase in FID at W8A8. Furthermore, it outperforms other baselines at W6A6,thereby confirming its suitability for low-bit quantization. These resultshighlight the potential of our method to enable efficient real-time generativemodels.",Younghye Hwang,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'eess.SP']"
2502.04055v1,Evaluating Inter-Column Logical Relationships in Synthetic Tabular Data Generation,http://arxiv.org/abs/2502.04055v1,"Current evaluations of synthetic tabular data mainly focus on how well jointdistributions are modeled, often overlooking the assessment of theireffectiveness in preserving realistic event sequences and coherent entityrelationships across columns.This paper proposes three evaluation metricsdesigned to assess the preservation of logical relationships among columns insynthetic tabular data. We validate these metrics by assessing the performanceof both classical and state-of-the-art generation methods on a real-worldindustrial dataset.Experimental results reveal that existing methods often failto rigorously maintain logical consistency (e.g., hierarchical relationships ingeography or organization) and dependencies (e.g., temporal sequences ormathematical relationships), which are crucial for preserving the fine-grainedrealism of real-world tabular data. Building on these insights, this study alsodiscusses possible pathways to better capture logical relationships whilemodeling the distribution of synthetic tabular data.",Yunbo Long,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04054v1,Precision Agriculture Revolution: Integrating Digital Twins and Advanced Crop Recommendation for Optimal Yield,http://arxiv.org/abs/2502.04054v1,"With the help of a digital twin structure, Agriculture 4.0 technologies likeweather APIs (Application programming interface), GPS (Global PositioningSystem) modules, and NPK (Nitrogen, Phosphorus and Potassium) soil sensors andmachine learning recommendation models, we seek to revolutionize agriculturalproduction through this concept. In addition to providing precise crop growthforecasts, the combination of real-time data on soil composition,meteorological dynamics, and geographic coordinates aims to support croprecommendation models and simulate predictive scenarios for improved water andpesticide management.",Sayan Banerjee,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04052v1,Decision Trees That Remember: Gradient-Based Learning of Recurrent Decision Trees with Memory,http://arxiv.org/abs/2502.04052v1,"Neural architectures such as Recurrent Neural Networks (RNNs), Transformers,and State-Space Models have shown great success in handling sequential data bylearning temporal dependencies. Decision Trees (DTs), on the other hand, remaina widely used class of models for structured tabular data but are typically notdesigned to capture sequential patterns directly. Instead, DT-based approachesfor time-series data often rely on feature engineering, such as manuallyincorporating lag features, which can be suboptimal for capturing complextemporal dependencies. To address this limitation, we introduce ReMeDe Trees, anovel recurrent DT architecture that integrates an internal memory mechanism,similar to RNNs, to learn long-term dependencies in sequential data. Our modellearns hard, axis-aligned decision rules for both output generation and stateupdates, optimizing them efficiently via gradient descent. We provide aproof-of-concept study on synthetic benchmarks to demonstrate the effectivenessof our approach.",Sascha Marton,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04053v1,Proof of principle for a light dark matter search with low-energy positron beams at NA64,http://arxiv.org/abs/2502.04053v1,"Thermal light dark matter (LDM) with particle masses in the 1 MeV - 1 GeVrange could successfully explain the observed dark matter abundance as a relicfrom the primordial Universe. In this picture, a new feeble interaction acts asa ""portal"" between the Standard Model and LDM particles, allowing for theexploration of this paradigm at accelerator experiments. In the last years, the""missing energy"" experiment NA64e at CERN SPS (Super Proton Synchrotron) hasset world-leading constraints in the vector-mediated LDM parameter space, byexploiting a 100 GeV electron beam impinging on an electromagnetic calorimeter,acting as an active target. In this paper, we report a detailed description ofthe analysis of a preliminary measurement with a 70 GeV positron beam at NA64e,performed during summer 2023 with an accumulated statistic of 1.6 x 10^10positrons on target. This data set was analyzed with the primary aim ofevaluating the performance of the NA64e detector with a lower energy positronbeam, towards the realization of the post-LS3 program. The analysis results,other than additionally probing unexplored regions in the LDM parameter space,provide valuable information towards the future NA64e positron campaign.",Yu. M. Andreev,2025-02-06,2025-02-06,,N/A,"['hep-ex', 'physics.ins-det']"
2502.04050v1,PartEdit: Fine-Grained Image Editing using Pre-Trained Diffusion Models,http://arxiv.org/abs/2502.04050v1,"We present the first text-based image editing approach for object parts basedon pre-trained diffusion models. Diffusion-based image editing approachescapitalized on the deep understanding of diffusion models of image semantics toperform a variety of edits. However, existing diffusion models lack sufficientunderstanding of many object parts, hindering fine-grained edits requested byusers. To address this, we propose to expand the knowledge of pre-traineddiffusion models to allow them to understand various object parts, enablingthem to perform fine-grained edits. We achieve this by learning special textualtokens that correspond to different object parts through an efficient tokenoptimization process. These tokens are optimized to produce reliablelocalization masks at each inference step to localize the editing region.Leveraging these masks, we design feature-blending and adaptive thresholdingstrategies to execute the edits seamlessly. To evaluate our approach, weestablish a benchmark and an evaluation protocol for part editing. Experimentsshow that our approach outperforms existing editing methods on all metrics andis preferred by users 77-90% of the time in conducted user studies.",Aleksandar Cvejic,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04049v1,Towards Explainable Spoofed Speech Attribution and Detection:a Probabilistic Approach for Characterizing Speech Synthesizer Components,http://arxiv.org/abs/2502.04049v1,"We propose an explainable probabilistic framework for characterizing spoofedspeech by decomposing it into probabilistic attribute embeddings. Unlike rawhigh-dimensional countermeasure embeddings, which lack interpretability, theproposed probabilistic attribute embeddings aim to detect specific speechsynthesizer components, represented through high-level attributes and theircorresponding values. We use these probabilistic embeddings with fourclassifier back-ends to address two downstream tasks: spoofing detection andspoofing attack attribution. The former is the well-known bonafide-spoofdetection task, whereas the latter seeks to identify the source method(generator) of a spoofed utterance. We additionally use Shapley values, awidely used technique in machine learning, to quantify the relativecontribution of each attribute value to the decision-making process in eachtask. Results on the ASVspoof2019 dataset demonstrate the substantial role ofduration and conversion modeling in spoofing detection; and waveform generationand speaker modeling in spoofing attack attribution. In the detection task, theprobabilistic attribute embeddings achieve $99.7\%$ balanced accuracy and$0.22\%$ equal error rate (EER), closely matching the performance of rawembeddings ($99.9\%$ balanced accuracy and $0.22\%$ EER). Similarly, in theattribution task, our embeddings achieve $90.23\%$ balanced accuracy and$2.07\%$ EER, compared to $90.16\%$ and $2.11\%$ with raw embeddings. Theseresults demonstrate that the proposed framework is both inherently explainableby design and capable of achieving performance comparable to raw CM embeddings.",Jagabandhu Mishraa,2025-02-06,2025-02-06,,N/A,['eess.AS']
2502.04048v1,Adaptive Output Feedback MPC with Guaranteed Stability and Robustness,http://arxiv.org/abs/2502.04048v1,"This work proposes an adaptive output feedback model predictive control (MPC)framework for uncertain systems subject to external disturbances. In theabsence of exact knowledge about the plant parameters and complete statemeasurements, the MPC optimization problem is reformulated in terms of theirestimates derived from a suitably designed robust adaptive observer. The MPCroutine returns a homothetic tube for the state estimate trajectory. Sets thatcharacterize the state estimation errors are then added to the homothetic tubesections, resulting in a larger tube containing the true state trajectory. Thetwo-tier tube architecture provides robustness to uncertainties due toimperfect parameter knowledge, external disturbances, and incomplete stateinformation. Additionally, recursive feasibility and robust exponentialstability are guaranteed and validated using a numerical example.",Anchita Dey,2025-02-06,2025-02-06,,N/A,"['eess.SY', 'cs.SY', 'math.OC']"
2502.04047v1,Non-renormalization of the fractional quantum Hall conductivity by interactions,http://arxiv.org/abs/2502.04047v1,"We investigate the theory of the fractional quantum Hall effect (QHE)proposed a long time ago by Lopez and Fradkin \cite{Fradkin1991chern}. Themagnetic fluxes of the statistical gauge field attached to electrons remain atrest in the reference frame moving together with the electron liquid. In thelaboratory reference frame the electric field of the statistical gauge fieldforms and screens the external electric field. The fractional QHE conductivityappears as a consequence of this screening already on the mean field theorylevel. We consider a relativistic extension of the model, and propose analternative description of the fractional QHE based on macroscopic motion ofthe electron liquid within the Zubarev statistical operator approach. It isthis macroscopic motion of electrons which in this pattern gives rise to thefractional QHE. Within this approach we propose the proof to all orders ofperturbation theory that the interaction corrections cannot change the abovementioned mean field theory result for the QHE conductivity.",M. Selch,2025-02-06,2025-02-06,,N/A,['cond-mat.mes-hall']
2502.04043v1,Probe-Free Low-Rank Activation Intervention,http://arxiv.org/abs/2502.04043v1,"Language models (LMs) can produce texts that appear accurate and coherent butcontain untruthful or toxic content. Inference-time interventions that edit thehidden activations have shown promising results in steering the LMs towardsdesirable generations. Existing activation intervention methods often comprisean activation probe to detect undesirable generation, triggering the activationmodification to steer subsequent generation. This paper proposes a probe-freeintervention method FLORAIN for all attention heads in a specific activationlayer. It eliminates the need to train classifiers for probing purposes. Theintervention function is parametrized by a sample-wise nonlinear low-rankmapping, which is trained by minimizing the distance between the modifiedactivations and their projection onto the manifold of desirable content. Underspecific constructions of the manifold and projection distance, we show thatthe intervention strategy can be computed efficiently by solving a smoothoptimization problem. The empirical results, benchmarked on multiple basemodels, demonstrate that FLORAIN consistently outperforms several baselinemethods in enhancing model truthfulness and quality across generation andmultiple-choice tasks.",Chonghe Jiang,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI']"
2502.04042v1,Spontaneous helix formation in polar smectic phase,http://arxiv.org/abs/2502.04042v1,"In soft ferroelectric crystals, the depolarization field can be reduced byperiodic distortion of the polarization direction. In the polar nematic andtilted smectic phases, this process is energetically favorured , as it onlyrequires changes in the director orientation. We demonstrate the spontaneousformation of a helical structure in the proper ferroelectric tilted smectic(SmCTBF) phase, the phase is formed below the heliconical polar nematic (NTBF)phase. The helical pitch in the smectic phase is approximately 600 nm andremains nearly constant across the entire temperature range of the phase. Underweak electric fields, the helix reorients while its structure remains largelyintact; however, in stronger fields, the helix is destroyed as the electricpolarization aligns along the electric field.",Ewa Gorecka,2025-02-06,2025-02-06,,N/A,['cond-mat.soft']
2502.04041v1,$\tt GrayHawk$: A public code for calculating the Gray Body Factors of massless fields around spherically symmetric Black Holes,http://arxiv.org/abs/2502.04041v1,"We introduce and describe $\tt GrayHawk$, a publicly availableMathematica-based tool designed for the efficient computation of gray-bodyfactors for spherically symmetric and asymptotically flat black holes. Thisprogram provides users with a rapid and reliable means to compute gray-bodyfactors for massless fields with spin \(s = 0, 1/2, 1, 2\) in modes specifiedby the angular quantum number \(l\), given a black hole metric and theassociated parameter values. $\tt GrayHawk$ is preloaded with seven differentblack hole metrics, offering immediate applicability to a variety oftheoretical models. Additionally, its modular structure allows users to extendits functionality easily by incorporating alternative metrics orconfigurations. This versatility makes $\tt GrayHawk$ a powerful and adaptableresource for researchers studying black hole physics and Hawking radiation. Thecodes described in this work are publicly available athttps://github.com/marcocalza89/GrayHawk.",Marco Calzá,2025-02-06,2025-02-06,,N/A,"['gr-qc', 'astro-ph.CO', 'astro-ph.IM', 'hep-th']"
2502.04040v1,Leveraging Reasoning with Guidelines to Elicit and Utilize Knowledge for Enhancing Safety Alignment,http://arxiv.org/abs/2502.04040v1,"Training safe LLMs is one of the most critical research challenge. However,the commonly used method, Refusal Training (RT), struggles to generalizeagainst various OOD jailbreaking attacks. Many safety training methods havebeen proposed to address this issue. While they offer valuable insights, we aimto complement this line of research by investigating whether OOD attacks trulyexceed the capability of RT model. Conducting evaluation with BoN, we observesignificant improvements on generalization as N increases. This underscoresthat the model possesses sufficient safety-related latent knowledge, but RTfails to consistently elicit this knowledge when addressing OOD attacks.Further analysis based on domain adaptation reveals that training with directrefusal causes model to rely on superficial shortcuts, resulting in learning ofnon-robust representation mappings. Based on our findings, we propose trainingmodel to perform safety reasoning for each query. Reasoning supervisionencourages model to perform more computations, explicitly eliciting and usinglatent knowledge through reasoning. To achieve this, we synthesize reasoningsupervision based on pre-guidelines, training the model to reason in alignmentwith them, thereby effectively eliciting and utilizing latent knowledge fromdiverse perspectives. Extensive experiments show that our method significantlyimproves generalization performance against OOD attacks.",Haoyu Wang,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI', 'cs.CL']"
2502.04039v1,A Cloud-native Agile approach to cyber platform prototyping and integration for astronomy: the ENGAGE SKA case,http://arxiv.org/abs/2502.04039v1,"The Square Kilometre Array (SKA) Observatory is gearing up the formalconstruction of its two radio interferometers in Australia and South Africaafter the end of design and pre-construction phases. Agile methodologies, theCloud native Computing technologies and the DevOps software ideas areinfluencing the design of compute infrastructures that will be key to reducethe operational costs of SKA while improving the control and monitoring of theSKA antennas and ancillary systems, Correlators, HPC facilities or related datacentre tiered systems. These tools will likely include advanced power meteringtechnologies and efficient distribution automation and Network OperationCentres (NOC). SKA will become the world's largest radio telescope and isexpected to achieve its first science by 2026. To cope with this dimension andcomplexity, a key part of this distributed Observatory is the overall softwarecontrol and monitoring system embodied in the Observatory Management andControl (OMC) and the Services Teams that requires specialized Agile Teams toassist in software and cyber infrastructure building using an Agile developmentenvironment that includes test automation, Continuous Integration, andContinuous Deployment. To manage such a large and distributed machine, theAgile approach was adopted for the core software package of the SKA Telescopeaimed at scheduling observations, controlling their execution, monitoring thetelescope status and ensuring scalability and reliability. Here, we report onthe ENGAGE SKA ciberinfrastructure prototyping support to the SKA AgileSoftware Development Life Cycle (SDLC).",Domingos Barbosa,2025-02-06,2025-02-06,,N/A,"['astro-ph.IM', 'cs.SY', 'eess.SY', 'physics.med-ph']"
2502.04038v1,Simulating the Emergence of Differential Case Marking with Communicating Neural-Network Agents,http://arxiv.org/abs/2502.04038v1,"Differential Case Marking (DCM) refers to the phenomenon where grammaticalcase marking is applied selectively based on semantic, pragmatic, or otherfactors. The emergence of DCM has been studied in artificial language learningexperiments with human participants, which were specifically aimed atdisentangling the effects of learning from those of communication (Smith &Culbertson, 2020). Multi-agent reinforcement learning frameworks based onneural networks have gained significant interest to simulate the emergence ofhuman-like linguistic phenomena. In this study, we employ such a framework inwhich agents first acquire an artificial language before engaging incommunicative interactions, enabling direct comparisons to human result. Usinga very generic communication optimization algorithm and neural-network learnersthat have no prior experience with language or semantic preferences, ourresults demonstrate that learning alone does not lead to DCM, but when agentscommunicate, differential use of markers arises. This supports Smith andCulbertson (2020)'s findings that highlight the critical role of communicationin shaping DCM and showcases the potential of neural-agent models to complementexperimental research on language evolution.",Yuchen Lian,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04037v1,Exploring Imbalanced Annotations for Effective In-Context Learning,http://arxiv.org/abs/2502.04037v1,"Large language models (LLMs) have shown impressive performance on downstreamtasks through in-context learning (ICL), which heavily relies on thedemonstrations selected from annotated datasets. Existing selection methods mayhinge on the distribution of annotated datasets, which can often be long-tailedin real-world scenarios. In this work, we show that imbalanced classdistributions in annotated datasets significantly degrade the performance ofICL across various tasks and selection methods. Moreover, traditional rebalancemethods fail to ameliorate the issue of class imbalance in ICL. Our method ismotivated by decomposing the distributional differences between annotated andtest datasets into two-component weights: class-wise weights and conditionalbias. The key idea behind our method is to estimate the conditional bias byminimizing the empirical error on a balanced validation dataset and to employthe two-component weights to modify the original scoring functions duringselection. Our approach can prevent selecting too many demonstrations from asingle class while preserving the effectiveness of the original selectionmethods. Extensive experiments demonstrate the effectiveness of our method,improving the average accuracy by up to 5.46 on common benchmarks withimbalanced datasets.",Hongfu Gao,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.LG']"
2502.04035v1,Complete FSM Testing Using Strong Separability,http://arxiv.org/abs/2502.04035v1,"Apartness is a concept developed in constructive mathematics, which hasresurfaced as a powerful notion for separating states in the area of modellearning and model-based testing. We identify some fundamental shortcomings ofapartness in quantitative models, such as in hybrid and stochastic systems. Wepropose a closely-related alternative, called strong separability and show thatusing it to replace apartness addresses the identified shortcomings. We adapt awell-known complete model-based testing method, called the Harmonized StateIdentifiers (HSI) method, to adopt the proposed notion of strong separability.We prove that the adapted HSI method is complete. As far as we are aware, thisis the first work to show how complete test suites can be generated forquantitative models such as those found in the development of cyber-physicalsystems.",Robert M. Hierons,2025-02-06,2025-02-06,,N/A,"['cs.SE', 'cs.FL']"
2502.04034v1,Generalize Drug Response Prediction by Latent Independent Projection for Asymmetric Constrained Domain Generalization,http://arxiv.org/abs/2502.04034v1,"The accurate prediction of drug responses remains a formidable challenge,particularly at the single-cell level and in clinical treatment contexts. Somestudies employ transfer learning techniques to predict drug responses inindividual cells and patients, but they require access to target-domain dataduring training, which is often unavailable or only obtainable in future. Inthis study, we propose a novel domain generalization framework, termedpanCancerDR, to address this challenge. We conceptualize each cancer type as adistinct source domain, with its cell lines serving as domain-specific samples.Our primary objective is to extract domain-invariant features from theexpression profiles of cell lines across diverse cancer types, therebygeneralize the predictive capacity to out-of-distribution samples. To enhancerobustness, we introduce a latent independence projection (LIP) module thatencourages the encoder to extract informative yet non-redundant features. Also,we propose an asymmetric adaptive clustering constraint, which clustersdrug-sensitive samples into a compact group while drives resistant samplesdispersed across separate clusters in the latent space. Our empiricalexperiments demonstrate that panCancerDR effectively learns task-relevantfeatures from diverse source domains, and achieves accurate predictions of drugresponse for unseen cancer type during training. Furthermore, when evaluated onsingle-cell and patient-level prediction tasks, our model-trained solely on invitro cell line data without access to target-domain information-consistentlyoutperforms and matched current state-of-the-art methods. These findingshighlights the potential of our method for real-world clinical applications.",Ran Song,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI']"
2502.04031v1,Modeling the laser-pulse induced helium trimer dynamics,http://arxiv.org/abs/2502.04031v1,"Motivated by ongoing pump-probe spectroscopy experiments, this work developsa theoretical framework for describing the rovibrational wave packet dynamicsthat ensues when a single weakly-bound van der Waals trimer is exposed to ashort, sub-picosecond linearly polarized pump laser pulse. The intensity I ofthe pump laser is chosen such that excitation and ionization of the electronicdegrees of freedom are negligible while excitation of the wavepacket in thenuclear degrees of freedom is non-negligible. The numerical treatment, whichtakes advantage of the fact that the laser pulse is very short compared totypical molecular time scales, is based on a wave packet decomposition thatutilizes hyperspherical coordinates. The framework is applied to the extremelyfloppy bosonic helium trimer. A convergence analysis of the partial wavedecomposition is conducted. The kinetic energy release and orientation dynamicsare presented. While the dynamics of more strongly-bound van der Waals trimerssuch as, e.g., the argon trimer display negligible coupling between vibrationaland rotational degrees of freedom, rendering a description within a rigid-bodypicture appropriate, those of weakly-bound trimers display non-negligiblecoupling between vibrational and rotational degrees of freedom, rendering adescription within a rigid-body picture inappropriate. It is shown that a modelthat constructs the helium trimer dynamics from the dynamics of the heliumdimer captures a number of key characteristics of the alignment signal,including the interference between different angular momentum wave packetcomponents.",Q. Guan,2025-02-06,2025-02-06,,N/A,"['quant-ph', 'cond-mat.quant-gas']"
2502.04030v1,"Fine, I'll Merge It Myself: A Multi-Fidelity Framework for Automated Model Merging",http://arxiv.org/abs/2502.04030v1,"Reasoning capabilities represent a critical frontier for large languagemodels (LLMs), but developing them requires extensive proprietary datasets andcomputational resources. One way to efficiently supplement capabilities with isby model merging, which offers a promising alternative by combining multiplemodels without retraining. However, current merging approaches rely onmanually-designed strategies for merging hyperparameters, limiting theexploration of potential model combinations and requiring significant humaneffort. We propose an Automated Model Merging Framework that enablesfine-grained exploration of merging strategies while reducing costs throughmulti-fidelity approximations. We support both single and multi-objectiveoptimization and introduce two novel search spaces: layerwise fusion (LFS) anddepth-wise integration (DIS). Evaluating across a number of benchmarks, we findthat the search autonomously finds 1) Merges that further boostsingle-objective performance, even on tasks the model has already beenfinetuned on, and 2) Merges that optimize multi-objective frontiers acrosstasks. Effective merges are found with limited compute, e.g. within less than500 search steps.",Guinan Su,2025-02-06,2025-02-06,,N/A,"['cs.AI', 'cs.LG']"
2502.04029v1,Echo-Teddy: Preliminary Design and Development of Large Language Model-based Social Robot for Autistic Students,http://arxiv.org/abs/2502.04029v1,"Autistic students often face challenges in social interaction, which canhinder their educational and personal development. This study introducesEcho-Teddy, a Large Language Model (LLM)-based social robot designed to supportautistic students in developing social and communication skills. Unlikeprevious chatbot-based solutions, Echo-Teddy leverages advanced LLMcapabilities to provide more natural and adaptive interactions. The researchaddresses two key questions: (1) What are the design principles and initialprototype characteristics of an effective LLM-based social robot for autisticstudents? (2) What improvements can be made based on developerreflection-on-action and expert interviews? The study employed a mixed-methodsapproach, combining prototype development with qualitative analysis ofdeveloper reflections and expert interviews. Key design principles identifiedinclude customizability, ethical considerations, and age-appropriateinteractions. The initial prototype, built on a Raspberry Pi platform, featurescustom speech components and basic motor functions. Evaluation of the prototyperevealed potential improvements in areas such as user interface, educationalvalue, and practical implementation in educational settings. This researchcontributes to the growing field of AI-assisted special education bydemonstrating the potential of LLM-based social robots in supporting autisticstudents. The findings provide valuable insights for future developments inaccessible and effective social support tools for special education.",Unggi Lee,2025-02-06,2025-02-06,,N/A,['cs.HC']
2502.04028v1,Deep Meta Coordination Graphs for Multi-agent Reinforcement Learning,http://arxiv.org/abs/2502.04028v1,"This paper presents deep meta coordination graphs (DMCG) for learningcooperative policies in multi-agent reinforcement learning (MARL). Coordinationgraph formulations encode local interactions and accordingly factorize thejoint value function of all agents to improve efficiency in MARL. However,existing approaches rely solely on pairwise relations between agents, whichpotentially oversimplifies complex multi-agent interactions. DMCG goes beyondthese simple direct interactions by also capturing useful higher-order andindirect relationships among agents. It generates novel graph structuresaccommodating multiple types of interactions and arbitrary lengths of multi-hopconnections in coordination graphs to model such interactions. It then employsa graph convolutional network module to learn powerful representations in anend-to-end manner. We demonstrate its effectiveness in multiple coordinationproblems in MARL where other state-of-the-art methods can suffer from sampleinefficiency or fail entirely. All codes can be found here:https://github.com/Nikunj-Gupta/dmcg-marl.",Nikunj Gupta,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04027v1,High-Frequency Market Manipulation Detection with a Markov-modulated Hawkes process,http://arxiv.org/abs/2502.04027v1,"This work focuses on a self-exciting point process defined by a Hawkes-likeintensity and a switching mechanism based on a hidden Markov chain. Previousworks in such a setting assume constant intensities between consecutive events.We extend the model to general Hawkes excitation kernels that are piecewiseconstant between events. We develop an expectation-maximization algorithm forthe statistical inference of the Hawkes intensities parameters as well as thestate transition probabilities. The numerical convergence of the estimators isextensively tested on simulated data. Using high-frequency cryptocurrency dataon a top centralized exchange, we apply the model to the detection of anomalousbursts of trades. We benchmark the goodness-of-fit of the model with theMarkov-modulated Poisson process and demonstrate the relevance of the model indetecting suspicious activities.",Timothée Fabre,2025-02-06,2025-02-06,,N/A,"['stat.ME', 'q-fin.ST', 'q-fin.TR']"
2502.04025v1,Renormalization group invariant mean-field model for QCD at finite isospin density,http://arxiv.org/abs/2502.04025v1,"QCD at nonzero isospin chemical potentials has phenomenological relevance fora series of physical systems and provides an ideal testground for the modelingof dense strongly interacting matter. The two-flavor quark-meson model is knownto effectively describe the condensation of charged pions in QCD that occurs inthis setting. In this paper, we work out a renormalization-group invariantmean-field formulation of the model and demonstrate that the resulting phasediagram and equation of state is in quantitative agreement with data fromlattice QCD simulations.",Bastian B. Brandt,2025-02-06,2025-02-06,,N/A,"['hep-ph', 'hep-lat', 'nucl-th']"
2502.04024v1,A Robust Optimization Model for Cost-Efficient and Fast Electric Vehicle Charging with L2-norm Uncertainty,http://arxiv.org/abs/2502.04024v1,"In this paper, we propose a robust optimization model that addresses both thecost-efficiency and fast charging requirements for electric vehicles (EVs) atcharging stations. By combining elements from traditional cost-minimizationmodels and a fast charging objective, we construct an optimization model thatbalances user costs with rapid power allocation. Additionally, we incorporateL2-norm uncertainty into the charging cost, ensuring that the model remainsresilient under cost fluctuations. The proposed model is tested underreal-world scenarios and demonstrates its potential for efficient and flexibleEV charging solutions.",Trung Duc Tran,2025-02-06,2025-02-06,,N/A,"['eess.SY', 'cs.SY']"
2502.04022v1,Quantification of Biodiversity from Historical Survey Text with LLM-based Best-Worst Scaling,http://arxiv.org/abs/2502.04022v1,"In this study, we evaluate methods to determine the frequency of species viaquantity estimation from historical survey text. To that end, we formulateclassification tasks and finally show that this problem can be adequatelyframed as a regression task using Best-Worst Scaling (BWS) with Large LanguageModels (LLMs). We test Ministral-8B, DeepSeek-V3, and GPT-4, finding that thelatter two have reasonable agreement with humans and each other. We concludethat this approach is more cost-effective and similarly robust compared to afine-grained multi-class approach, allowing automated quantity estimationacross species.",Thomas Haider,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04018v1,PINT: Physics-Informed Neural Time Series Models with Applications to Long-term Inference on WeatherBench 2m-Temperature Data,http://arxiv.org/abs/2502.04018v1,"This paper introduces PINT (Physics-Informed Neural Time Series Models), aframework that integrates physical constraints into neural time series modelsto improve their ability to capture complex dynamics. We apply PINT to the ERA5WeatherBench dataset, focusing on long-term forecasting of 2m-temperature data.PINT incorporates the Simple Harmonic Oscillator Equation as a physics-informedprior, embedding its periodic dynamics into RNN, LSTM, and GRU architectures.This equation's analytical solutions (sine and cosine functions) facilitaterigorous evaluation of the benefits of incorporating physics-informedconstraints. By benchmarking against a linear regression baseline derived fromits exact solutions, we quantify the impact of embedding physical principles indata-driven models. Unlike traditional time series models that rely on futureobservations, PINT is designed for practical forecasting. Using only the first90 days of observed data, it iteratively predicts the next two years,addressing challenges posed by limited real-time updates. Experiments on theWeatherBench dataset demonstrate PINT's ability to generalize, capture periodictrends, and align with physical principles. This study highlights the potentialof physics-informed neural models in bridging machine learning andinterpretable climate applications.  Our models and datasets are publicly available on GitHub:https://github.com/KV-Park.",Keon Vin Park,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04015v1,Search for Stable States in Two-Body Excitations of the Hubbard Model on the Honeycomb Lattice,http://arxiv.org/abs/2502.04015v1,"We present one- and two-body measurements for the Hubbard model on thehoneycomb (graphene) lattice from ab-initio quantum monte carlo simulations. Ofparticular interest is excitons, which are particle/hole excitations inlow-dimensional systems. They are analogous to the pion in QCD, but withoutconfinement, the question of whether they are bound and stable is of greatinterest in the condensed matter arena. By measuring one- and two-bodycorrelators across various spin and isospin channels we can compute two-bodyenergies relative to their thresholds, ultimately allowing us to check forstable states.",Petar Sinilkov,2025-02-06,2025-02-06,,N/A,['cond-mat.str-el']
2502.04013v1,Search for resonance-enhanced $CP$ and angular asymmetries in the $Λ^+_{c}\to pμ^+μ^-$ decay at LHCb,http://arxiv.org/abs/2502.04013v1,"The first measurement of the $CP$ asymmetry of the decay rate ($A_{CP}$) andthe $CP$ average ($\Sigma A_{\text{FB}}$) and $CP$ asymmetry ($\DeltaA_{\text{FB}}$) of the forward-backward asymmetry in the muon system of$\mathit{\Lambda}^+_c\to p\mu^+\mu^-$ decays is reported. The measurement isperformed using a data sample of proton-proton collisions, recorded by the LHCbexperiment from 2016 to 2018 at a center-of-mass energy of 13$\text{ TeV}$,which corresponds to an integrated luminosity of 5.4$\text{ fb}^{-1}$. Theasymmetries are measured in two regions of dimuon mass near the $\phi$-mesonmass peak. The dimuon-mass integrated results are \begin{align*} A_{CP} &=(-1.1 \pm 4.0 \pm 0.5)\%,\\ \Sigma A_{\text{FB}} &= (\phantom{-}3.9 \pm 4.0 \pm0.6)\%,\\ \Delta A_{\text{FB}} &= (\phantom{-}3.1 \pm 4.0 \pm 0.4)\%,\end{align*} where the first uncertainty is statistical and the secondsystematic. The results are consistent with the conservation of $CP$ symmetryand the Standard Model expectations.",LHCb collaboration,2025-02-06,2025-02-06,,N/A,['hep-ex']
2502.04008v1,Automating a Complete Software Test Process Using LLMs: An Automotive Case Study,http://arxiv.org/abs/2502.04008v1,"Vehicle API testing verifies whether the interactions between a vehicle'sinternal systems and external applications meet expectations, ensuring thatusers can access and control various vehicle functions and data. However, thistask is inherently complex, requiring the alignment and coordination of APIsystems, communication protocols, and even vehicle simulation systems todevelop valid test cases. In practical industrial scenarios, inconsistencies,ambiguities, and interdependencies across various documents and systemspecifications pose significant challenges. This paper presents a systemdesigned for the automated testing of in-vehicle APIs. By clearly defining andsegmenting the testing process, we enable Large Language Models (LLMs) to focuson specific tasks, ensuring a stable and controlled testing workflow.Experiments conducted on over 100 APIs demonstrate that our system effectivelyautomates vehicle API testing. The results also confirm that LLMs canefficiently handle mundane tasks requiring human judgment, making them suitablefor complete automation in similar industrial contexts.",Shuai Wang,2025-02-06,2025-02-06,,N/A,"['cs.SE', 'cs.AI']"
2502.04005v1,Quantifying Ionic Liquid Affinity and Its Effect on Phospholipid Membrane Structure and Dynamics,http://arxiv.org/abs/2502.04005v1,"In this study, we examine the impact of imidazolium based ILs on theviscoelasticity, dynamics, and phase behavior of two model membrane systems,(i) lipid monolayers and (ii) unilamellar vesicles composed ofdipalmitoylphosphatidylcholine (DPPC). Our findings demonstrate that both ILsinduce significant disorder in lipid membranes by altering the area per lipidmolecule, thereby modulating their viscoelastic properties. ILs with longeralkyl chains show stronger interactions with membranes, causing more pronounceddisorder. Fourier transform infrared spectroscopy indicates that ILincorporation shifts the membrane main phase transition to lower temperaturesand introduces gauche defects, signifying increased structural disorder. Thiseffect is amplified with longer alkyl chains and higher IL concentrations.Quasielastic neutron scattering studies highlight that ILs markedly enhance thelateral diffusion of lipids within the membrane leaflet, with the extent ofenhancement determined by the membrane physical state, IL concentration, andalkyl chain length. The most pronounced acceleration in lateral diffusionoccurs in ordered membrane phase with higher concentrations of the longer chainIL. Molecular dynamics simulations corroborate these experimental findings,showing that longer chain ILs extensively disrupt lipid organization, introducemore gauche defects, increase the area per lipid, and consequently enhancelateral diffusion. This increase in lipid fluidity and permeability provides amechanistic basis for the observed higher toxicity associated with longer chainILs.",V. K. Sharma,2025-02-06,2025-02-06,,N/A,['cond-mat.soft']
2502.04003v1,Performance Analysis of BEM-based Channel Estimation for OTFS with Hardware Impairments,http://arxiv.org/abs/2502.04003v1,"This letter studies the low-complexity channel estimation for orthogonal timefrequency space (OTFS) in the presence of hardware impairments. Firstly, totackle the computational complexity of channel estimation, the basis expansionmodel (BEM) is utilized. Then, the mean square error (MSE) of the estimatedchannel is theoretically derived, revealing the effects of hardware impairmentson channel estimation. Based on the estimated channel, the minimum mean squareerror (MMSE) detector is adopted to analyze the impacts of imperfect hardwareon the bit error rate (BER). Finally, the numerical results validate thecorrectness of our theoretical analysis of the MSE for channel estimation andlower bound of the BER, and also demonstrate that even minor hardwareimpairments can significantly degrade the performance of the OTFS system.",Haowei Wu,2025-02-06,2025-02-06,,N/A,['eess.SP']
2502.04002v1,Nonextensive entropic behavior observed in Quasar 3C 273,http://arxiv.org/abs/2502.04002v1,"We investigate the flux intensities spanning from radio waves to X-raysacross 39 light curves of Quasar 3C 273, utilizing publicly available datacollected by the Integral Science Data Centre (ISDC) database. Our resultssuggest that Quasar 3C 273 exhibits nonextensive behavior. Furthermore, wecalculate the $q$ entropic indices for these light curves using the$q$-Gaussian distribution with a predominant observation of cases where $q>1$.Based on this index, we estimate the non-extensive entropy ($S_{q}$) andexplore its correlation with the energy (in eV). In this context, we identifytwo jump-like increases in entropy, particularly evident in the infrared (IR)and X-ray wavebands. The peak in the far-IR band, around 0.34 eV, results fromsynchrotron flares evolving from higher to lower energies and thermal radiationemitted by hot dust near the sublimation radius. However, the second entropicpeak in the hard X-ray range lacks statistical robustness due to limited dataor large measurement uncertainties.",C. V. da Silva,2025-02-06,2025-02-06,,N/A,['astro-ph.HE']
2502.03998v1,Online Learning of Counter Categories and Ratings in PvP Games,http://arxiv.org/abs/2502.03998v1,"In competitive games, strength ratings like Elo are widely used to quantifyplayer skill and support matchmaking by accounting for skill disparities betterthan simple win rate statistics. However, scalar ratings cannot handle complexintransitive relationships, such as counter strategies seen inRock-Paper-Scissors. To address this, recent work introduced Neural RatingTable and Neural Counter Table, which combine scalar ratings with discretecounter categories to model intransitivity. While effective, these methods relyon neural network training and cannot perform real-time updates. In this paper,we propose an online update algorithm that extends Elo principles toincorporate real-time learning of counter categories. Our method dynamicallyadjusts both ratings and counter relationships after each match, preserving theexplainability of scalar ratings while addressing intransitivity. Experimentson zero-sum competitive games demonstrate its practicality, particularly inscenarios without complex team compositions.",Chiu-Chou Lin,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI', 'cs.GT', 'cs.MA']"
2502.03997v1,CAD-Editor: A Locate-then-Infill Framework with Automated Training Data Synthesis for Text-Based CAD Editing,http://arxiv.org/abs/2502.03997v1,"Computer Aided Design (CAD) is indispensable across various industries.\emph{Text-based CAD editing}, which automates the modification of CAD modelsbased on textual instructions, holds great potential but remains underexplored.Existing methods primarily focus on design variation generation or text-basedCAD generation, either lacking support for text-based control or neglectingexisting CAD models as constraints. We introduce \emph{CAD-Editor}, the firstframework for text-based CAD editing. To address the challenge of demandingtriplet data with accurate correspondence for training, we propose an automateddata synthesis pipeline. This pipeline utilizes design variation models togenerate pairs of original and edited CAD models and employs LargeVision-Language Models (LVLMs) to summarize their differences into editinginstructions. To tackle the composite nature of text-based CAD editing, wepropose a locate-then-infill framework that decomposes the task into twofocused sub-tasks: locating regions requiring modification and infilling theseregions with appropriate edits. Large Language Models (LLMs) serve as thebackbone for both sub-tasks, leveraging their capabilities in natural languageunderstanding and CAD knowledge. Experiments show that CAD-Editor achievessuperior performance both quantitatively and qualitatively.",Yu Yuan,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03995v1,Modeling fast X-ray variability around an accreting black hole,http://arxiv.org/abs/2502.03995v1,"X-ray inter-band time lags are observed during the outbursts of black holeX-ray binaries (BHXRBs). Timing analysis of fast variability in low Fourierfrequency bands shows that high-energy photons lag behind low-energy photons, aphenomenon referred to as hard lag. Conversely, in high Fourier frequencybands, low-energy photons lag behind high-energy photons, known as soft lag.This frequency-dependent lag spectrum suggests that the lags arise fromdifferent physical processes. Notably, a trend has been observed wherein thelags shift towards shorter timescales during the rising hard state, indicatingan evolution in the inner accretion flow. In this study, we simulate theseinter-band lags by conducting Monte Carlo simulations of the rapid variabilitywithin the geometry of a jet base corona. We consider both inward propagatingaccretion rate fluctuations and reverberation (light crossing) delays in oursimulations. We successfully reproduce both low-frequency hard lags andhigh-frequency soft lags in a self-consistent manner. We replicate the observedevolution of the frequency-dependent lag spectra by varying the geometricalscale of the corona and the viscous frequency of the disc. Finally, we discussthe potential of a spherical corona and emphasize that polarizationobservations from the Imaging X-ray Polarimetry Explorer (IXPE) and theenhanced X-ray Timing and Polarimetry mission (eXTP) will be crucial fordistinguishing the corona's geometry in future studies.",Yejing Zhan,2025-02-06,2025-02-06,,N/A,['astro-ph.HE']
2502.03992v1,"Ontology-Guided, Hybrid Prompt Learning for Generalization in Knowledge Graph Question Answering",http://arxiv.org/abs/2502.03992v1,"Most existing Knowledge Graph Question Answering (KGQA) approaches aredesigned for a specific KG, such as Wikidata, DBpedia or Freebase. Due to theheterogeneity of the underlying graph schema, topology and assertions, mostKGQA systems cannot be transferred to unseen Knowledge Graphs (KGs) withoutresource-intensive training data. We present OntoSCPrompt, a novel LargeLanguage Model (LLM)-based KGQA approach with a two-stage architecture thatseparates semantic parsing from KG-dependent interactions. OntoSCPrompt firstgenerates a SPARQL query structure (including SPARQL keywords such as SELECT,ASK, WHERE and placeholders for missing tokens) and then fills them withKG-specific information. To enhance the understanding of the underlying KG, wepresent an ontology-guided, hybrid prompt learning strategy that integrates KGontology into the learning process of hybrid prompts (e.g., discrete andcontinuous vectors). We also present several task-specific decoding strategiesto ensure the correctness and executability of generated SPARQL queries in bothstages. Experimental results demonstrate that OntoSCPrompt performs as well asSOTA approaches without retraining on a number of KGQA datasets such as CWQ,WebQSP and LC-QuAD 1.0 in a resource-efficient manner and can generalize wellto unseen domain-specific KGs like DBLP-QuAD and CoyPu KG Code:\href{https://github.com/LongquanJiang/OntoSCPrompt}{https://github.com/LongquanJiang/OntoSCPrompt}",Longquan Jiang,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.03991v1,Simulation of the thermocapillary assembly of a colloidal cluster during the evaporation of a liquid film in an unevenly heated cell,http://arxiv.org/abs/2502.03991v1,"The control of the thermocapillary assembly of colloidal particle clusters isimportant for a variety of applications, including the creation of photoniccrystals for microelectronics and optoelectronics, membrane formation forbiotechnology, and surface cleaning for laboratory-on-chip devices. It isimportant to understand the main mechanisms that influence the formation ofsuch clusters. This article considers a two-dimensional mathematical modeldescribing the transfer of particles by a thermocapillary flow in an unevenlyheated cell during the evaporation of a liquid. This gave us the opportunity tostudy one of the main processes that triggers the formation of a particlecluster. Whether the particle will move with the flow or stop at the heater,becoming the basis for the cluster, is determined by the ratio between gravityand the drag force. The results of numerical calculations show that, for smallparticle concentrations, their fraction entering the cluster decreases as thevolumetric heat flux density $Q$ increases. The reason for this is an increasein the thermocapillary flow with an increase in the volumetric heat flux $Q$.It reduces the probability of particles entering the cluster.",Kristina N. Kondrashova,2025-02-06,2025-02-06,,N/A,"['cond-mat.soft', 'physics.flu-dyn']"
2502.03989v1,Radii of light nuclei from the Jacobi No-Core Shell Model,http://arxiv.org/abs/2502.03989v1,"Accurately determining the size of the atomic nucleus with realistic nuclearforces is a long outstanding issue of nuclear physics. The no-core shell model(NCSM), one of the powerful ab initio methods for nuclear structure, canachieve accurate energies of light nuclei. The extraction of converged radii ismore difficult. In this work, we present a novel method to effectively extractthe radius of light nuclei by restoring the long-range behavior of densitiesfrom NCSM calculations. The correct large distance asymptotic of two-bodyrelative densities are deduced based on the NCSM densities in limited basissize. The resulting radii using the corrected densities show a niceconvergence. The root-mean-square matter and charge radii of $^{4,6,8}$He and$^{6,7,8}$Li can be accurately obtained based on Jacobi-NCSM calculations withthe high-precision chiral two-nucleon and three-nucleon forces combined withthis new method. Our method can be straightforwardly extended to other abinitio calculations, potentially providing a better description of nuclearsizes with realistic nuclear forces.",Xiang-Xiang Sun,2025-02-06,2025-02-06,,N/A,['nucl-th']
2502.03988v1,Tight Bounds on Jensen's Gap: Novel Approach with Applications in Generative Modeling,http://arxiv.org/abs/2502.03988v1,"Among various mathematical tools of particular interest are those thatprovide a common basis for researchers in different scientific fields. One ofthem is Jensen's inequality, which states that the expectation of a convexfunction is greater than or equal to the function evaluated at the expectation.The resulting difference, known as Jensen's gap, became the subject ofinvestigation by both the statistical and machine learning communities. Amongmany related topics, finding lower and upper bounds on Jensen's gap (underdifferent assumptions on the underlying function and distribution) has recentlybecome a problem of particular interest. In our paper, we take another step inthis direction by providing a novel general and mathematically rigoroustechnique, motivated by the recent results of Struski et al. (2023). Inaddition, by studying in detail the case of the logarithmic function and thelog-normal distribution, we explore a method for tightly estimating thelog-likelihood of generative models trained on real-world datasets.Furthermore, we present both analytical and experimental arguments in supportof the superiority of our approach in comparison to existing state-of-the-artsolutions, contingent upon fulfillment of the criteria set forth by theoreticalstudies and corresponding experiments on synthetic data.",Marcin Mazur,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.03987v1,"Deep Learning-Optimized, Fabrication Error-Tolerant Photonic Crystal Nanobeam Cavities for Scalable On-Chip Diamond Quantum Systems",http://arxiv.org/abs/2502.03987v1,"Cavity-enhanced diamond color center qubits can be initialized, manipulated,entangled, and read individually with high fidelity, which makes them ideal forlarge-scale, modular quantum computers, quantum networks, and distributedquantum sensing systems. However, diamond's unique material properties posesignificant challenges in manufacturing nanophotonic devices, leading tofabrication-induced structural imperfections and inaccuracies in defectimplantation, which hinder reproducibility, degrade optical properties andcompromise the spatial coupling of color centers to small mode-volume cavities.A cavity design tolerant to fabrication imperfections, such as surfaceroughness, sidewall slant, and non-optimal emitter positioning, can improvecoupling efficiency while simplifying fabrication. To address this challenge, adeep learning-based optimization methodology is developed to enhance thefabrication error tolerance of nanophotonic devices. Convolutional neuralnetworks (CNNs) are applied to promising designs, such as L2 and fishbonenanobeam cavities, predicting Q-factors up to one million times faster thantraditional finite-difference time-domain (FDTD) simulations, enablingefficient optimization of complex, high-dimensional parameter spaces. The CNNsachieve prediction errors below 3.99% and correlation coefficients up to 0.988.Optimized structures demonstrate a 52% reduction in Q-factor degradation,achieving quality factors of 5e4 under real-world conditions and a two-foldexpansion in field distribution, enabling efficient coupling of non-optimallypositioned emitters. This methodology enables scalable, high-yieldmanufacturing of robust nanophotonic devices, including the cavity-enhanceddiamond quantum systems developed in this study.",Sander van Haagen,2025-02-06,2025-02-06,,N/A,"['physics.optics', 'physics.app-ph', 'quant-ph']"
2502.03984v1,PGB: One-Shot Pruning for BERT via Weight Grouping and Permutation,http://arxiv.org/abs/2502.03984v1,"Large pretrained language models such as BERT suffer from slow inference andhigh memory usage, due to their huge size. Recent approaches to compressingBERT rely on iterative pruning and knowledge distillation, which, however, areoften too complicated and computationally intensive. This paper proposes anovel semi-structured one-shot pruning method for BERT, called$\textit{Permutation and Grouping for BERT}$ (PGB), which achieves highcompression efficiency and sparsity while preserving accuracy. To this end, PGBidentifies important groups of individual weights by permutation and prunes allother weights as a structure in both multi-head attention and feed-forwardlayers. Furthermore, if no important group is formed in a particular layer, PGBdrops the entire layer to produce an even more compact model. Our experimentalresults on BERT$_{\text{BASE}}$ demonstrate that PGB outperforms thestate-of-the-art structured pruning methods in terms of computational cost andaccuracy preservation.",Hyemin Lim,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.03982v1,Temporal Distribution Shift in Real-World Pharmaceutical Data: Implications for Uncertainty Quantification in QSAR Models,http://arxiv.org/abs/2502.03982v1,"The estimation of uncertainties associated with predictions from quantitativestructure-activity relationship (QSAR) models can accelerate the drug discoveryprocess by identifying promising experiments and allowing an efficientallocation of resources. Several computational tools exist that estimate thepredictive uncertainty in machine learning models. However, deviations from thei.i.d. setting have been shown to impair the performance of these uncertaintyquantification methods. We use a real-world pharmaceutical dataset to addressthe pressing need for a comprehensive, large-scale evaluation of uncertaintyestimation methods in the context of realistic distribution shifts over time.We investigate the performance of several uncertainty estimation methods,including ensemble-based and Bayesian approaches. Furthermore, we use thisreal-world setting to systematically assess the distribution shifts in labeland descriptor space and their impact on the capability of the uncertaintyestimation methods. Our study reveals significant shifts over time in bothlabel and descriptor space and a clear connection between the magnitude of theshift and the nature of the assay. Moreover, we show that pronounceddistribution shifts impair the performance of popular uncertainty estimationmethods used in QSAR models. This work highlights the challenges of identifyinguncertainty quantification methods that remain reliable under distributionshifts introduced by real-world data.",Hannah Rosa Friesacher,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.03979v1,Towards Unified Music Emotion Recognition across Dimensional and Categorical Models,http://arxiv.org/abs/2502.03979v1,"One of the most significant challenges in Music Emotion Recognition (MER)comes from the fact that emotion labels can be heterogeneous across datasetswith regard to the emotion representation, including categorical (e.g., happy,sad) versus dimensional labels (e.g., valence-arousal). In this paper, wepresent a unified multitask learning framework that combines these two types oflabels and is thus able to be trained on multiple datasets. This framework usesan effective input representation that combines musical features (i.e., key andchords) and MERT embeddings. Moreover, knowledge distillation is employed totransfer the knowledge of teacher models trained on individual datasets to astudent model, enhancing its ability to generalize across multiple tasks. Tovalidate our proposed framework, we conducted extensive experiments on avariety of datasets, including MTG-Jamendo, DEAM, PMEmo, and EmoMusic.According to our experimental results, the inclusion of musical features,multitask learning, and knowledge distillation significantly enhancesperformance. In particular, our model outperforms the state-of-the-art models,including the best-performing model from the MediaEval 2021 competition on theMTG-Jamendo dataset. Our work makes a significant contribution to MER byallowing the combination of categorical and dimensional emotion labels in oneunified framework, thus enabling training across datasets.",Jaeyong Kang,2025-02-06,2025-02-06,,N/A,"['cs.SD', 'cs.AI', 'eess.AS']"
2502.03977v1,Performance Analysis of Digital Flux-locked Loop Circuit with Different SQUID $V$-$φ$ Transfer Curves for TES Readout System,http://arxiv.org/abs/2502.03977v1,"A superconducting quantum interference device (SQUID), functioning as anonlinear response device, typically requires the incorporation of aflux-locked loop (FLL) circuit to facilitate linear amplification of thecurrent signal transmitted through a superconducting transition-edge sensor(TES) across a large dynamic range. This work presents a reasonable model ofthe SQUID-FLL readout system, based on a digitalproportional-integral-differential (PID) flux negative feedback algorithm. Thiswork investigates the effect of $V$-$\phi$ shape on the performance of digitalFLL circuits. Such as the impact factors of bandwidth, design limits of slewrate of the system and the influence of the shapes of SQUID $V$-$\phi$ curve.Furthermore, the dynamic response of the system to X-ray pulse signals withrise time ranging from $4.4{\sim}281$ $\mathrm{{\mu}s}$ and amplitudes rangingfrom $6{\sim}8$ $\mathrm{\phi_0}$ was simulated. All the simulation resultswere found to be consistent with the existing mature theories, therebyvalidating the accuracy of the model. The results also provide a reliablemodelling reference for the design of digital PID flux negative feedback andmultiplexing SQUID readout electronic systems.",Nan Li,2025-02-06,2025-02-06,,N/A,['astro-ph.IM']
2502.03976v1,Small Signal Stability Analysis of Kurdistan Regional Power System,http://arxiv.org/abs/2502.03976v1,"This paper presents for the first time a mathematical model for evaluatingthe Planned Kurdistan Regional Power System (KRPS) for its ability to maintainstability under small disturbances and fluctuations during normal operatingconditions. To achieve this objective, practical field data, manufacture'sdatasheets, related IEEE task force reports have been used to build a completemathematical model in MATLAB/SIMULINK/SimPowerSystem environment. New moduleshave been established and added to the platform wherever it does not supportspecial type of elements. The model represents accurately all the power systemcomponents involved in physical phenomena of system dynamic oscillations. Themodel consists of 53 transmission lines, 35 nodes and 6 generating stations.The system is simulated under different configurations and settings; thedynamic behaviors associated with each configuration are recorded and analyzedaccordingly.",Ibrahim Ismael Hamarash,2025-02-06,2025-02-06,,N/A,"['eess.SY', 'cs.SY']"
2502.03971v1,RWKV-UI: UI Understanding with Enhanced Perception and Reasoning,http://arxiv.org/abs/2502.03971v1,"Existing Visual Language Modelsoften struggle with information loss andlimited reasoning abilities when handling high-resolution web interfaces thatcombine complex visual, textual, and interactive elements. These challenges areparticularly evident in tasks requiring webpage layout comprehension andmulti-step interactive reasoning. To address these challenges, we proposeRWKV-UI, a Visual Language Model based on the RWKV architecture, specificallydesigned to handle high-resolution UI images. During model training, weintroduce layout detection as a visual prompt to help the model betterunderstand the webpage layout structures. Additionally, we design a visualprompt based on the Chain-of-Thought(CoT) mechanism, which enhances the model'sability to understand and reason about webpage content through reasoningchains. Experimental results show that RWKV-UI demonstrates significantperformance improvements in high-resolution UI understanding and interactivereasoning tasks.",Jiaxi Yang,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.HC']"
2502.03966v1,MultiFloodSynth: Multi-Annotated Flood Synthetic Dataset Generation,http://arxiv.org/abs/2502.03966v1,"In this paper, we present synthetic data generation framework for floodhazard detection system. For high fidelity and quality, we characterize severalreal-world properties into virtual world and simulate the flood situation bycontrolling them. For the sake of efficiency, recent generative models inimage-to-3D and urban city synthesis are leveraged to easily composite floodenvironments so that we avoid data bias due to the hand-crafted manner. Basedon our framework, we build the flood synthetic dataset with 5 levels, dubbedMultiFloodSynth which contains rich annotation types like normal map,segmentation, 3D bounding box for a variety of downstream task. In experiments,our dataset demonstrate the enhanced performance of flood hazard detection withon-par realism compared with real dataset.",YoonJe Kang,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.AI', 'cs.LG']"
2502.03965v1,Innovative Framework for Early Estimation of Mental Disorder Scores to Enable Timely Interventions,http://arxiv.org/abs/2502.03965v1,"Individual's general well-being is greatly impacted by mental healthconditions including depression and Post-Traumatic Stress Disorder (PTSD),underscoring the importance of early detection and precise diagnosis in orderto facilitate prompt clinical intervention. An advanced multimodal deeplearning system for the automated classification of PTSD and depression ispresented in this paper. Utilizing textual and audio data from clinicalinterview datasets, the method combines features taken from both modalities bycombining the architectures of LSTM (Long Short Term Memory) and BiLSTM(Bidirectional Long Short-Term Memory).Although text features focus on speech'ssemantic and grammatical components; audio features capture vocal traitsincluding rhythm, tone, and pitch. This combination of modalities enhances themodel's capacity to identify minute patterns connected to mental healthconditions. Using test datasets, the proposed method achieves classificationaccuracies of 92% for depression and 93% for PTSD, outperforming traditionalunimodal approaches and demonstrating its accuracy and robustness.",Himanshi Singh,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.03964v1,"""It Warned Me Just at the Right Moment"": Exploring LLM-based Real-time Detection of Phone Scams",http://arxiv.org/abs/2502.03964v1,"Despite living in the era of the internet, phone-based scams remain one ofthe most prevalent forms of scams. These scams aim to exploit victims forfinancial gain, causing both monetary losses and psychological distress. Whilegovernments, industries, and academia have actively introduced variouscountermeasures, scammers also continue to evolve their tactics, making phonescams a persistent threat. To combat these increasingly sophisticated scams,detection technologies must also advance. In this work, we propose a frameworkfor modeling scam calls and introduce an LLM-based real-time detectionapproach, which assesses fraudulent intent in conversations, further providingimmediate warnings to users to mitigate harm. Through experiments, we evaluatethe method's performance and analyze key factors influencing its effectiveness.This analysis enables us to refine the method to improve precision whileexploring the trade-off between recall and timeliness, paving the way forfuture directions in this critical area of research.",Zitong Shen,2025-02-06,2025-02-06,,N/A,"['cs.HC', 'cs.CR', 'H.5']"
2502.03963v1,AL-PINN: Active Learning-Driven Physics-Informed Neural Networks for Efficient Sample Selection in Solving Partial Differential Equations,http://arxiv.org/abs/2502.03963v1,"Physics-Informed Neural Networks (PINNs) have emerged as a promising approachfor solving Partial Differential Equations (PDEs) by incorporating physicalconstraints into deep learning models. However, standard PINNs often require alarge number of training samples to achieve high accuracy, leading to increasedcomputational costs. To address this issue, we propose Active Learning-DrivenPINNs (AL-PINN), which integrates Uncertainty Quantification (UQ) and ActiveLearning (AL) strategies to optimize sample selection dynamically.  AL-PINN utilizes Monte Carlo Dropout to estimate epistemic uncertainty in themodel predictions, enabling the adaptive selection of high-uncertainty regionsfor additional training. This approach significantly enhances learningefficiency by focusing computational resources on the most informative datapoints. We evaluate AL-PINN on benchmark PDE problems with known analyticalsolutions and real-world WeatherBench climate data. Our results demonstratethat AL-PINN achieves comparable or superior accuracy compared to traditionalPINNs while reducing the number of required training samples.  The proposed framework is particularly beneficial for scientific andengineering applications where data collection is expensive or limited, such asclimate modeling, medical simulations, and material science. Our findingshighlight the potential of active learning in accelerating PINN-based PDEsolvers while maintaining high accuracy and computational efficiency.",Keon Vin Park,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.03960v1,Bilevel Multi-Armed Bandit-Based Hierarchical Reinforcement Learning for Interaction-Aware Self-Driving at Unsignalized Intersections,http://arxiv.org/abs/2502.03960v1,"In this work, we present BiM-ACPPO, a bilevel multi-armed bandit-basedhierarchical reinforcement learning framework for interaction-awaredecision-making and planning at unsignalized intersections. Essentially, itproactively takes the uncertainties associated with surrounding vehicles (SVs)into consideration, which encompass those stemming from the driver's intention,interactive behaviors, and the varying number of SVs. Intermediate decisionvariables are introduced to enable the high-level RL policy to provide aninteraction-aware reference, for guiding low-level model predictive control(MPC) and further enhancing the generalization ability of the proposedframework. By leveraging the structured nature of self-driving at unsignalizedintersections, the training problem of the RL policy is modeled as a bilevelcurriculum learning task, which is addressed by the proposed Exp3.S-based BiMABalgorithm. It is noteworthy that the training curricula are dynamicallyadjusted, thereby facilitating the sample efficiency of the RL trainingprocess. Comparative experiments are conducted in the high-fidelity CARLAsimulator, and the results indicate that our approach achieves superiorperformance compared to all baseline methods. Furthermore, experimental resultsin two new urban driving scenarios clearly demonstrate the commendablegeneralization performance of the proposed method.",Zengqi Peng,2025-02-06,2025-02-06,,N/A,['cs.RO']
2502.03959v1,Phase diagram of the hard-sphere potential model in three and four dimensions using a pseudo-hard-sphere potential,http://arxiv.org/abs/2502.03959v1,"The hard-sphere potential has become a cornerstone in the study of bothmolecular and complex fluids. Despite its mathematical simplicity, itsimplementation in fixed time-step molecular simulations remains a formidablechallenge due to the discontinuity at contact. To circumvent the issuesassociated with the ill-defined force at contact, a continuouspotential--referred to here as the pseudo-hard-sphere (pHS) potential--hasrecently been proposed [J. Chem, Phys. 149, 164907 (2018)]. This potential isconstructed to match the second virial coefficient of the hard-sphere potentialand is expected to mimic its thermodynamic properties. However, this hypothesishas only been partially validated within the fluid region of the phase diagramfor hard-sphere dispersions in two and three dimensions. In this contribution,we examine the ability of the continuous pHS potential to reproduce theequation of state of a hard-sphere fluid, not only in the fluid phase but alsoacross the fluid-solid coexistence region. Our focus is primarily onhard-sphere systems in three and four dimensions. We compare the resultsobtained from Brownian dynamics simulations of the pHS potential with thosederived from refined event-driven simulations of the corresponding hard-spherepotential. Furthermore, we provide a comparative analysis with theoreticalequations of state based on both mean-field and integral equationapproximations.",Edwin A. Bedolla-Montiel,2025-02-06,2025-02-06,,N/A,['cond-mat.soft']
2502.03957v1,Improving the Perturbation-Based Explanation of Deepfake Detectors Through the Use of Adversarially-Generated Samples,http://arxiv.org/abs/2502.03957v1,"In this paper, we introduce the idea of using adversarially-generated samplesof the input images that were classified as deepfakes by a detector, to formperturbation masks for inferring the importance of different input features andproduce visual explanations. We generate these samples based on NaturalEvolution Strategies, aiming to flip the original deepfake detector's decisionand classify these samples as real. We apply this idea to fourperturbation-based explanation methods (LIME, SHAP, SOBOL and RISE) andevaluate the performance of the resulting modified methods using a SOTAdeepfake detection model, a benchmarking dataset (FaceForensics++) and acorresponding explanation evaluation framework. Our quantitative assessmentsdocument the mostly positive contribution of the proposed perturbation approachin the performance of explanation methods. Our qualitative analysis shows thecapacity of the modified explanation methods to demarcate the manipulated imageregions more accurately, and thus to provide more useful explanations.",Konstantinos Tsigos,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.AI', 'cs.CR']"
2502.03956v1,POPACheck: a Model Checker for probabilistic Pushdown Automata,http://arxiv.org/abs/2502.03956v1,"We present POPACheck, the first full-fledged model checking tool for pPDA.POPACheck provides a user-friendly probabilistic modeling language withrecursion that automatically translates into pOPA. pOPA are a class of pPDAthat can express all the behaviors of probabilistic programs. On pOPA,POPACheck can solve reachability queries as well as qualitative andquantitative model checking queries for specifications in LTL and a fragment ofPOTL, a logic for context-free properties such as pre/post-conditioning.",Francesco Pontiggia,2025-02-06,2025-02-06,,N/A,['cs.LO']
2502.03955v1,On the extension of analytic solutions of first-order difference equations,http://arxiv.org/abs/2502.03955v1,"We will consider first-order difference equations of the form \[ y(z+1) =\frac{\lambda y(z)+a_2(z)y(z)^2+\cdots+a_p(z)y(z)^p}{1 +b_1(z)y(z)+\cdots+b_q(z)y(z)^q}, \]  where $\lambda\in\mathbb{C}\setminus\{0\}$ and the coefficients $a_j(z)$ and$b_k(z)$ are meromorphic.  When existence of an analytic solution can be proved for large negativevalues of $\Re(z)$, the equation determines a unique extension to a globalmeromorphic solution. In this paper we prove the existence of non-constantmeromorphic solutions when the coefficients satisfy $|a_{j}(z)|\leq \nu^{|z|}$and $|b_{k}(z)|\leq \nu^{|z|}$ for some $\nu<|\lambda|$ in a half-plane.Furthermore, when a solution exists that is analytic for large positive valuesof $\Re(z)$, the equation determines a unique extension to a global solutionthat will generically have algebraic branch points. We analyse a particularconstant coefficient equation, $y(z+1)=\lambda y(z)+y(z)^2$, $0<\lambda<1$, anddescribe in detail the infinitely-sheeted Riemann surface for such a solution.We also describe solutions with natural boundaries found by Mahler.",Rod Halburd,2025-02-06,2025-02-06,,N/A,"['math.CV', '30D05']"
2502.03954v1,MAQInstruct: Instruction-based Unified Event Relation Extraction,http://arxiv.org/abs/2502.03954v1,"Extracting event relations that deviate from known schemas has provenchallenging for previous methods based on multi-class classification, MASKprediction, or prototype matching. Recent advancements in large language modelshave shown impressive performance through instruction tuning. Nevertheless, inthe task of event relation extraction, instruction-based methods face severalchallenges: there are a vast number of inference samples, and the relationsbetween events are non-sequential. To tackle these challenges, we present animproved instruction-based event relation extraction framework namedMAQInstruct. Firstly, we transform the task from extracting event relationsusing given event-event instructions to selecting events using givenevent-relation instructions, which reduces the number of samples required forinference. Then, by incorporating a bipartite matching loss, we reduce thedependency of the instruction-based method on the generation sequence. Ourexperimental results demonstrate that MAQInstruct significantly improves theperformance of event relation extraction across multiple LLMs.",Jun Xu,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.03952v1,Bridging the inference gap in Mutimodal Variational Autoencoders,http://arxiv.org/abs/2502.03952v1,"From medical diagnosis to autonomous vehicles, critical applications rely onthe integration of multiple heterogeneous data modalities. MultimodalVariational Autoencoders offer versatile and scalable methods for generatingunobserved modalities from observed ones. Recent models usingmixturesof-experts aggregation suffer from theoretically grounded limitationsthat restrict their generation quality on complex datasets. In this article, wepropose a novel interpretable model able to learn both joint and conditionaldistributions without introducing mixture aggregation. Our model follows amultistage training process: first modeling the joint distribution withvariational inference and then modeling the conditional distributions withNormalizing Flows to better approximate true posteriors. Importantly, we alsopropose to extract and leverage the information shared between modalities toimprove the conditional coherence of generated samples. Our method achievesstate-of-the-art results on several benchmark datasets.",Agathe Senellart,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'stat.ML']"
2502.03950v1,LR0.FM: Low-Resolution Zero-shot Classification Benchmark For Foundation Models,http://arxiv.org/abs/2502.03950v1,"Visual-language foundation Models (FMs) exhibit remarkable zero-shotgeneralization across diverse tasks, largely attributed to extensivepre-training on large-scale datasets. However, their robustness onlow-resolution/pixelated (LR) images, a common challenge in real-worldscenarios, remains underexplored. We introduce LR0.FM, a comprehensivebenchmark evaluating the impact of low resolution on the zero-shotclassification performance of 10 FM(s) across 66 backbones and 15 datasets. Wepropose a novel metric, Weighted Aggregated Robustness, to address thelimitations of existing metrics and better evaluate model performance acrossresolutions and datasets. Our key findings show that: (i) model size positivelycorrelates with robustness to resolution degradation, (ii) pre-training datasetquality is more important than its size, and (iii) fine-tuned andhigher-resolution models are less robust against LR. Our analysis furtherreveals that the model makes semantically reasonable predictions at LR, and thelack of fine-grained details in input adversely impacts the model's initiallayers more than the deeper layers. We use these insights and introduce asimple strategy, LR-TK0, to enhance the robustness of models withoutcompromising their pre-trained weights. We demonstrate the effectiveness ofLR-TK0 for robustness against low-resolution across several datasets and itsgeneralization capability across backbones and other approaches. Code isavailable at this https://github.com/shyammarjit/LR0.FM",Priyank Pathak,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03948v1,Enhancing Online Learning Efficiency Through Heterogeneous Resource Integration with a Multi-Agent RAG System,http://arxiv.org/abs/2502.03948v1,"Efficient online learning requires seamless access to diverse resources suchas videos, code repositories, documentation, and general web content. Thisposter paper introduces early-stage work on a Multi-Agent Retrieval-AugmentedGeneration (RAG) System designed to enhance learning efficiency by integratingthese heterogeneous resources. Using specialized agents tailored for specificresource types (e.g., YouTube tutorials, GitHub repositories, documentationwebsites, and search engines), the system automates the retrieval and synthesisof relevant information. By streamlining the process of finding and combiningknowledge, this approach reduces manual effort and enhances the learningexperience. A preliminary user study confirmed the system's strong usabilityand moderate-high utility, demonstrating its potential to improve theefficiency of knowledge acquisition.",Devansh Srivastav,2025-02-06,2025-02-06,,N/A,"['cs.AI', 'cs.CL', 'cs.MA']"
2502.03946v1,CleanSurvival: Automated data preprocessing for time-to-event models using reinforcement learning,http://arxiv.org/abs/2502.03946v1,"Data preprocessing is a critical yet frequently neglected aspect of machinelearning, often paid little attention despite its potentially significantimpact on model performance. While automated machine learning pipelines arestarting to recognize and integrate data preprocessing into their solutions forclassification and regression tasks, this integration is lacking for morespecialized tasks like survival or time-to-event models. As a result, survivalanalysis not only faces the general challenges of data preprocessing but alsosuffers from the lack of tailored, automated solutions in this area.  To address this gap, this paper presents 'CleanSurvival', areinforcement-learning-based solution for optimizing preprocessing pipelines,extended specifically for survival analysis. The framework can handlecontinuous and categorical variables, using Q-learning to select whichcombination of data imputation, outlier detection and feature extractiontechniques achieves optimal performance for a Cox, random forest, neuralnetwork or user-supplied time-to-event model. The package is available onGitHub: https://github.com/datasciapps/CleanSurvival  Experimental benchmarks on real-world datasets show that the Q-learning-baseddata preprocessing results in superior predictive performance to standardapproaches, finding such a model up to 10 times faster than undirected randomgrid search. Furthermore, a simulation study demonstrates the effectiveness indifferent types and levels of missingness and noise in the data.",Yousef Koka,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.03945v1,Afrispeech-Dialog: A Benchmark Dataset for Spontaneous English Conversations in Healthcare and Beyond,http://arxiv.org/abs/2502.03945v1,"Speech technologies are transforming interactions across various sectors,from healthcare to call centers and robots, yet their performance onAfrican-accented conversations remains underexplored. We introduceAfrispeech-Dialog, a benchmark dataset of 50 simulated medical and non-medicalAfrican-accented English conversations, designed to evaluate automatic speechrecognition (ASR) and related technologies. We assess state-of-the-art (SOTA)speaker diarization and ASR systems on long-form, accented speech, comparingtheir performance with native accents and discover a 10%+ performancedegradation. Additionally, we explore medical conversation summarizationcapabilities of large language models (LLMs) to demonstrate the impact of ASRerrors on downstream medical summaries, providing insights into the challengesand opportunities for speech technologies in the Global South. Our workhighlights the need for more inclusive datasets to advance conversational AI inlow-resource settings.",Mardhiyah Sanni,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.03942v1,A retake on the analysis of scores truncated by terminal events,http://arxiv.org/abs/2502.03942v1,"Analysis of data from randomized controlled trials in vulnerable populationsrequires special attention when assessing treatment effect by a scoremeasuring, e.g., disease stage or activity together with onset of prevalentterminal events. In reality, it is impossible to disentangle a disease scorefrom the terminal event, since the score is not clinically meaningful afterthis event. In this work, we propose to assess treatment interventionssimultaneously on disease score and the terminal event. Our proposal is basedon a natural data-generating mechanism respecting that a disease score does notexist beyond the terminal event. We use modern semi-parametric statisticalmethods to provide robust and efficient estimation of the risk of terminalevent and expected disease score conditional on no terminal event at apre-specified landmark time. We also use the simultaneous asymptotic behaviorof our estimators to develop a powerful closed testing procedure forconfirmatory assessment of treatment effect on both onset of terminal event andlevel of disease score. A simulation study mimicking a large-scale outcometrial in chronic kidney patients as well as an analysis of that trial isprovided to assess performance.",Klaus Kähler Holst,2025-02-06,2025-02-06,,N/A,['stat.ME']
2502.03938v1,Unravelling Causal Genetic Biomarkers of Alzheimer's Disease via Neuron to Gene-token Backtracking in Neural Architecture: A Groundbreaking Reverse-Gene-Finder Approach,http://arxiv.org/abs/2502.03938v1,"Alzheimer's Disease (AD) affects over 55 million people globally, yet the keygenetic contributors remain poorly understood. Leveraging recent advancementsin genomic foundation models, we present the innovative Reverse-Gene-Findertechnology, a ground-breaking neuron-to-gene-token backtracking approach in aneural network architecture to elucidate the novel causal genetic biomarkersdriving AD onset. Reverse-Gene-Finder comprises three key innovations. Firstly,we exploit the observation that genes with the highest probability of causingAD, defined as the most causal genes (MCGs), must have the highest probabilityof activating those neurons with the highest probability of causing AD, definedas the most causal neurons (MCNs). Secondly, we utilize a gene tokenrepresentation at the input layer to allow each gene (known or novel to AD) tobe represented as a discrete and unique entity in the input space. Lastly, incontrast to the existing neural network architectures, which track neuronactivations from the input layer to the output layer in a feed-forward manner,we develop an innovative backtracking method to track backwards from the MCNsto the input layer, identifying the Most Causal Tokens (MCTs) and thecorresponding MCGs. Reverse-Gene-Finder is highly interpretable, generalizable,and adaptable, providing a promising avenue for application in other diseasescenarios.",Victor OK Li,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.03937v1,Quantifying Correlations of Machine Learning Models,http://arxiv.org/abs/2502.03937v1,"Machine Learning models are being extensively used in safety criticalapplications where errors from these models could cause harm to the user. Suchrisks are amplified when multiple machine learning models, which are deployedconcurrently, interact and make errors simultaneously. This paper exploresthree scenarios where error correlations between multiple models arise,resulting in such aggregated risks. Using real-world data, we simulate thesescenarios and quantify the correlations in errors of different models. Ourfindings indicate that aggregated risks are substantial, particularly whenmodels share similar algorithms, training datasets, or foundational models.Overall, we observe that correlations across models are pervasive and likely tointensify with increased reliance on foundational models and widely used publicdatasets, highlighting the need for effective mitigation strategies to addressthese challenges.",Yuanyuan Li,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.NA', 'math.NA']"
2502.03936v1,ICGNN: Graph Neural Network Enabled Scalable Beamforming for MISO Interference Channels,http://arxiv.org/abs/2502.03936v1,"This paper investigates the graph neural network (GNN)-enabled beamformingdesign for interference channels. We propose a model termed interferencechannel GNN (ICGNN) to solve a quality-of-service constrained energy efficiencymaximization problem. The ICGNN is two-stage, where the direction and powerparts of beamforming vectors are learned separately but trained jointly viaunsupervised learning. By formulating the dimensionality of featuresindependent of the transceiver pairs, the ICGNN is scalable with the number oftransceiver pairs. Besides, to improve the performance of the ICGNN, the hybridmaximum ratio transmission and zero-forcing scheme reduces the output ports,the feature enhancement module unifies the two types of links into one type,the subgraph representation enhances the message passing efficiency, and themulti-head attention and residual connection facilitate the feature extracting.Furthermore, we present the over-the-air distributed implementation of theICGNN. Ablation studies validate the effectiveness of key components in theICGNN. Numerical results also demonstrate the capability of ICGNN in achievingnear-optimal performance with an average inference time less than 0.1 ms. Thescalability of ICGNN for unseen problem sizes is evaluated and enhanced bytransfer learning with limited fine-tuning cost. The results of the centralizedand distributed implementations of ICGNN are illustrated.",Changpeng He,2025-02-06,2025-02-06,,N/A,['eess.SP']
2502.03935v1,Thermal Model Calibration of a Squirrel-Cage Induction Machine,http://arxiv.org/abs/2502.03935v1,"Accurate and efficient thermal simulations of induction machines areindispensable for detecting thermal hot spots and hence avoiding potentialmaterial failure in an early design stage. A goal is the better utilization ofthe machines with reduced safety margins due to a better knowledge of thecritical conditions. In this work, the parameters of a two-dimensionalinduction machine model are calibrated according to evidence from measurements,by solving an inverse field problem. The set of parameters comprise materialparameters as well as parameters that model three-dimensional effects. Thisallows a consideration of physical effects without explicit knowledge of itsquantities. First, the accuracy of the approach is studied using an academicexample in combination with synthetic data. Afterwards, it is successfullyapplied to a realistic induction machine model.",Leon Blumrich,2025-02-06,2025-02-06,,N/A,['cs.CE']
2502.03933v1,HEP-JEPA: A foundation model for collider physics using joint embedding predictive architecture,http://arxiv.org/abs/2502.03933v1,We present a transformer architecture-based foundation model for tasks athigh-energy particle colliders such as the Large Hadron Collider. We train themodel to classify jets using a self-supervised strategy inspired by the JointEmbedding Predictive Architecture. We use the JetClass dataset containing 100Mjets of various known particles to pre-train the model with a data-centricapproach -- the model uses a fraction of the jet constituents as the context topredict the embeddings of the unseen target constituents. Our pre-trained modelfares well with other datasets for standard classification benchmark tasks. Wetest our model on two additional downstream tasks: top tagging anddifferentiating light-quark jets from gluon jets. We also evaluate our modelwith task-specific metrics and baselines and compare it with state-of-the-artmodels in high-energy physics. Project site: https://hep-jepa.github.io/,Jai Bardhan,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'hep-ex', 'hep-ph']"
2502.03932v1,Memory-induced current reversal of Brownian motors,http://arxiv.org/abs/2502.03932v1,"Kinetics of biological motors such as kinesin or dynein is notably influencedby viscoelastic intracellular environment. The characteristic relaxation timeof the cytosol is not separable from the colloidal timescale and thereforetheir dynamics is inherently non-Markovian. In this paper we consider a variantof a Brownian motor model, namely a Brownian ratchet immersed in a correlatedthermal bath and analyze how memory influences its dynamics. In particular, wedemonstrate the memory-induced current reversal effect and explain thisphenomenon by applying the effective mass approximation as well as uncoveringthe memory-induced dynamical localization of the motor trajectories in thephase space. Our results reveal new aspects of the role of memory inmicroscopic systems out of thermal equilibrium.",Mateusz Wiśniewski,2025-02-06,2025-02-06,,N/A,"['cond-mat.stat-mech', 'cond-mat.mes-hall', 'cond-mat.soft']"
2502.03930v1,DiTAR: Diffusion Transformer Autoregressive Modeling for Speech Generation,http://arxiv.org/abs/2502.03930v1,"Several recent studies have attempted to autoregressively generate continuousspeech representations without discrete speech tokens by combining diffusionand autoregressive models, yet they often face challenges with excessivecomputational loads or suboptimal outcomes. In this work, we propose DiffusionTransformer Autoregressive Modeling (DiTAR), a patch-based autoregressiveframework combining a language model with a diffusion transformer. Thisapproach significantly enhances the efficacy of autoregressive models forcontinuous tokens and reduces computational demands. DiTAR utilizes adivide-and-conquer strategy for patch generation, where the language modelprocesses aggregated patch embeddings and the diffusion transformersubsequently generates the next patch based on the output of the languagemodel. For inference, we propose defining temperature as the time point ofintroducing noise during the reverse diffusion ODE to balance diversity anddeterminism. We also show in the extensive scaling analysis that DiTAR hassuperb scalability. In zero-shot speech generation, DiTAR achievesstate-of-the-art performance in robustness, speaker similarity, andnaturalness.",Dongya Jia,2025-02-06,2025-02-06,,N/A,"['eess.AS', 'cs.AI', 'cs.CL', 'cs.LG', 'cs.SD']"
2502.03929v1,pyEFPE: An improved post-Newtonian waveform model for inspiralling precessing-eccentric compact binaries,http://arxiv.org/abs/2502.03929v1,"The measurement of spin-precession and orbital eccentricity ingravitational-wave (GW) signals is a key priority in GW astronomy, as theseeffects not only provide insights into the astrophysical formation andevolution of compact binaries but also, if neglected, could introducesignificant biases in parameter estimation, searches, and tests of GeneralRelativity. Despite the growing potential of upcoming LIGO-Virgo-KAGRAobserving runs and future detectors to measure eccentric-precessing signals,accurately and efficiently modeling them remains a challenge. In this work, wepresent pyEFPE, a frequency-domain post-Newtonian (PN) waveform model for theinspiral of precessing-eccentric compact binaries. pyEFPE improves uponprevious models by introducing analytical expressions for the Fourier modeamplitudes, enhancing the numerical stability of the multiple scale analysisframework, and adding recently derived PN corrections, critical to accuratelydescribe signals in GW detectors. Additionally, we simplify the numericalimplementation and introduce a scheme to interpolate the amplitudes, achievinga speedup of up to ~O(20) in the waveform computations, making the modelpractical for data analysis applications. We thoroughly validate pyEFPE bycomparing it to other waveform models in the quasi-circular andeccentric-spin-aligned limits, finding good agreement. Additionally, wedemonstrate pyEFPE's capability to analyze simulated GW events, accuratelyrecovering the parameters of signals described by both pyEFPE and IMRPhenomXP.While pyEFPE still lacks important physical effects, such as higher-order PNcorrections, higher-order modes, mode asymmetries, tidal interactions or themerger-ringdown phase, it represents a significant step towards more completewaveform models, offering a flexible and efficient framework that can beextended in future work to incorporate these effects.",Gonzalo Morras,2025-02-06,2025-02-06,,N/A,"['gr-qc', 'astro-ph.HE', 'astro-ph.IM']"
2502.03928v1,SWIPTNet: A Unified Deep Learning Framework for SWIPT based on GNN and Transfer Learning,http://arxiv.org/abs/2502.03928v1,"This paper investigates the deep learning based approaches for simultaneouswireless information and power transfer (SWIPT). The quality-of-service (QoS)constrained sum-rate maximization problems are, respectively, formulated forpower-splitting (PS) receivers and time-switching (TS) receivers and solved bya unified graph neural network (GNN) based model termed SWIPT net (SWIPTNet).To improve the performance of SWIPTNet, we first propose a single-type outputmethod to reduce the learning complexity and facilitate the satisfaction of QoSconstraints, and then, utilize the Laplace transform to enhance input featureswith the structural information. Besides, we adopt the multi-head attention andlayer connection to enhance feature extracting. Furthermore, we present theimplementation of transfer learning to the SWIPTNet between PS and TSreceivers. Ablation studies show the effectiveness of key components in theSWIPTNet. Numerical results also demonstrate the capability of SWIPTNet inachieving near-optimal performance with millisecond-level inference speed whichis much faster than the traditional optimization algorithms. We also show theeffectiveness of transfer learning via fast convergence and expressivecapability improvement.",Hong Han,2025-02-06,2025-02-06,,N/A,['eess.SP']
2502.03927v1,Free Growth under Tension,http://arxiv.org/abs/2502.03927v1,"Ever since the ground breaking work of Trepat et al. in 2009, we know thatcell colonies growing on a substrate can be under tensile mechanical stress.The origin of tension has so far been attributed to cellular motility forcesbeing oriented outward of the colony. Works in the field mainly revolve aroundhow this orientation of the forces can be explained, ranging from velocityalignment, self-sorting due to self-propulsion, to kenotaxis. In this work, wedemonstrate that tension in growing colonies can also be explained withoutcellular motility forces! Using a combination of well established tissue growthsimulation technique and analytical modelling, we show how tension can arise asa consequence of simple mechanics of growing tissues. Combining these modelswith a minimalistic motility model shows how colonies can expand while undereven larger tension. Furthermore, our results and analytical models providenovel analysis procedures to identify the underlying mechanics.",Chenyun Yao,2025-02-06,2025-02-06,,N/A,"['physics.bio-ph', 'cond-mat.soft', 'q-bio.CB']"
2502.03918v1,Adaptation of Task Goal States from Prior Knowledge,http://arxiv.org/abs/2502.03918v1,"This paper presents a framework to define a task with freedom and variabilityin its goal state. A robot could use this to observe the execution of a taskand target a different goal from the observed one; a goal that is stillcompatible with the task description but would be easier for the robot toexecute. We define the model of an environment state and an environmentvariation, and present experiments on how to interactively create the variationfrom a single task demonstration and how to use this variation to create anexecution plan for bringing any environment into the goal state.",Andrei Costinescu,2025-02-06,2025-02-06,,N/A,"['cs.RO', 'cs.AI']"
2502.03916v1,Experiments with Large Language Models on Retrieval-Augmented Generation for Closed-Source Simulation Software,http://arxiv.org/abs/2502.03916v1,"Large Language Models (LLMs) are increasingly helpful in text generation,even writing code in programming languages based on user prompts written innatural language. They are even applied to generate simulation models formultibody systems from natural language. Research results suggest that LLMssurpass the mere replication of existing code examples, where some LLMs havebeen trained on an open-source multibody simulation code. However, forclosed-source simulation software, such results are not to be expected as theirideas and concepts might differ from other publicly available ones. LLMs canhallucinate for knowledge-intensive tasks, such as model creation, which canlead to wrong responses. This is especially the case for the LLM unknownclosed-source simulation software. The same applies to other internal knowledgekept private to protect intellectual property or data privacy. TheRetrieval-Augmented Generation (RAG) approach might yield a solution for theseknowledge-intensive tasks. This paper explores the application of RAG toclosed-source simulation software and presents first experiments. After a briefintroduction to LLMs, the RAG approach, and the simulation method applied bythe close-source simulation software, several examples are provided to testLLMs' knowledge of the simulation software and the creation of simulationmodels using two RAG systems. The examples show promising results indicatingthe benefits of applying RAG systems to closed-source simulation software,helping to access their knowledge. Nevertheless, they also reveal gaps in theapplied information and open questions for further research.",Andreas Baumann,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.03908v1,Improving and benchmarking NISQ qubit routers,http://arxiv.org/abs/2502.03908v1,"Quantum computers with a limited qubit connectivity require inserting SWAPgates for qubit routing, which increases gate execution errors and the impactof environmental noise due to an overhead in circuit depth. In this work, webenchmark various routing techniques considering random quantum circuits onone-dimensional and square lattice connectivities, employing both analyticaland numerical methods. We introduce circuit fidelity as a comprehensive metricthat captures the effects of SWAP and circuit depth overheads. Leveraging anovel approach based on the SABRE algorithm, we achieve up to $84\%$ higheraverage circuit fidelity for large devices within the NISQ range, compared topreviously existing methods. Additionally, our results highlight that theoptimal routing choice critically depends on the qubit count and the hardwarecharacteristics, including gate fidelities and coherence times.",Vicente Pina-Canelles,2025-02-06,2025-02-06,,N/A,['quant-ph']
2502.03907v1,No Free Lunch in Annotation either: An objective evaluation of foundation models for streamlining annotation in animal tracking,http://arxiv.org/abs/2502.03907v1,"We analyze the capabilities of foundation models addressing the tedious taskof generating annotations for animal tracking. Annotating a large amount ofdata is vital and can be a make-or-break factor for the robustness of atracking model. Robustness is particularly crucial in animal tracking, asaccurate tracking over long time horizons is essential for capturing thebehavior of animals. However, generating additional annotations usingfoundation models can be counterproductive, as the quality of the annotationsis just as important. Poorly annotated data can introduce noise andinaccuracies, ultimately compromising the performance and accuracy of thetrained model. Over-reliance on automated annotations without ensuringprecision can lead to diminished results, making careful oversight and qualitycontrol essential in the annotation process. Ultimately, we demonstrate that athoughtful combination of automated annotations and manually annotated data isa valuable strategy, yielding an IDF1 score of 80.8 against blind usage of SAM2video with an IDF1 score of 65.6.",Emil Mededovic,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03904v1,A Gaussian-Sinc Pulse Shaping Filter for Zak-OTFS,http://arxiv.org/abs/2502.03904v1,"The choice of delay-Doppler domain (DD) pulse shaping filter plays animportant role in determining the performance of Zak-OTFS. Sinc filter has goodmain lobe characteristics (with nulls at information grid points) which is goodfor equalization/detection, but has high side lobes which are detrimental forinput-output (I/O) relation estimation. Whereas, Gaussian filter is highlylocalized with very low side lobes which is good for I/O relation estimation,but has poor main lobe characteristics which is not good forequalization/detection. In this paper, we propose a new filter, termed as {\emGaussian-sinc (GS) filter}, which inherits the complementary strengths of bothGaussian and sinc filters. The proposed filter does not incur time or bandwidthexpansion. We derive closed-form expressions for the I/O relation and noisecovariance of Zak-OTFS with the proposed GS filter. We evaluate the Zak-OTFSperformance for different pulse shaping filters with I/O relation estimatedusing exclusive and embedded pilots. Our results show that the proposed GSfilter achieves better bit error rate (BER) performance compared to otherfilters reported in the literature. For example, with model-free I/O relationestimation using embedded pilot and 8-QAM, the proposed GS filter achieves anSNR gain of about 4 dB at $10^{-2}$ uncoded BER compared to Gaussian and sincfilters, and the SNR gain becomes more than 6 dB at a coded BER of $10^{-4}$with rate-1/2 coding.",Arpan Das,2025-02-06,2025-02-06,,N/A,"['cs.IT', 'eess.SP', 'math.IT']"
2502.03901v1,LeAP: Consistent multi-domain 3D labeling using Foundation Models,http://arxiv.org/abs/2502.03901v1,"Availability of datasets is a strong driver for research on 3D semanticunderstanding, and whilst obtaining unlabeled 3D point cloud data isstraightforward, manually annotating this data with semantic labels istime-consuming and costly. Recently, Vision Foundation Models (VFMs) enableopen-set semantic segmentation on camera images, potentially aiding automaticlabeling. However,VFMs for 3D data have been limited to adaptations of 2Dmodels, which can introduce inconsistencies to 3D labels. This work introducesLabel Any Pointcloud (LeAP), leveraging 2D VFMs to automatically label 3D datawith any set of classes in any kind of application whilst ensuring labelconsistency. Using a Bayesian update, point labels are combined into voxels toimprove spatio-temporal consistency. A novel 3D Consistency Network (3D-CN)exploits 3D information to further improve label quality. Through variousexperiments, we show that our method can generate high-quality 3D semanticlabels across diverse fields without any manual labeling. Further, modelsadapted to new domains using our labels show up to a 34.2 mIoU increase insemantic segmentation tasks.",Simon Gebraad,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.RO']"
2502.03900v1,How to introduce an initial crack in phase field simulations to accurately predict the linear elastic fracture propagation threshold?,http://arxiv.org/abs/2502.03900v1,"Variational phase field fracture models are now widely used to simulate crackpropagation in structures. A critical aspect of these simulations is thecorrect determination of the propagation threshold of pre-existing cracks, asit highly relies on how the initial cracks are implemented. While prior studiesbriefly discuss initial crack implementation techniques, we present here asystematic investigation. Various techniques to introduce initial cracks inphase field fracture simulations are tested, from the crack explicit meshing tothe replacement by a fully damaged phase field, including different variantsfor the boundary conditions. Our focus here is on phase field models aiming toapproximate, in the $\Gamma$-convergence limit, Griffith quasi-staticpropagation in the framework of Linear Elastic Fracture Mechanics. Therefore, asharp crack model from classic linear elastic fracture mechanics based onGriffith criterion is the reference in this work. To assess the differenttechniques to introduce initial cracks, we rely on path-following methods tocompute the sharp crack and the phase field smeared crack solutions. Theunderlying idea is that path-following ensures staying at equilibrium at eachinstant so that any difference between phase field and sharp crack models canbe attributed to numerical artifacts. Thus, by comparing the results from bothmodels, we can provide practical recommendations for reliably incorporatinginitial cracks in phase field fracture simulations. The comparison shows thatan improper initial crack implementation often requires the smeared crack totransition to a one-element-wide phase band to adequately represent adisplacement jump along a crack. This transition increases the energy requiredto propagate the crack, leading to a significant overshoot in theforce-displacement response. The take-home message is that to predict thepropagation threshold accurately and avoid artificial toughening; the crackmust be initialized either setting the phase field to its damage state over aone-element-wide band or meshing the crack explicitly as a one-element-wideslit and imposing the fully cracked state on the crack surface.",Flavien Loiseau,2025-02-06,2025-02-06,,N/A,['cs.CE']
2502.03899v1,A Slicing Model for Transport Networks with Traffic Burst Control and QoS Compliance for Traffic Flows,http://arxiv.org/abs/2502.03899v1,"Network slicing has emerged as a key network technology, providing networkoperators with the means to offer virtual networks to vertical users over asingle physical network infrastructure. Recent research has resulted mainly intechniques for managing and deploying network slices, but the implementation ofnetwork slices on a real physical transport network infrastructure has receivedmuch less attention. Standardization bodies, such as the Internet EngineeringTask Force (IETF), have provided some implementation recommendations. Still,there is a lack of mechanisms to implement network slices capable of handlingtraffic bursts while simultaneously meeting the Quality of Service (QoS)requirements of the traffic flows associated with the slices. In this paper, wepropose a novel fine-grained resource control mechanism to implement transportnetwork slices that meet traffic QoS requirements while both accepting limitedtraffic bursts, and enabling efficient bandwidth sharing within and acrossslices. The mechanism is executed at the edge of the transport network. Theproposed model aligns with current standards on network slicing and has beentested on an experimental platform. Using this platform, we have conducted anextensive experimental campaign that demonstrates that our proposal caneffectively control traffic bursts generated within the network slices whilemaximizing bandwidth utilization across the network.",Aitor Encinas-Alonso,2025-02-06,2025-02-06,,N/A,['cs.NI']
2502.03898v1,Feedback stabilization for a spatial-dependent Sterile Insect Technique model with Allee Effect,http://arxiv.org/abs/2502.03898v1,"This work focuses on feedback control strategies for applying the sterileinsect technique (SIT) to eliminate pest populations. The presentation iscentered on the case of mosquito populations, but most of the results can beextended to other species by adapting the model and selecting appropriateparameter values to describe the reproduction and movement dynamics of thespecies under consideration. In our study, we address the spatial distributionof the population in a two dimensional bounded domain by extending the temporalSIT model analyzed in [2], thereby obtaining a reaction-diffusion SIT model.After the analysis of the existence and the uniqueness of the solution of thisproblem, we construct a feedback law that globally asymptotically stabilizesthe extinction equilibrium thus yielding a robust strategy to keep the pestpopulation at very low levels in the long term.",Kala Agbo bidi,2025-02-06,2025-02-06,,N/A,"['math.AP', 'math.DS', 'math.OC']"
2502.03895v1,Rule-Based Modeling of Low-Dimensional Data with PCA and Binary Particle Swarm Optimization (BPSO) in ANFIS,http://arxiv.org/abs/2502.03895v1,"Fuzzy rule-based systems interpret data in low-dimensional domains, providingtransparency and interpretability. In contrast, deep learning excels in complextasks like image and speech recognition but is prone to overfitting in sparse,unstructured, or low-dimensional data. This interpretability is crucial infields like healthcare and finance. Traditional rule-based systems, especiallyANFIS with grid partitioning, suffer from exponential rule growth asdimensionality increases. We propose a strategic rule-reduction model thatapplies Principal Component Analysis (PCA) on normalized firing strengths toobtain linearly uncorrelated components. Binary Particle Swarm Optimization(BPSO) selectively refines these components, significantly reducing the numberof rules while preserving precision in decision-making. A custom parameterupdate mechanism fine-tunes specific ANFIS layers by dynamically adjusting BPSOparameters, avoiding local minima. We validated our approach on standard UCIrespiratory, keel classification, regression datasets, and a real-worldischemic stroke dataset, demonstrating adaptability and practicality. Resultsindicate fewer rules, shorter training, and high accuracy, underscoring themethods effectiveness for low-dimensional interpretability and complex datascenarios. This synergy of fuzzy logic and optimization fosters robustsolutions. Our method contributes a powerful framework for interpretable AI inmultiple domains. It addresses dimensionality, ensuring a rule base.",Afnan Al-Ali,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03892v1,"A class of positive-preserving,energy stable and high order numerical schemes for the Poission-Nernst-Planck system",http://arxiv.org/abs/2502.03892v1,"In this paper, we introduce and analyze a class of numerical schemes thatdemonstrate remarkable superiority in terms of efficiency, the preservation ofpositivity, energy stability, and high-order precision to solve thetime-dependent Poisson-Nernst-Planck (PNP) system, which is  as a highly versatile and sophisticated model and accommodates a plenitude ofapplications in the emulation of the translocation of charged particles acrossa multifarious expanse of physical and biological systems. The numericalschemes presented here are based on the energy variational formulation. Itallows the PNP system to be reformulated as a non-constant mobility $H^{-1}$gradient flow, incorporating singular logarithmic energy potentials. To achievea fully discrete numerical scheme, we employ a combination offirst/second-order semi-implicit time discretization methods, coupled witheither the $k$-th order direct discontinuous Galerkin (DDG) method or thefinite element (FE) method for spatial discretization. The schemes are verifiedto possess positivity preservation and energy stability. Optimal errorestimates and particular superconvergence results for the fully-discretenumerical solution are established. Numerical experiments are provided toshowcase the accuracy, efficiency, and robustness of the proposed schemes.",Waixiang Cao,2025-02-06,2025-02-06,,N/A,"['math.NA', 'cs.NA']"
2502.03885v1,InfinitePOD: Building Datacenter-Scale High-Bandwidth Domain for LLM with Optical Circuit Switching Transceivers,http://arxiv.org/abs/2502.03885v1,"Scaling Large Language Model (LLM) training relies on multi-dimensionalparallelism, where High-Bandwidth Domains (HBDs) are critical forcommunication-intensive parallelism like Tensor Parallelism (TP) and ExpertParallelism (EP). However, existing HBD architectures face fundamentallimitations in scalability, cost, and fault resiliency: switch-centric HBDs(e.g., NVL-72) incur prohibitive scaling costs, while GPU-centric HBDs (e.g.,TPUv3/Dojo) suffer from severe fault propagation. Switch-GPU hybrid HBDs suchas TPUv4 takes a middle-ground approach by leveraging Optical Circuit Switches,but the fault explosion radius remains large at the cube level (e.g., 64 TPUs).  We propose InfinitePOD, a novel transceiver-centric HBD architecture thatunifies connectivity and dynamic switching at the transceiver level usingOptical Circuit Switching (OCS). By embedding OCS within each transceiver,InfinitePOD achieves reconfigurable point-to-multipoint connectivity, allowingthe topology to adapt into variable-size rings. This design provides: i)datacenter-wide scalability without cost explosion; ii) fault resilience byisolating failures to a single node, and iii) full bandwidth utilization forfault-free GPUs. Key innovations include a Silicon Photonic (SiPh) basedlow-cost OCS transceiver (OCSTrx), a reconfigurable k-hop ring topologyco-designed with intra-/inter-node communication, and an HBD-DCN orchestrationalgorithm maximizing GPU utilization while minimizing cross-ToR datacenternetwork traffic. The evaluation demonstrates that InfinitePOD achieves 31% ofthe cost of NVL-72, near-zero GPU waste ratio (over one order of magnitudelower than NVL-72 and TPUv4), near-zero cross-ToR traffic when node faultratios under 7%, and improves Model FLOPs Utilization by 3.37x compared toNVIDIA DGX (8 GPUs per Node).",Chenchen Shou,2025-02-06,2025-02-06,,N/A,"['cs.NI', 'cs.DC', 'cs.LG']"
2502.03884v1,Rank Also Matters: Hierarchical Configuration for Mixture of Adapter Experts in LLM Fine-Tuning,http://arxiv.org/abs/2502.03884v1,"Large language models (LLMs) have demonstrated remarkable success acrossvarious tasks, accompanied by a continuous increase in their parameter size.Parameter-efficient fine-tuning (PEFT) methods, such as Low-Rank Adaptation(LoRA), address the challenges of fine-tuning LLMs by significantly reducingthe number of trainable parameters. Recent studies have integrated LoRA withMixture of Experts (MoE) architectures, leveraging multiple adapter experts andgating mechanisms to further improve fine-tuning performance. However, existingapproaches primarily focus on adjusting the allocations of adapter experts perlayer to optimize the introduced trainable parameter size, while neglecting acritical factor of adapters' rank. To this end, we propose a hierarchicalscheme for expert allocation and rank configuration, HILO, which dynamicallyadjusts the number and rank of adapter experts across layers, matching thevarying representational complexity of model layers in adapter-granularity.Extensive experiments on multiple benchmark tasks demonstrate that HILOoutperforms existing methods in accuracy while introducing fewer trainableparameters, providing an efficient and practical solution for fine-tuning LLMs.",Peizhuang Cong,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI']"
2502.03882v1,Hierarchical Entropic Diffusion for Ransomware Detection: A Probabilistic Approach to Behavioral Anomaly Isolation,http://arxiv.org/abs/2502.03882v1,"The increasing complexity of cryptographic extortion techniques hasnecessitated the development of adaptive detection frameworks capable ofidentifying adversarial encryption behaviors without reliance on predefinedsignatures. Hierarchical Entropic Diffusion (HED) introduces a structuredentropy-based anomaly classification mechanism that systematically tracksfluctuations in entropy evolution to differentiate between benign cryptographicprocesses and unauthorized encryption attempts. The integration of hierarchicalclustering, entropy profiling, and probabilistic diffusion modeling refinesdetection granularity, ensuring that encryption anomalies are identifieddespite obfuscation strategies or incremental execution methodologies.Experimental evaluations demonstrated that HED maintained high classificationaccuracy across diverse ransomware families, outperforming traditionalheuristic-based and signature-driven approaches while reducing false positiveoccurrences. Comparative analysis highlighted that entropy-driven anomalysegmentation improved detection efficiency under variable system workloadconditions, ensuring real-time classification feasibility. The computationaloverhead associated with entropy anomaly detection remained within operationalconstraints, reinforcing the suitability of entropy-driven classification forlarge-scale deployment. The ability to identify adversarial entropymanipulations before encryption completion contributes to broader cybersecuritydefenses, offering a structured methodology for isolating unauthorizedcryptographic activities within heterogeneous computing environments. Theresults further emphasized that entropy evolution modeling facilitatespredictive anomaly detection, enhancing resilience against encryption evasiontechniques designed to circumvent traditional detection mechanisms.",Vasili Iskorohodov,2025-02-06,2025-02-06,,N/A,['cs.CR']
2502.03879v1,First-order CP phase transition in two-flavor QCD at $θ= π$ under electromagnetic scale anomaly via a Nambu-Jona-Lasinio description,http://arxiv.org/abs/2502.03879v1,"We discuss the thermal CP phase transition in QCD at $\theta=\pi$ under aweak magnetic field background, where the electromagnetic scale anomaly getssignificant. To explicitize, we work on a two-flavor Polyakov-loopNambu-Jona-Lasinio model at $\theta=\pi$ in the mean field approximation,including the electromagnetic-scale anomaly term. We find that the thermal CPphase transition becomes first order and the strength of the first order getsmore prominent as the magnetic field increases. The associated potentialbarrier is thermally created by the electromagnetic scale anomaly and givesrise to criticality due to the induced potential of a non-perturbative form$\sim \frac{|eB|^3}{f_\pi} \frac{|P|}{P^2 + m_0^2}$, where $eB$ denotes themagnetic field strength; $P$ the CP order parameter, and $m_0$ theisospin-symmetric current-quark mass. The CP-broken deconfinement(-like)domain, $T^{\rm (CP)}_c > T^{\rm (dec)}_{\rm pc}$, gets wider as $eB$increases.",Yuanyuan Wang. Shinya Matsuzaki,2025-02-06,2025-02-06,,N/A,"['hep-ph', 'hep-lat', 'hep-th', 'nucl-th']"
2502.03878v1,Sensitivity to Triple Higgs Couplings via Di-Higgs Production in the RxSM at the (HL-)LHC and future $e^+e^-$ Colliders,http://arxiv.org/abs/2502.03878v1,"The real Higgs singlet extension of the Standard Model (SM) without $Z_2$symmetry, the RxSM, is the simplest extension of the SM that features a FirstOrder Electroweak Phase Transition (FOEWPT) in the early universe. The FOEWPTis one of the requirements needed for electroweak baryogenesis to explain thebaryon asymmetry of the universe (BAU). Thus, the RxSM is a perfect example tostudy features related to the FOEWPT at current and future colliderexperiments. The RxSM has two CP-even Higgs bosons, $h$ and $H$, with masses$m_h < m_H$, where we assume that $h$ corresponds to the Higgs boson discoveredat the LHC. Our analysis is based on a benchmark plane that ensures theoccurence of a strong FOEWPT, where $m_H > 2 m_h$ is found. In a first step weanalyze the di-Higgs production at the (HL-)LHC, $gg \to hh$, with a focus onthe impact of the trilinear Higgs couplings (THCs), $\lambda_{hhh}$ and$\lambda_{hhH}$. The interferences of the resonant $H$-exchange diagraminvolving $\lambda_{hhH}$ and the non-resonant diagrams result in acharacteristic peak-dip (or dip-peak) structure in the $m_{hh}$ distribution.We analyze how $\lambda_{hhH}$ can be accessed, taking into account theexperimental smearing and binning. We also demonstrate that the approximationused by ATLAS and CMS for the resonant di-Higgs searches may fail to capturethe relevant effects and lead to erroneous results. In a second step we analyzethe benchmark plane at a future high-energy $e^+e^-$ collider with $\sqrt{s} =1000$ GeV (ILC1000). We demonstrate the potential sensitivity to$\lambda_{hhH}$ via an experimental determination at the ILC1000.",F. Arco,2025-02-06,2025-02-06,,N/A,['hep-ph']
2502.03877v1,Advanced Object Detection and Pose Estimation with Hybrid Task Cascade and High-Resolution Networks,http://arxiv.org/abs/2502.03877v1,"In the field of computer vision, 6D object detection and pose estimation arecritical for applications such as robotics, augmented reality, and autonomousdriving. Traditional methods often struggle with achieving high accuracy inboth object detection and precise pose estimation simultaneously. This studyproposes an improved 6D object detection and pose estimation pipeline based onthe existing 6D-VNet framework, enhanced by integrating a Hybrid Task Cascade(HTC) and a High-Resolution Network (HRNet) backbone. By leveraging thestrengths of HTC's multi-stage refinement process and HRNet's ability tomaintain high-resolution representations, our approach significantly improvesdetection accuracy and pose estimation precision. Furthermore, we introduceadvanced post-processing techniques and a novel model integration strategy thatcollectively contribute to superior performance on public and privatebenchmarks. Our method demonstrates substantial improvements overstate-of-the-art models, making it a valuable contribution to the domain of 6Dobject detection and pose estimation.",Yuhui Jin,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03876v1,Position: Untrained Machine Learning for Anomaly Detection,http://arxiv.org/abs/2502.03876v1,"Anomaly detection based on 3D point cloud data is an important researchproblem and receives more and more attention recently. Untrained anomalydetection based on only one sample is an emerging research problem motivated byreal manufacturing industries such as personalized manufacturing that only onesample can be collected without any additional labels. How to accuratelyidentify anomalies based on one 3D point cloud sample is a critical challengein both industrial applications and the field of machine learning. This paperaims to provide a formal definition of untrained anomaly detection problembased on 3D point cloud data, discuss the differences between untrained anomalydetection and current unsupervised anomaly detection methods. Unlikeunsupervised learning, untrained methods do not rely on any data, includingunlabeled data. Instead, they leverage prior knowledge about the manufacturingsurfaces and anomalies. Examples are used to illustrate these prior knowledgeand untrained machine learning model. Afterwards, literature review onuntrained anomaly detection based on 3D point cloud data is also provided, andthe potential of untrained deep neural networks for anomaly detection is alsodiscussed as outlooks.",Juan Du,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.03874v1,Any theory that admits a Wigner's Friend type multi-agent paradox is logically contextual,http://arxiv.org/abs/2502.03874v1,"Wigner's Friend scenarios push the boundaries of quantum theory by modelingagents, along with their memories storing measurement outcomes, as physicalquantum systems. Extending these ideas beyond quantum theory, we ask: in whichphysical theories, and under what assumptions, can agents who are reasoninglogically about each other's measurement outcomes encounter apparent paradoxes?To address this, we prove a link between Wigner's Friend type multi-agentparadoxes and contextuality in general theories: if agents who are modeledwithin a physical theory come to a contradiction when reasoning using thattheory (under certain assumptions on how they reason and describemeasurements), then the theory must admit contextual correlations of a logicalform. This also yields a link between the distinct fundamental concepts ofHeisenberg cuts and measurement contexts in general theories, and inparticular, implies that the quantum Frauchiger-Renner paradox is a proof oflogical contextuality. Moreover, we identify structural properties of suchparadoxes in general theories and specific to quantum theory. For instance, wedemonstrate that theories admitting behaviors corresponding to extremalvertices of n-cycle contextuality scenarios admit Wigner's Friend typeparadoxes without post-selection, and that any quantum Wigner's Friend paradoxbased on the n-cycle scenario must necessarily involve post-selection. Further,we construct a multi-agent paradox based on a genuine contextuality scenarioinvolving sequential measurements on a single system, showing that Bellnon-local correlations between distinct subsystems are not necessary forWigner's Friend paradoxes. Our work offers an approach to investigate thestructure of physical theories and their information-theoretic resources bymeans of deconstructing the assumptions underlying multi-agent physicalparadoxes.",Nuriya Nurgalieva,2025-02-06,2025-02-06,,N/A,['quant-ph']
2502.03873v1,Oxygen sublattice disorder and valence state modulation in infinite-layer nickelate superlattices,http://arxiv.org/abs/2502.03873v1,"The family of infinite-layer nickelates promises important insights into themechanism of unconventional superconductivity. Since superconductivity has sofar only been observed in epitaxial thin films, heteroepitaxy with thesubstrate or a capping layer possibly plays an important role. Here, we usesoft x-ray spectroscopy to investigate superlattices as a potential approachfor a targeted material design of high-temperature superconductors. We observemodulations in valence state and oxygen coordination in topotactically reducedartificial superlattices with repeating interfaces between nickelate layers andlayers of materials commonly used as substrates and capping layers. Our resultsshow that depending on the interlayer material metallic conductivity akin tothe parent infinite-layer compounds is achieved. Depth-resolved electronicstructure measured by resonant x-ray reflectivity reveals a reconstructedligand field and valence state at the interface, which is confined to one ortwo unit cells. The central layers show characteristics of monovalent nickel,but linear dichroism analysis reveals considerable disorder in the oxygenremoval sites. We observe a quantitative correlation of this disorder with theinterlayer material that is important for future modeling and designstrategies.",R. A. Ortiz,2025-02-06,2025-02-06,,N/A,"['cond-mat.supr-con', 'cond-mat.mtrl-sci', 'cond-mat.str-el']"
2502.03871v1,"Blind Capon Beamformer Based on Independent Component Extraction: Single-Parameter Algorithm,",http://arxiv.org/abs/2502.03871v1,"We consider a phase-shift mixing model for linear sensor arrays in thecontext of blind source extraction. We derive a blind Capon beamformer thatseeks the direction where the output is independent of the other signals in themixture. The algorithm is based on Independent Component Extraction and imposesan orthogonal constraint, thanks to which it optimizes only one real-valuedparameter related to the angle of arrival. The Cram\'er-Rao lower bound for themean interference-to-signal ratio is derived. The algorithm and the bound arecompared with conventional blind and direction-of-arrivalestimation+beamforming methods, showing improvements in terms of extractionaccuracy. An application is demonstrated in frequency-domain speaker extractionin a low-reverberation room.",Zbyněk Koldovský,2025-02-06,2025-02-06,,N/A,"['eess.SP', 'eess.AS']"
2502.03869v1,A microscopic model of de Sitter spacetime with an observer,http://arxiv.org/abs/2502.03869v1,"We introduce a simple microscopic quantum mechanical model of low-dimensionalde Sitter holography with an observer. Using semiclassical gravity andelementary thermodynamic considerations, we derive a formula for the totalentropy of a 3D Schwarzschild-de Sitter universe with an observer. We thenmatch this entropy formula with the exactly known spectral density of thedouble scaled SYK model. Our result gives a de Sitter interpretation of theappearance of two notions of temperature in DSSYK.",Damiano Tietto,2025-02-06,2025-02-06,,N/A,['hep-th']
2502.03868v1,Time-based GNSS attack detection,http://arxiv.org/abs/2502.03868v1,"To safeguard Civilian Global Navigation Satellite Systems (GNSS) externalinformation available to the platform encompassing the GNSS receiver can beused to detect attacks. Cross-checking the GNSS-provided time againstalternative multiple trusted time sources can lead to attack detection aimingat controlling the GNSS receiver time. Leveraging external, network-connectedsecure time providers and onboard clock references, we achieve detection evenunder fine-grained time attacks. We provide an extensive evaluation of ourmulti-layered defense against adversaries mounting attacks against the GNSSreceiver along with controlling the network link. We implement adversariesspanning from simplistic spoofers to advanced ones synchronized with the GNSSconstellation. We demonstrate attack detection is possible in all tested cases(sharp discontinuity, smooth take-over, and coordinated network manipulation)without changes to the structure of the GNSS receiver. Leveraging the diversityof the reference time sources, detection of take-over time push as low as 150usis possible. Smooth take-overs forcing variations as low as 30ns are alsodetected based on on-board precision oscillators. The method (and thus theevaluation) is largely agnostic to the satellite constellation and the attackertype, making time-based data validation of GNSS information compatible withexisting receivers and readily deployable.",Marco Spanghero,2025-02-06,2025-02-06,,N/A,['cs.CR']
2502.03863v1,Compact Nested Hexagonal Metamaterial Sensor for High-Sensitivity Permittivity Characterization Across S and X-Band Frequencies,http://arxiv.org/abs/2502.03863v1,"This article presents a Compact Nested Hexagonal Metamaterial Sensor designedfor microwave sensing to characterize material permittivity in S and X-bandapplications. The proposed sensor attained compact dimensions of merely 30 mm x30 mm x 0.79 mm. This innovative design technique employs a distinctive andcompact architecture with elevated electromagnetic (EM) field strength,enhancing the precision of the sensing mechanism in the microwave frequencyspectrum. The design geometry and dimensions attained resonance frequencies of3.98 GHz and 11.57 GHz, with notch depths of -13.16129 dB and -10.23024 dB,respectively. The design evolution, metamaterial properties, equivalent circuitmodel, and electric (E) is delineated to elucidate the stopband features at theresonant frequency. The suggested sensor attains a very high sensitivity of9.55% in transmission mode (S21) for a permittivity range of 1 to 6. Thereflection and transmission properties of the proposed CRR-based sensor arevalidated by simulations using the mathematical equations of the design.Furthermore, the sensor's performance is corroborated by utilizing severaldielectric materials (Roger R04350B, Roger RT5880 and FR-4). The computedoutcomes demonstrate alignment with the simulated results. The compact,low-profile sensor design and its excellent sensitivity for characterizingmaterial permittivity render the suggested sensor appropriate for permittivitysensing applications.",Md Mujahid Hossain,2025-02-06,2025-02-06,,N/A,['eess.SP']
2502.03862v1,Enhancing Deliberativeness: Evaluating the Impact of Multimodal Reflection Nudges,http://arxiv.org/abs/2502.03862v1,"Nudging participants with text-based reflective nudges enhances deliberationquality on online deliberation platforms. The effectiveness of multimodalreflective nudges, however, remains largely unexplored. Given the multi-sensorynature of human perception, incorporating diverse modalities intoself-reflection mechanisms has the potential to better support variousreflective styles. This paper explores how presenting reflective nudges ofdifferent types (direct: persona and indirect: storytelling) in differentmodalities (text, image, video and audio) affects deliberation quality. Weconducted two user studies with 20 and 200 participants respectively. The firststudy identifies the preferred modality for each type of reflective nudges,revealing that text is most preferred for persona and video is most preferredfor storytelling. The second study assesses the impact of these modalities ondeliberation quality. Our findings reveal distinct effects associated with eachmodality, providing valuable insights for developing more inclusive andeffective online deliberation platforms.",ShunYi Yeo,2025-02-06,2025-02-06,,N/A,['cs.HC']
2502.03861v1,Analysis of Newly Catalogued Open Star Cluster UPK~220 with Gaia DR3 and TESS: Discovering Member Variable Stars,http://arxiv.org/abs/2502.03861v1,"Studies on star clusters with the same age and initial chemical compositionhave gained momentum in recent years with the use of \textit{Gaia}. Inaddition, the discovery of new clusters with Gaia has increased the number ofopen clusters to be examined. Many of these discovered sources areintermediate-age open clusters and have not been analyzed in detail yet. Inthis study, we focused on newly cataloged open cluster UPK~220. The fundamentalparameters (distance, age, metallicity and reddening) of UPK~220 weredetermined by analysing the variable stars within the cluster, whilesimultaneously constraining the parameters of the variable stars using thesecluster parameters. To achieve this, we combined GaiaDR3 and TESS photometricobservations. Using GaiaDR3, we derive fundamental parameters of UPK~220through membership analyses, and with TESS, we discovered eight member variablestars. We also extracted the atmospheric parameters ($logg$, $[Fe/H]$ and$T_{\rm eff}$) for the variable stars using SED, GSP-Phot and GSP-Spec, andMESA models.",İnci Akkaya Oralhan,2025-02-06,2025-02-06,,N/A,"['astro-ph.SR', 'astro-ph.GA']"
2502.03860v1,BOLT: Bootstrap Long Chain-of-Thought in Language Models without Distillation,http://arxiv.org/abs/2502.03860v1,"Large language models (LLMs), such as o1 from OpenAI, have demonstratedremarkable reasoning capabilities. o1 generates a long chain-of-thought(LongCoT) before answering a question. LongCoT allows LLMs to analyze problems,devise plans, reflect, and backtrack effectively. These actions empower LLM tosolve complex problems. After the release of o1, many teams have attempted toreplicate its LongCoT and reasoning capabilities. In terms of methods, theyprimarily rely on knowledge distillation with data from existing models withLongCoT capacities (e.g., OpenAI-o1, Qwen-QwQ, DeepSeek-R1-Preview), leavingsignificant uncertainties on systematically developing such reasoningabilities. In terms of data domains, these works focus narrowly on math while afew others include coding, limiting their generalizability. This paperintroduces a novel approach to enable LLM's LongCoT capacity withoutdistillation from o1-like models or expensive human annotations, where webootstrap LongCoT (BOLT) from a standard instruct model. BOLT involves threestages: 1) LongCoT data bootstrapping with in-context learning on a standardinstruct model; 2) LongCoT supervised finetuning; 3) online training to furtherrefine LongCoT capacities. In BOLT, only a few in-context examples need to beconstructed during the bootstrapping stage; in our experiments, we created 10examples, demonstrating the feasibility of this approach. We useLlama-3.1-70B-Instruct to bootstrap LongCoT and apply our method to variousmodel scales (7B, 8B, 70B). We achieve impressive performance on a variety ofbenchmarks, Arena-Hard, MT-Bench, WildBench, ZebraLogic, MATH500, whichevaluate diverse task-solving and reasoning capabilities.",Bo Pang,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.03856v1,Taking A Closer Look at Interacting Objects: Interaction-Aware Open Vocabulary Scene Graph Generation,http://arxiv.org/abs/2502.03856v1,"Today's open vocabulary scene graph generation (OVSGG) extends traditionalSGG by recognizing novel objects and relationships beyond predefinedcategories, leveraging the knowledge from pre-trained large-scale models. Mostexisting methods adopt a two-stage pipeline: weakly supervised pre-trainingwith image captions and supervised fine-tuning (SFT) on fully annotated scenegraphs. Nonetheless, they omit explicit modeling of interacting objects andtreat all objects equally, resulting in mismatched relation pairs. To this end,we propose an interaction-aware OVSGG framework INOVA. During pre-training,INOVA employs an interaction-aware target generation strategy to distinguishinteracting objects from non-interacting ones. In SFT, INOVA devises aninteraction-guided query selection tactic to prioritize interacting objectsduring bipartite graph matching. Besides, INOVA is equipped with aninteraction-consistent knowledge distillation to enhance the robustness bypushing interacting object pairs away from the background. Extensiveexperiments on two benchmarks (VG and GQA) show that INOVA achievesstate-of-the-art performance, demonstrating the potential of interaction-awaremechanisms for real-world applications.",Lin Li,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03855v1,Semi-rPPG: Semi-Supervised Remote Physiological Measurement with Curriculum Pseudo-Labeling,http://arxiv.org/abs/2502.03855v1,"Remote Photoplethysmography (rPPG) is a promising technique to monitorphysiological signals such as heart rate from facial videos. However, thelabeled facial videos in this research are challenging to collect. Current rPPGresearch is mainly based on several small public datasets collected in simpleenvironments, which limits the generalization and scale of the AI models.Semi-supervised methods that leverage a small amount of labeled data andabundant unlabeled data can fill this gap for rPPG learning. In this study, anovel semi-supervised learning method named Semi-rPPG that combines curriculumpseudo-labeling and consistency regularization is proposed to extract intrinsicphysiological features from unlabelled data without impairing the model fromnoises. Specifically, a curriculum pseudo-labeling strategy withsignal-to-noise ratio (SNR) criteria is proposed to annotate the unlabelleddata while adaptively filtering out the low-quality unlabelled data. Besides, anovel consistency regularization term for quasi-periodic signals is proposedthrough weak and strong augmented clips. To benefit the research onsemi-supervised rPPG measurement, we establish a novel semi-supervisedbenchmark for rPPG learning through intra-dataset and cross-dataset evaluationon four public datasets. The proposed Semi-rPPG method achieves the bestresults compared with three classical semi-supervised methods under differentprotocols. Ablation studies are conducted to prove the effectiveness of theproposed methods.",Bingjie Wu,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03853v1,VERITAS and multiwavelength observations of the Blazar B3 2247+381 in response to an IceCube neutrino alert,http://arxiv.org/abs/2502.03853v1,"While the sources of the diffuse astrophysical neutrino flux detected by theIceCube Neutrino Observatory are still largely unknown, one of the promisingmethods used towards understanding this is investigating the potential temporaland spatial correlations between neutrino alerts and the electromagneticradiation from blazars. We report on the multiwavelength target-of-opportunityobservations of the blazar B3 2247+381, taken in response to an IceCubemultiplet alert for a cluster of muon neutrino events compatible with thesource location between May 20, 2022 and November 10, 2022. B3 2247+381 was notdetected with VERITAS during this time period. The source was found to be in alow-flux state in the optical, ultraviolet and gamma-ray bands for the timeinterval corresponding to the neutrino event, but was detected in the hardX-ray band with NuSTAR during this period. We find the multiwavelength spectralenergy distribution is well described using a simple one-zone leptonicsynchrotron self-Compton radiation model. Moreover, assuming the neutrinosoriginate from hadronic processes within the jet, the neutrino flux would beaccompanied by a photon flux from the cascade emission, and the integratedphoton flux required in such a case would significantly exceed the totalmultiwavelength fluxes and the VERITAS upper limits presented here. The lack offlaring activity observed with VERITAS, combined with the low multiwavelengthflux levels, and given the significance of the neutrino excess is at 3$\sigma$level (uncorrected for trials), makes B3 2247+381 an unlikely source of theIceCube multiplet. We conclude that the neutrino excess is likely a backgroundfluctuation.",Atreya Acharyya,2025-02-06,2025-02-06,,N/A,['astro-ph.HE']
2502.03852v1,Pursuing Better Decision Boundaries for Long-Tailed Object Detection via Category Information Amount,http://arxiv.org/abs/2502.03852v1,"In object detection, the instance count is typically used to define whether adataset exhibits a long-tail distribution, implicitly assuming that models willunderperform on categories with fewer instances. This assumption has led toextensive research on category bias in datasets with imbalanced instancecounts. However, models still exhibit category bias even in datasets whereinstance counts are relatively balanced, clearly indicating that instance countalone cannot explain this phenomenon. In this work, we first introduce theconcept and measurement of category information amount. We observe asignificant negative correlation between category information amount andaccuracy, suggesting that category information amount more accurately reflectsthe learning difficulty of a category. Based on this observation, we proposeInformation Amount-Guided Angular Margin (IGAM) Loss. The core idea of IGAM isto dynamically adjust the decision space of each category based on itsinformation amount, thereby reducing category bias in long-tail datasets. IGAMLoss not only performs well on long-tailed benchmark datasets such as LVIS v1.0and COCO-LT but also shows significant improvement for underrepresentedcategories in the non-long-tailed dataset Pascal VOC. Comprehensive experimentsdemonstrate the potential of category information amount as a tool and thegenerality of our proposed method.",Yanbiao Ma,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.AI']"
2502.03851v1,Frustration In Physiology And Molecular Medicine,http://arxiv.org/abs/2502.03851v1,"Molecules provide the ultimate language in terms of which physiology andpathology must be understood. Myriads of proteins participate in elaboratenetworks of interactions and perform chemical activities coordinating the lifeof cells. To perform these often amazing tasks, proteins must move and we mustthink of them as dynamic ensembles of three dimensional structures formed firstby folding the polypeptide chains so as to minimize the conflicts between theinteractions of their constituent amino acids. It is apparent however that,even when completely folded, not all conflicting interactions have beenresolved so the structure remains ""locally frustrated"". Over the last decadesit has become clearer that this local frustration is not just a random accidentbut plays an essential part of the inner workings of protein molecules. We willreview here the physical origins of the frustration concept and review evidencethat local frustration is important for protein physiology, protein-proteinrecognition, catalysis and allostery. Also, we highlight examples showing howalterations in the local frustration patterns can be linked to distinctpathologies. Finally we explore the extensions of the impact of frustration inhigher order levels of organization of systems including gene regulatorynetworks and the neural networks of the brain.",R. Gonzalo Parra,2025-02-06,2025-02-06,,N/A,['q-bio.BM']
2502.03850v1,Electromagnetic Channel Modeling and Capacity Analysis for HMIMO Communications,http://arxiv.org/abs/2502.03850v1,"Advancements in emerging technologies, e.g., reconfigurable intelligentsurfaces and holographic MIMO (HMIMO), facilitate unprecedented manipulation ofelectromagnetic (EM) waves, significantly enhancing the performance of wirelesscommunication systems. To accurately characterize the achievable performancelimits of these systems, it is crucial to develop a universal EM-compliantchannel model. This paper addresses this necessity by proposing a comprehensiveEM channel model tailored for realistic multi-path environments, accounting forthe combined effects of antenna array configurations and propagation conditionsin HMIMO communications. Both polarization phenomena and spatial correlationare incorporated into this probabilistic channel model. Additionally, physicalconstraints of antenna configurations, such as mutual coupling effects andenergy consumption, are integrated into the channel modeling framework.Simulation results validate the effectiveness of the proposed probabilisticchannel model, indicating that traditional Rician and Rayleigh fading modelscannot accurately depict the channel characteristics and underestimate thechannel capacity. More importantly, the proposed channel model outperformsfree-space Green's functions in accurately depicting both near-field gain andmulti-path effects in radiative near-field regions. These gains are much moreevident in tri-polarized systems, highlighting the necessity of polarizationinterference elimination techniques. Moreover, the theoretical analysisaccurately verifies that capacity decreases with expanding communicationregions of two-user communications.",Li Wei,2025-02-06,2025-02-06,,N/A,"['cs.IT', 'eess.SP', 'math.IT']"
2502.03848v1,Consistent model selection in a collection of stochastic block models,http://arxiv.org/abs/2502.03848v1,"We introduce the penalized Krichevsky-Trofimov (KT) estimator as a convergentmethod for estimating the number of nodes clusters when observing multiplenetworks within both multi-layer and dynamic Stochastic Block Models. Weestablish the consistency of the KT estimator, showing that it converges to thecorrect number of clusters in both types of models when the number of nodes inthe networks increases. Our estimator does not require a known upper bound onthis number to be consistent. Furthermore, we show that these consistencyresults hold in both dense and sparse regimes, making the penalized KTestimator robust across various network configurations. We illustrate itsperformance on synthetic datasets.",Lucie Arts,2025-02-06,2025-02-06,,N/A,"['math.ST', 'stat.TH']"
2502.03846v1,On the limits of some Bayesian model evaluation statistics,http://arxiv.org/abs/2502.03846v1,"Model selection and order selection problems frequently arise in statisticalpractice. A popular approach to addressing these problems in the frequentistsetting involves information criteria based on penalized maxima oflog-likelihoods for competing models. In the Bayesian context, similar criteriaare employed, replacing the maxima of log-likelihoods with their posteriorexpectations. Despite their popularity in applications, the large-samplebehavior of these criteria -- such as the deviance information criterion (DIC),Bayesian predictive information criterion (BPIC), and widely-applicableBayesian information criterion (WBIC) -- has received relatively littleattention. In this work, we investigate the almost sure limits of thesecriteria and establish novel results on posterior and generalized posteriorconsistency, which are of independent interest. The utility of our theoreticalfindings is demonstrated via illustrative technical and numerical examples.",Hien Duy Nguyen,2025-02-06,2025-02-06,,N/A,"['math.ST', 'stat.TH']"
2502.03845v1,PAGNet: Pluggable Adaptive Generative Networks for Information Completion in Multi-Agent Communication,http://arxiv.org/abs/2502.03845v1,"For partially observable cooperative tasks, multi-agent systems must developeffective communication and understand the interplay among agents in order toachieve cooperative goals. However, existing multi-agent reinforcement learning(MARL) with communication methods lack evaluation metrics for informationweights and information-level communication modeling. This causes agents toneglect the aggregation of multiple messages, thereby significantly reducingpolicy learning efficiency. In this paper, we propose pluggable adaptivegenerative networks (PAGNet), a novel framework that integrates generativemodels into MARL to enhance communication and decision-making. PAGNet enablesagents to synthesize global states representations from weighted localobservations and use these representations alongside learned communicationweights for coordinated decision-making. This pluggable approach reduces thecomputational demands typically associated with the joint training ofcommunication and policy networks. Extensive experimental evaluations acrossdiverse benchmarks and communication scenarios demonstrate the significantperformance improvements achieved by PAGNet. Furthermore, we analyze theemergent communication patterns and the quality of generated global states,providing insights into operational mechanisms.",Zhuohui Zhang,2025-02-06,2025-02-06,,N/A,['cs.MA']
2502.03843v1,Improving Natural Language Understanding for LLMs via Large-Scale Instruction Synthesis,http://arxiv.org/abs/2502.03843v1,"High-quality, large-scale instructions are crucial for aligning largelanguage models (LLMs), however, there is a severe shortage of instruction inthe field of natural language understanding (NLU). Previous works onconstructing NLU instructions mainly focus on information extraction (IE),neglecting tasks such as machine reading comprehension, question answering, andtext classification. Furthermore, the lack of diversity in the data has led toa decreased generalization ability of trained LLMs in other NLU tasks and anoticeable decline in the fundamental model's general capabilities. To addressthis issue, we propose Hum, a large-scale, high-quality synthetic instructioncorpus for NLU tasks, designed to enhance the NLU capabilities of LLMs.Specifically, Hum includes IE (either close IE or open IE), machine readingcomprehension, text classification, and instruction generalist tasks, therebyenriching task diversity. Additionally, we introduce a human-LLMs collaborativemechanism to synthesize instructions, which enriches instruction diversity byincorporating guidelines, preference rules, and format variants. We conductextensive experiments on 5 NLU tasks and 28 general capability evaluationdatasets for LLMs. Experimental results show that Hum enhances the NLUcapabilities of six LLMs by an average of 3.1\%, with no significant declineobserved in other general capabilities.",Lin Yuan,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.03836v1,Adapting Human Mesh Recovery with Vision-Language Feedback,http://arxiv.org/abs/2502.03836v1,"Human mesh recovery can be approached using either regression-based oroptimization-based methods. Regression models achieve high pose accuracy butstruggle with model-to-image alignment due to the lack of explicit 2D-3Dcorrespondences. In contrast, optimization-based methods align 3D models to 2Dobservations but are prone to local minima and depth ambiguity. In this work,we leverage large vision-language models (VLMs) to generate interactive bodypart descriptions, which serve as implicit constraints to enhance 3D perceptionand limit the optimization space. Specifically, we formulate monocular humanmesh recovery as a distribution adaptation task by integrating both 2Dobservations and language descriptions. To bridge the gap between text and 3Dpose signals, we first train a text encoder and a pose VQ-VAE, aligning textsto body poses in a shared latent space using contrastive learning.Subsequently, we employ a diffusion-based framework to refine the initialparameters guided by gradients derived from both 2D observations and textdescriptions. Finally, the model can produce poses with accurate 3D perceptionand image consistency. Experimental results on multiple benchmarks validate itseffectiveness. The code will be made publicly available.",Chongyang Xu,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03835v1,Single-Domain Generalized Object Detection by Balancing Domain Diversity and Invariance,http://arxiv.org/abs/2502.03835v1,"Single-domain generalization for object detection (S-DGOD) aims to transferknowledge from a single source domain to unseen target domains. In recentyears, many models have focused primarily on achieving feature invariance toenhance robustness. However, due to the inherent diversity across domains, anexcessive emphasis on invariance can cause the model to overlook the actualdifferences between images. This overemphasis may complicate the trainingprocess and lead to a loss of valuable information. To address this issue, wepropose the Diversity Invariance Detection Model (DIDM), which focuses on thebalance between the diversity of domain-specific and invariance cross domains.Recognizing that domain diversity introduces variations in domain-specificfeatures, we introduce a Diversity Learning Module (DLM). The DLM is designedto preserve the diversity of domain-specific information with proposed featurediversity loss while limiting the category semantics in the features. Inaddition, to maintain domain invariance, we incorporate a Weighted AligningModule (WAM), which aligns features without compromising feature diversity. Weconducted our model on five distinct datasets, which have illustrated thesuperior performance and effectiveness of the proposed model.",Zhenwei He,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03833v1,Properties of the emission region in pulsars with opposite subpulse drift directions in different profile components,http://arxiv.org/abs/2502.03833v1,"We investigate properties of the emission region as revealed by driftingsubpulses of opposite drift directions at different parts of a pulse profile byusing the rotating carousel model in an obliquely rotating pulsar magnetosphereof multiple emission states. Subpulse emission is assumed coming from mdiscrete emission areas that are distributed around the magnetic axis on arotating carousel. The flow rate of the emission areas is determined by the E xB drift in an emission state, designated by the parameter y, in which E and theassociated flow rate are dependent on y. In this model, subpulses appear todrift in an emission state if a relative speed exists between the plasma flowand corotation, and the diversity in the drift rates and directions correspondsto the relative speed being different in different parts of a profile. We applythe model to three pulsars that exhibit drifting subpulses of opposite driftdirections to identify the emission states and the values of m. Our resultsshow that different drifting subpulses correspond to particular values of m andy, and the latter implies that different emission states can coexist andoperate concurrently in an emission region. We find that m does not show cleardependency on either the obliquity angle or emission state. We demonstrate thatsubpulse arrangement may vary across an emission region meaning that it is notalways uniform on a carousel. We discuss drifting subpulses of opposite driftdirections and subpulse drift-rate switching in terms of different emissionstates in our model, and speculate that they may be two manifestations of thesame underlying mechanism.",H. M. Tedila,2025-02-06,2025-02-06,,N/A,['astro-ph.HE']
2502.03832v1,Correlated helimagnetic configuration in a nonsymmorphic magnetic nodal semimetal,http://arxiv.org/abs/2502.03832v1,"Nonsymmorphic magnetic Weyl semimetal materials such as ReAlX (Re=rare earth,X=Si/Ge) provide a unique opportunity to explore the correlated phenomenabetween Weyl fermions and nontrivial magnetic configurations. To be specific,we study a lattice model in which the magnetic configuration is determined bythe competition among ferromagnetic (FM) interaction, the Dzyaloshinsky-Moriyainteraction, and the Kondo coupling $K_0$ to the Weyl fermion. Both quantum andfinite-temperature phase transitions between FM and correlated nesting helicalconfigurations are found. Different from the uncorrelated helimagnet thatdecouples to the Weyl fermions, this correlated helimagnet induces a magneticBrillouin zone with a $K_0$-dependent nesting in the band structure of theconducting fermions instead of the magnetic monopole-like Weyl cone. Bymeasuring the current induced by the chiral magnetic effect on the conductingfermion with nesting Weyl nodes, one can distinguish the correlated nestinghelical order and the ferromagnetism because the chiral magnetic effect isconsiderably suppressed in the former case. These properties we study here mayexplain the experimental observations in ReAlX.",Xi Luo,2025-02-06,2025-02-06,,N/A,['cond-mat.mes-hall']
2502.03831v1,Optimizing Bayesian model selection for equation of state of cold neutron stars,http://arxiv.org/abs/2502.03831v1,"We introduce a computational framework, Bayesian Evidence calculation fOrModel Selection (BEOMS) to evaluate multiple Bayesian model selection methodsin the context of determining the equation of state (EOS) for cold neutron star(NS), focusing on their performance with current and next-generationgravitational wave (GW) observatories. We conduct a systematic comparison ofvarious EOS models by using posterior distributions obtained from EOS-agnosticBayesian inference of binary parameters applied to GWs from a population ofbinary neutron star (BNS) mergers. The cumulative evidence for each model iscalculated in a multi-dimensional parameter space characterized by neutron starmasses and tidal deformabilities. Our findings indicate that Bayesian modelselection is most effective when performed in the two-dimensional subspace ofcomponent mass and tidal deformability, requiring fewer events to distinguishbetween EOS models with high confidence. Furthermore, we establish arelationship between the precision of tidal deformability measurements and theaccuracy of model selection, taking into account the evolving sensitivities ofcurrent and planned GW observatories. BEOMS offers computational efficiency andcan be adapted to execute model selection for gravitational wave data fromother sources.",Rahul Kashyap,2025-02-06,2025-02-06,,N/A,"['gr-qc', 'astro-ph.HE', 'astro-ph.IM']"
2502.03829v1,FE-UNet: Frequency Domain Enhanced U-Net with Segment Anything Capability for Versatile Image Segmentation,http://arxiv.org/abs/2502.03829v1,"Image segmentation is a critical task in visual understanding. ConvolutionalNeural Networks (CNNs) are predisposed to capture high-frequency features inimages, while Transformers exhibit a contrasting focus on low-frequencyfeatures. In this paper, we experimentally quantify the contrast sensitivityfunction of CNNs and compare it with that of the human visual system, informedby the seminal experiments of Mannos and Sakrison. Leveraging these insights,we propose the Wavelet-Guided Spectral Pooling Module (WSPM) to enhance andbalance image features across the frequency domain. To further emulate thehuman visual system, we introduce the Frequency Domain Enhanced Receptive FieldBlock (FE-RFB), which integrates WSPM to extract enriched features from thefrequency domain. Building on these innovations, we develop FE-UNet, a modelthat utilizes SAM2 as its backbone and incorporates Hiera-Large as apre-trained block, designed to enhance generalization capabilities whileensuring high segmentation accuracy. Experimental results demonstrate thatFE-UNet achieves state-of-the-art performance in diverse tasks, includingmarine animal and polyp segmentation, underscoring its versatility andeffectiveness.",Guohao Huo,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03827v1,"A comprehensive survey of contemporary Arabic sentiment analysis: Methods, Challenges, and Future Directions",http://arxiv.org/abs/2502.03827v1,"Sentiment Analysis, a popular subtask of Natural Language Processing, employscomputational methods to extract sentiment, opinions, and other subjectiveaspects from linguistic data. Given its crucial role in understanding humansentiment, research in sentiment analysis has witnessed significant growth inthe recent years. However, the majority of approaches are aimed at the Englishlanguage, and research towards Arabic sentiment analysis remains relativelyunexplored. This paper presents a comprehensive and contemporary survey ofArabic Sentiment Analysis, identifies the challenges and limitations ofexisting literature in this field and presents avenues for future research. Wepresent a systematic review of Arabic sentiment analysis methods, focusingspecifically on research utilizing deep learning. We then situate ArabicSentiment Analysis within the broader context, highlighting research gaps inArabic sentiment analysis as compared to general sentiment analysis. Finally,we outline the main challenges and promising future directions for research inArabic sentiment analysis.",Zhiqiang Shi,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.03826v1,FairT2I: Mitigating Social Bias in Text-to-Image Generation via Large Language Model-Assisted Detection and Attribute Rebalancing,http://arxiv.org/abs/2502.03826v1,"The proliferation of Text-to-Image (T2I) models has revolutionized contentcreation, providing powerful tools for diverse applications ranging fromartistic expression to educational material development and marketing. Despitethese technological advancements, significant ethical concerns arise from thesemodels' reliance on large-scale datasets that often contain inherent societalbiases. These biases are further amplified when AI-generated content isincluded in training data, potentially reinforcing and perpetuating stereotypesin the generated outputs. In this paper, we introduce FairT2I, a novelframework that harnesses large language models to detect and mitigate socialbiases in T2I generation. Our framework comprises two key components: (1) anLLM-based bias detection module that identifies potential social biases ingenerated images based on text prompts, and (2) an attribute rebalancing modulethat fine-tunes sensitive attributes within the T2I model to mitigateidentified biases. Our extensive experiments across various T2I models anddatasets show that FairT2I can significantly reduce bias while maintaininghigh-quality image generation. We conducted both qualitative user studies andquantitative non-parametric analyses in the generated image feature space,building upon the occupational dataset introduced in the Stable Bias study. Ourresults show that FairT2I successfully mitigates social biases and enhances thediversity of sensitive attributes in generated images. We further demonstrate,using the P2 dataset, that our framework can detect subtle biases that arechallenging for human observers to perceive, extending beyondoccupation-related prompts. On the basis of these findings, we introduce a newbenchmark dataset for evaluating bias in T2I models.",Jinya Sakurai,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03825v1,Synthetic Poisoning Attacks: The Impact of Poisoned MRI Image on U-Net Brain Tumor Segmentation,http://arxiv.org/abs/2502.03825v1,"Deep learning-based medical image segmentation models, such as U-Net, rely onhigh-quality annotated datasets to achieve accurate predictions. However, theincreasing use of generative models for synthetic data augmentation introducespotential risks, particularly in the absence of rigorous quality control. Inthis paper, we investigate the impact of synthetic MRI data on the robustnessand segmentation accuracy of U-Net models for brain tumor segmentation.Specifically, we generate synthetic T1-contrast-enhanced (T1-Ce) MRI scansusing a GAN-based model with a shared encoding-decoding framework andshortest-path regularization. To quantify the effect of synthetic datacontamination, we train U-Net models on progressively ""poisoned"" datasets,where synthetic data proportions range from 16.67% to 83.33%. Experimentalresults on a real MRI validation set reveal a significant performancedegradation as synthetic data increases, with Dice coefficients dropping from0.8937 (33.33% synthetic) to 0.7474 (83.33% synthetic). Accuracy andsensitivity exhibit similar downward trends, demonstrating the detrimentaleffect of synthetic data on segmentation robustness. These findings underscorethe importance of quality control in synthetic data integration and highlightthe risks of unregulated synthetic augmentation in medical image analysis. Ourstudy provides critical insights for the development of more reliable andtrustworthy AI-driven medical imaging systems.",Tianhao Li,2025-02-06,2025-02-06,,N/A,"['eess.IV', 'cs.CR', 'cs.CV']"
2502.03824v1,Syntriever: How to Train Your Retriever with Synthetic Data from LLMs,http://arxiv.org/abs/2502.03824v1,"LLMs have boosted progress in many AI applications. Recently, there wereattempts to distill the vast knowledge of LLMs into information retrievalsystems. Those distillation methods mostly use output probabilities of LLMswhich are unavailable in the latest black-box LLMs. We propose Syntriever, atraining framework for retrievers using synthetic data from black-box LLMs.Syntriever consists of two stages. Firstly in the distillation stage, wesynthesize relevant and plausibly irrelevant passages and augmented queriesusing chain-of-thoughts for the given queries. LLM is asked to self-verify thesynthetic data for possible hallucinations, after which retrievers are trainedwith a loss designed to cluster the embeddings of relevant passages. Secondlyin the alignment stage, we align the retriever with the preferences of LLMs. Wepropose a preference modeling called partial Plackett-Luce ranking to learn LLMpreferences with regularization which prevents the model from deviatingexcessively from that trained in the distillation stage. Experiments show thatSyntriever achieves state-of-the-art performances on benchmark datasets fromvarious domains in nDCG@$K$. The code is available at\href{https://github.com/kmswin1/Syntriever}{https://github.com/kmswin1/Syntriever}.",Minsang Kim,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.03822v1,Dynamic Rank Adjustment in Diffusion Policies for Efficient and Flexible Training,http://arxiv.org/abs/2502.03822v1,"Diffusion policies trained via offline behavioral cloning have recentlygained traction in robotic motion generation. While effective, these policiestypically require a large number of trainable parameters. This model sizeaffords powerful representations but also incurs high computational cost duringtraining. Ideally, it would be beneficial to dynamically adjust the trainableportion as needed, balancing representational power with computationalefficiency. For example, while overparameterization enables diffusion policiesto capture complex robotic behaviors via offline behavioral cloning, theincreased computational demand makes online interactive imitation learningimpractical due to longer training time. To address this challenge, we presenta framework, called DRIFT, that uses the Singular Value Decomposition to enabledynamic rank adjustment during diffusion policy training. We implement anddemonstrate the benefits of this framework in DRIFT-DAgger, an imitationlearning algorithm that can seamlessly slide between an offline bootstrappingphase and an online interactive phase. We perform extensive experiments tobetter understand the proposed framework, and demonstrate that DRIFT-DAggerachieves improved sample efficiency and faster training with minimal impact onmodel performance.",Xiatao Sun,2025-02-06,2025-02-06,,N/A,['cs.RO']
2502.03821v1,PsyPlay: Personality-Infused Role-Playing Conversational Agents,http://arxiv.org/abs/2502.03821v1,"The current research on Role-Playing Conversational Agents (RPCAs) with LargeLanguage Models (LLMs) primarily focuses on imitating specific speaking stylesand utilizing character backgrounds, neglecting the depiction of deeperpersonality traits.~In this study, we introduce personality-infusedrole-playing for LLM agents, which encourages agents to accurately portraytheir designated personality traits during dialogues. We then propose PsyPlay,a dialogue generation framework that facilitates the expression of richpersonalities among multiple LLM agents. Specifically, PsyPlay enables agentsto assume roles with distinct personality traits and engage in discussionscentered around specific topics, consistently exhibiting their designatedpersonality traits throughout the interactions. Validation on generateddialogue data demonstrates that PsyPlay can accurately portray the intendedpersonality traits, achieving an overall success rate of 80.31% on GPT-3.5.Notably, we observe that LLMs aligned with positive values are more successfulin portraying positive personality roles compared to negative ones. Moreover,we construct a dialogue corpus for personality-infused role-playing, calledPsyPlay-Bench. The corpus, which consists of 4745 instances of correctlyportrayed dialogues using PsyPlay, aims to further facilitate research inpersonalized role-playing and dialogue personality detection.",Tao Yang,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.03817v1,Knowing When to Stop Matters: A Unified Algorithm for Online Conversion under Horizon Uncertainty,http://arxiv.org/abs/2502.03817v1,"This paper investigates the online conversion problem, which involvessequentially trading a divisible resource (e.g., energy) under dynamicallychanging prices to maximize profit. A key challenge in online conversion ismanaging decisions under horizon uncertainty, where the duration of trading iseither known, revealed partway, or entirely unknown. We propose a unifiedalgorithm that achieves optimal competitive guarantees across these horizonmodels, accounting for practical constraints such as box constraints, whichlimit the maximum allowable trade per step. Additionally, we extend thealgorithm to a learning-augmented version, leveraging horizon predictions toadaptively balance performance: achieving near-optimal results when predictionsare accurate while maintaining strong guarantees when predictions areunreliable. These results advance the understanding of online conversion undervarious degrees of horizon uncertainty and provide more practical strategies toaddress real world constraints.",Yanzhao Wang,2025-02-06,2025-02-06,,N/A,"['cs.DS', 'cs.LG']"
2502.03814v1,Large Language Models for Multi-Robot Systems: A Survey,http://arxiv.org/abs/2502.03814v1,"The rapid advancement of Large Language Models (LLMs) has opened newpossibilities in Multi-Robot Systems (MRS), enabling enhanced communication,task planning, and human-robot interaction. Unlike traditional single-robot andmulti-agent systems, MRS poses unique challenges, including coordination,scalability, and real-world adaptability. This survey provides the firstcomprehensive exploration of LLM integration into MRS. It systematicallycategorizes their applications across high-level task allocation, mid-levelmotion planning, low-level action generation, and human intervention. Wehighlight key applications in diverse domains, such as household robotics,construction, formation control, target tracking, and robot games, showcasingthe versatility and transformative potential of LLMs in MRS. Furthermore, weexamine the challenges that limit adapting LLMs in MRS, including mathematicalreasoning limitations, hallucination, latency issues, and the need for robustbenchmarking systems. Finally, we outline opportunities for future research,emphasizing advancements in fine-tuning, reasoning techniques, andtask-specific models. This survey aims to guide researchers in the intelligenceand real-world deployment of MRS powered by LLMs. Based on the fast-evolvingnature of research in the field, we keep updating the papers in the open-sourceGithub repository.",Peihan Li,2025-02-06,2025-02-06,,N/A,"['cs.RO', 'cs.AI']"
2502.03813v1,Optimized Unet with Attention Mechanism for Multi-Scale Semantic Segmentation,http://arxiv.org/abs/2502.03813v1,"Semantic segmentation is one of the core tasks in the field of computervision, and its goal is to accurately classify each pixel in an image. Thetraditional Unet model achieves efficient feature extraction and fusion throughan encoder-decoder structure, but it still has certain limitations when dealingwith complex backgrounds, long-distance dependencies, and multi-scale targets.To this end, this paper proposes an improved Unet model combined with anattention mechanism, introduces channel attention and spatial attentionmodules, enhances the model's ability to focus on important features, andoptimizes skip connections through a multi-scale feature fusion strategy,thereby improving the combination of global semantic information andfine-grained features. The experiment is based on the Cityscapes dataset andcompared with classic models such as FCN, SegNet, DeepLabv3+, and PSPNet. Theimproved model performs well in terms of mIoU and pixel accuracy (PA), reaching76.5% and 95.3% respectively. The experimental results verify the superiorityof this method in dealing with complex scenes and blurred target boundaries. Inaddition, this paper discusses the potential of the improved model in practicalapplications and future expansion directions, indicating that it has broadapplication value in fields such as autonomous driving, remote sensing imageanalysis, and medical image processing.",Xuan Li,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03812v1,Numerical study on wave attenuation via 2D fully kinetic electromagnetic particle-in-cell simulations,http://arxiv.org/abs/2502.03812v1,"The propagation and absorption of electromagnetic waves in plasma is one ofthe fundamental issues in plasma physics. The electromagnetic particle-in-cellmethod with the finite-difference time-domain solver plus Monte Carlo collisionmodel would be the most accurate method to simulate the wave-plasmainteraction. However, the numerical effects of this method have not beencarefully investigated especially in two dimensions. In this paper, the 2D PICmethod is used to study the electromagnetic wave attenuation by fluorescentlamp plasma tubes. The study finds that the number of macro-particles and theincident electromagnetic wave amplitude have minor effects on the waveattenuation within a certain appropriate parameter range. Furthermore, theeffects of electromagnetic wave frequency, the plasma distribution structures,and collision types on wave attenuation are investigated. Particularly, it isfound that the staggered way of arranging the plasma tubes can achieve betterwave attenuation than the parallel way, which agrees with our recentexperimental observation.",Fei Du,2025-02-06,2025-02-06,,N/A,['physics.plasm-ph']
2502.03810v1,DeblurDiff: Real-World Image Deblurring with Generative Diffusion Models,http://arxiv.org/abs/2502.03810v1,"Diffusion models have achieved significant progress in image generation. Thepre-trained Stable Diffusion (SD) models are helpful for image deblurring byproviding clear image priors. However, directly using a blurry image orpre-deblurred one as a conditional control for SD will either hinder accuratestructure extraction or make the results overly dependent on the deblurringnetwork. In this work, we propose a Latent Kernel Prediction Network (LKPN) toachieve robust real-world image deblurring. Specifically, we co-train the LKPNin latent space with conditional diffusion. The LKPN learns a spatially variantkernel to guide the restoration of sharp images in the latent space. Byapplying element-wise adaptive convolution (EAC), the learned kernel isutilized to adaptively process the input feature, effectively preserving thestructural information of the input. This process thereby more effectivelyguides the generative process of Stable Diffusion (SD), enhancing both thedeblurring efficacy and the quality of detail reconstruction. Moreover, theresults at each diffusion step are utilized to iteratively estimate the kernelsin LKPN to better restore the sharp latent by EAC. This iterative refinementenhances the accuracy and robustness of the deblurring process. Extensiveexperimental results demonstrate that the proposed method outperformsstate-of-the-art image deblurring methods on both benchmark and real-worldimages.",Lingshun Kong,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03809v1,Bayesian Time-Varying Meta-Analysis via Hierarchical Mean-Variance Random-effects Models,http://arxiv.org/abs/2502.03809v1,"Meta-analysis is widely used to integrate results from multiple experimentsto obtain generalized insights. Since meta-analysis datasets are oftenheteroscedastic due to varying subgroups and temporal heterogeneity arisingfrom experiments conducted at different time points, the typical meta-analysisapproach, which assumes homoscedasticity, fails to adequately address thisheteroscedasticity among experiments. This paper proposes a new Bayesianestimation method that simultaneously shrinks estimates of the means andvariances of experiments using a hierarchical Bayesian approach whileaccounting for time effects through a Gaussian process. This method connectsexperiments via the hierarchical framework, enabling ""borrowing strength""between experiments to achieve high-precision estimates of each experiment'smean. The method can flexibly capture potential time trends in datasets bymodeling time effects with the Gaussian process. We demonstrate theeffectiveness of the proposed method through simulation studies and illustrateits practical utility using a real marketing promotions dataset.",Kohsuke Kubota,2025-02-06,2025-02-06,,N/A,"['stat.ME', '62-08']"
2502.03808v1,Pre-stack and post-stack seismic inversion using quantum computing,http://arxiv.org/abs/2502.03808v1,"Quantum computing harnesses the principles of quantum mechanics to solveproblems that are intractable for classical computers. Quantum annealing, aspecialized approach within quantum computing, is particularly effective foroptimization tasks, as it leverages quantum tunneling to escape local minimaand efficiently explore complex energy landscapes. In geosciences, manyproblems are framed as high-dimensional optimization problems, includingseismic inversion, which aims to estimate subsurface impedances from seismicdata for accurate geological interpretation and resource exploration. Thisstudy presents a novel application of quantum computing for seismic inversion,marking the first instance of inverting seismic data to estimate both P-waveand S-wave impedances using a quantum annealer. Building upon our prior work,which demonstrated the estimation of acoustic impedances from post-stack datausing a two-step framework, we propose an enhanced workflow capable ofinverting both post-stack and pre-stack seismic data in a single step. Thisadvancement significantly reduces the number of qubits per model parameter(from 20 to 5) while improving computational speed (from 20 seconds to 6.3seconds). The seismic inversion is implemented using the D-Wave Leap hybridsolver, achieving impedance estimation within 4-9 seconds, with the quantumprocessing unit (QPU) contributing just 0.043-0.085 seconds. Comparativeanalysis with simulated annealing reveals that quantum annealing producesimpedance models closely matching true values in a single epoch, whereassimulated annealing requires 10 epochs for improved accuracy. These findingsunderscore the transformative potential of quantum computing for real-time,high-precision seismic inversion, marking a crucial step toward fullyquantum-driven geophysical solutions.",Divakar Vashisth,2025-02-06,2025-02-06,,N/A,"['quant-ph', 'physics.geo-ph']"
2502.03806v1,Should Code Models Learn Pedagogically? A Preliminary Evaluation of Curriculum Learning for Real-World Software Engineering Tasks,http://arxiv.org/abs/2502.03806v1,"Learning-based techniques, especially advanced pre-trained models for codehave demonstrated capabilities in code understanding and generation, solvingdiverse software engineering (SE) tasks. Despite the promising results, currenttraining approaches may not fully optimize model performance, as they typicallyinvolve learning from randomly shuffled training data. Recent work shows thatCurriculum Learning (CL) can improve performance on code-related tasks throughincremental learning based on the difficulty of synthetic code. Yet, theeffectiveness of CL with conventional difficulty measures in SE tasks remainslargely unexplored. In this study, we explore two conventional code metrics:code length and cyclomatic complexity to determine the difficulty levels. Weinvestigate how the pre-trained code model (CodeT5) learns under CL, throughthe tasks of code clone detection and code summarization. Our empirical studyon the CodeXGLUE benchmark showed contrasting results to prior studies, wherethe model exhibited signs of catastrophic forgetting and shortcut learning.Surprisingly, model performance saturates after only the first quartile oftraining, potentially indicating a limit in the model's representation capacityand/or the task's inherent difficulty. Future work should further explorevarious CL strategies with different code models across a wider range of SEtasks for a more holistic understanding.",Kyi Shin Khant,2025-02-06,2025-02-06,,N/A,"['cs.SE', 'cs.LG']"
2502.03805v1,Identify Critical KV Cache in LLM Inference from an Output Perturbation Perspective,http://arxiv.org/abs/2502.03805v1,"Large language models have revolutionized natural language processing butface significant challenges of high storage and runtime costs, due to thetransformer architecture's reliance on self-attention, particularly the largeKey-Value (KV) cache for long-sequence inference. Recent efforts to reduce KVcache size by pruning less critical entries based on attention weights remainempirical and lack formal grounding. This paper presents a formal study onidentifying critical KV cache entries by analyzing attention outputperturbation. Our analysis reveals that, beyond attention weights, the valuestates within KV entries and pretrained parameter matrices are also crucial.Based on this, we propose a perturbation-constrained selection algorithm thatoptimizes the worst-case output perturbation to identify critical entries.Evaluations on the Needle-in-a-Haystack test and Longbench benchmark show ouralgorithm enhances state-of-the-art cache eviction methods. Further empiricalanalysis confirms that our algorithm achieves lower output perturbations inover 92% attention heads in Llama model, thereby providing a significantimprovement over existing methods.",Yuan Feng,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.03804v1,Understanding and Supporting Formal Email Exchange by Answering AI-Generated Questions,http://arxiv.org/abs/2502.03804v1,"Replying to formal emails is time-consuming and cognitively demanding, as itrequires polite phrasing and ensuring an adequate response to the sender'sdemands. Although systems with Large Language Models (LLM) were designed tosimplify the email replying process, users still needed to provide detailedprompts to obtain the expected output. Therefore, we proposed and evaluated anLLM-powered question-and-answer (QA)-based approach for users to reply toemails by answering a set of simple and short questions generated from theincoming email. We developed a prototype system, ResQ, and conducted controlledand field experiments with 12 and 8 participants. Our results demonstrated thatQA-based approach improves the efficiency of replying to emails and reducesworkload while maintaining email quality compared to a conventionalprompt-based approach that requires users to craft appropriate prompts toobtain email drafts. We discuss how QA-based approach influences the emailreply process and interpersonal relationship dynamics, as well as theopportunities and challenges associated with using a QA-based approach inAI-mediated communication.",Yusuke Miura,2025-02-06,2025-02-06,,N/A,"['cs.HC', 'cs.AI']"
2502.03803v1,Graph Neural Network-Driven Hierarchical Mining for Complex Imbalanced Data,http://arxiv.org/abs/2502.03803v1,"This study presents a hierarchical mining framework for high-dimensionalimbalanced data, leveraging a depth graph model to address the inherentperformance limitations of conventional approaches in handling complex,high-dimensional data distributions with imbalanced sample representations. Byconstructing a structured graph representation of the dataset and integratinggraph neural network (GNN) embeddings, the proposed method effectively capturesglobal interdependencies among samples. Furthermore, a hierarchical strategy isemployed to enhance the characterization and extraction of minority classfeature patterns, thereby facilitating precise and robust imbalanced datamining. Empirical evaluations across multiple experimental scenarios validatethe efficacy of the proposed approach, demonstrating substantial improvementsover traditional methods in key performance metrics, including patterndiscovery count, average support, and minority class coverage. Notably, themethod exhibits superior capabilities in minority-class feature extraction andpattern correlation analysis. These findings underscore the potential of depthgraph models, in conjunction with hierarchical mining strategies, tosignificantly enhance the efficiency and accuracy of imbalanced data analysis.This research contributes a novel computational framework for high-dimensionalcomplex data processing and lays the foundation for future extensions todynamically evolving imbalanced data and multi-modal data applications, therebyexpanding the applicability of advanced data mining methodologies to moreintricate analytical domains.",Yijiashun Qi,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.03802v1,MXMap: A Multivariate Cross Mapping Framework for Causal Discovery in Dynamical Systems,http://arxiv.org/abs/2502.03802v1,"Convergent Cross Mapping (CCM) is a powerful method for detecting causalityin coupled nonlinear dynamical systems, providing a model-free approach tocapture dynamic causal interactions. Partial Cross Mapping (PCM) was introducedas an extension of CCM to address indirect causality in three-variable systemsby comparing cross-mapping quality between direct cause-effect mapping andindirect mapping through an intermediate conditioning variable. However, PCMremains limited to univariate delay embeddings in its cross-mapping processes.In this work, we extend PCM to the multivariate setting, introducing multiPCM,which leverages multivariate embeddings to more effectively distinguishindirect causal relationships. We further propose a multivariate cross-mappingframework (MXMap) for causal discovery in dynamical systems. This two-phaseframework combines (1) pairwise CCM tests to establish an initial causal graphand (2) multiPCM to refine the graph by pruning indirect causal connections.Through experiments on simulated data and the ERA5 Reanalysis weather dataset,we demonstrate the effectiveness of MXMap. Additionally, MXMap is comparedagainst several baseline methods, showing advantages in accuracy and causalgraph refinement.",Elise Zhang,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'math.DS', 'stat.ME']"
2502.03801v1,SoK: Benchmarking Poisoning Attacks and Defenses in Federated Learning,http://arxiv.org/abs/2502.03801v1,"Federated learning (FL) enables collaborative model training while preservingdata privacy, but its decentralized nature exposes it to client-side datapoisoning attacks (DPAs) and model poisoning attacks (MPAs) that degrade globalmodel performance. While numerous proposed defenses claim substantialeffectiveness, their evaluation is typically done in isolation with limitedattack strategies, raising concerns about their validity. Additionally,existing studies overlook the mutual effectiveness of defenses against bothDPAs and MPAs, causing fragmentation in this field. This paper aims to providea unified benchmark and analysis of defenses against DPAs and MPAs, clarifyingthe distinction between these two similar but slightly distinct domains. Wepresent a systematic taxonomy of poisoning attacks and defense strategies,outlining their design, strengths, and limitations. Then, a unified comparativeevaluation across FL algorithms and data heterogeneity is conducted to validatetheir individual and mutual effectiveness and derive key insights for designprinciples and future research. Along with the analysis, we frame our work to aunified benchmark, FLPoison, with high modularity and scalability to evaluate15 representative poisoning attacks and 17 defense strategies, facilitatingfuture research in this domain. Code is available athttps://github.com/vio1etus/FLPoison.",Heyi Zhang,2025-02-06,2025-02-06,,N/A,"['cs.CR', 'cs.AI', 'cs.LG']"
2502.03799v1,Enhancing Hallucination Detection through Noise Injection,http://arxiv.org/abs/2502.03799v1,"Large Language Models (LLMs) are prone to generating plausible yet incorrectresponses, known as hallucinations. Effectively detecting hallucinations istherefore crucial for the safe deployment of LLMs. Recent research has linkedhallucinations to model uncertainty, suggesting that hallucinations can bedetected by measuring dispersion over answer distributions obtained from a setof samples drawn from a model. While drawing from the distribution over tokensdefined by the model is a natural way to obtain samples, in this work, we arguethat it is sub-optimal for the purpose of detecting hallucinations. We showthat detection can be improved significantly by taking into account modeluncertainty in the Bayesian sense. To this end, we propose a very simple andefficient approach that perturbs an appropriate subset of model parameters, orequivalently hidden unit activations, during sampling. We demonstrate itseffectiveness across a wide range of datasets and model architectures.",Litian Liu,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.SY', 'eess.SY']"
2502.03798v1,Network-Wide Traffic Flow Estimation Across Multiple Cities with Global Open Multi-Source Data: A Large-Scale Case Study in Europe and North America,http://arxiv.org/abs/2502.03798v1,"Network-wide traffic flow, which captures dynamic traffic volume on each linkof a general network, is fundamental to smart mobility applications. However,the observed traffic flow from sensors is usually limited across the entirenetwork due to the associated high installation and maintenance costs. Toaddress this issue, existing research uses various supplementary data sourcesto compensate for insufficient sensor coverage and estimate the unobservedtraffic flow. Although these studies have shown promising results, theinconsistent availability and quality of supplementary data across cities maketheir methods typically face a trade-off challenge between accuracy andgenerality. In this research, we first time advocate using the Global OpenMulti-Source (GOMS) data within an advanced deep learning framework to breakthe trade-off. The GOMS data primarily encompass geographical and demographicinformation, including road topology, building footprints, and populationdensity, which can be consistently collected across cities. More importantly,these GOMS data are either causes or consequences of transportation activities,thereby creating opportunities for accurate network-wide flow estimation.Furthermore, we use map images to represent GOMS data, instead of traditionaltabular formats, to capture richer and more comprehensive geographical anddemographic information. To address multi-source data fusion, we develop anattention-based graph neural network that effectively extracts and synthesizesinformation from GOMS maps while simultaneously capturing spatiotemporaltraffic dynamics from observed traffic data. A large-scale case study across 15cities in Europe and North America was conducted. The results demonstratestable and satisfactory estimation accuracy across these cities, which suggeststhat the trade-off challenge can be successfully addressed using our approach.",Zijian Hu,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.03795v1,Distribution learning via neural differential equations: minimal energy regularization and approximation theory,http://arxiv.org/abs/2502.03795v1,"Neural ordinary differential equations (ODEs) provide expressiverepresentations of invertible transport maps that can be used to approximatecomplex probability distributions, e.g., for generative modeling, densityestimation, and Bayesian inference. We show that for a large class of transportmaps $T$, there exists a time-dependent ODE velocity field realizing astraight-line interpolation $(1-t)x + tT(x)$, $t \in [0,1]$, of thedisplacement induced by the map. Moreover, we show that such velocity fieldsare minimizers of a training objective containing a specific minimum-energyregularization. We then derive explicit upper bounds for the $C^k$ norm of thevelocity field that are polynomial in the $C^k$ norm of the correspondingtransport map $T$; in the case of triangular (Knothe--Rosenblatt) maps, we alsoshow that these bounds are polynomial in the $C^k$ norms of the associatedsource and target densities. Combining these results with stability argumentsfor distribution approximation via ODEs, we show that Wasserstein orKullback--Leibler approximation of the target distribution to any desiredaccuracy $\epsilon > 0$ can be achieved by a deep neural network representationof the velocity field whose size is bounded explicitly in terms of $\epsilon$,the dimension, and the smoothness of the source and target densities. The sameneural network ansatz yields guarantees on the value of the regularizedtraining objective.",Youssef Marzouk,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'math.CA', 'stat.ME', 'stat.ML']"
2502.03794v1,The GeV $γ$-ray emission from the composite SNR CTB 87,http://arxiv.org/abs/2502.03794v1,"We report the GeV $\gamma$-ray emission around the composite supernovaremnant (SNR) CTB 87 with more than 16 yrs PASS 8 data recorded by the FermiLarge Area Telescope. Two separate point sources with the different GeV spectraare identified in this region: one has a soft $\gamma$-ray spectrum, likely dueto interactions between the SNR shock and molecular clouds (MCs); and anothersource with a hard GeV $\gamma$-ray spectrum aligns with the TeV spectrum ofVER J2016+371, suggesting it as the GeV counterpart. Considering theobservations of CTB 87 in the radio and X-ray bands, VER J2016+371 is proposedto originate from the pulsar wind nebula (PWN) associated with PSR J2016+3711.A leptonic model with a broken power-law electron distribution could explainthe multi-wavelength data of VER J2016+371, with fitted parameters matchingtypical $\gamma$-ray PWNe. Deeper searching for the SNR shock of CTB 87 inother bands and the future TeV observations by LHAASO and CTA are crucial toreveal the nature of CTB 87.",Yuliang Xin,2025-02-06,2025-02-06,,N/A,['astro-ph.HE']
2502.03793v1,It's All in The [MASK]: Simple Instruction-Tuning Enables BERT-like Masked Language Models As Generative Classifiers,http://arxiv.org/abs/2502.03793v1,"While encoder-only models such as BERT and ModernBERT are ubiquitous inreal-world NLP applications, their conventional reliance on task-specificclassification heads can limit their applicability compared to decoder-basedlarge language models (LLMs). In this work, we introduceModernBERT-Large-Instruct, a 0.4B-parameter encoder model that leverages itsmasked language modelling (MLM) head for generative classification. Ourapproach employs an intentionally simple training loop and inference mechanismthat requires no heavy pre-processing, heavily engineered prompting, orarchitectural modifications. ModernBERT-Large-Instruct exhibits strongzero-shot performance on both classification and knowledge-based tasks,outperforming similarly sized LLMs on MMLU and achieving 93% of Llama3-1B'sMMLU performance with 60% less parameters. We also demonstrate that, whenfine-tuned, the generative approach using the MLM head matches or evensurpasses traditional classification-head methods across diverse NLU tasks.Thiscapability emerges specifically in models trained on contemporary, diverse datamixes, with models trained on lower volume, less-diverse data yieldingconsiderably weaker performance. Although preliminary, these resultsdemonstrate the potential of using the original generative masked languagemodelling head over traditional task-specific heads for downstream tasks. Ourwork suggests that further exploration into this area is warranted,highlighting many avenues for future improvements.",Benjamin Clavié,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.03790v1,EigenCWD: a spatially-varying deconvolution algorithm for single metalens imaging,http://arxiv.org/abs/2502.03790v1,"The miniaturization of optics through the use of two-dimensional metalenseshas enabled novel applications in imaging. To date, single-lens imaging remainsthe most common configuration, in part due to the limited focusing efficiencyof metalenses. This results in limitations when it comes to wavefrontmanipulation and, thus, unavoidable aberrations in the formed image thatrequire computational deconvolution to deblur the image. For certain lensprofiles, such as the most common hyperbolic one that results in the highestefficiencies, at large fields of view, spatially-varying aberrations such ascoma or astigmatism are prominent. These aberrations cannot be corrected for bytraditional deconvolution methods, such as Wiener filtering. Here, we develop aspatially-varying deconvolution algorithm based on eigenvalue column-wisedecomposition (eigenCWD). EigenCWD solves a minimization problem of the errorbetween the measured image and the estimated image of the object to bereconstructed through an approximate forward blurring model. This approximateforward model uses an eigendecomposition of the spatially-varying point spreadfunctions for fast computation, allowing for efficient scaling to larger imagesizes and blurring kernels common in metalens imaging. We demonstrateeigenCWD's ability to correct spatially-varying blur and distortions forvarious lens profiles, surpassing that of the Wiener filter.",Joel Yeo,2025-02-06,2025-02-06,,N/A,"['physics.optics', 'physics.comp-ph']"
2502.03787v1,Iterate to Accelerate: A Unified Framework for Iterative Reasoning and Feedback Convergence,http://arxiv.org/abs/2502.03787v1,"We introduce a unified framework for iterative reasoning that leveragesnon-Euclidean geometry via Bregman divergences, higher-order operatoraveraging, and adaptive feedback mechanisms. Our analysis establishes that,under mild smoothness and contractivity assumptions, a generalized updatescheme not only unifies classical methods such as mirror descent and dynamicprogramming but also captures modern chain-of-thought reasoning processes inlarge language models. In particular, we prove that our accelerated iterativeupdate achieves an $O(1/t^2)$ convergence rate in the absence of persistentperturbations, and we further demonstrate that feedback (iterative)architectures are necessary to approximate certain fixed-point functionsefficiently. These theoretical insights bridge classical accelerationtechniques with contemporary applications in neural computation andoptimization.",Jacob Fein-Ashley,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.03784v1,GistVis: Automatic Generation of Word-scale Visualizations from Data-rich Documents,http://arxiv.org/abs/2502.03784v1,"Data-rich documents are ubiquitous in various applications, yet they oftenrely solely on textual descriptions to convey data insights. Prior researchprimarily focused on providing visualization-centric augmentation to data-richdocuments. However, few have explored using automatically generated word-scalevisualizations to enhance the document-centric reading process. As anexploratory step, we propose GistVis, an automatic pipeline that extracts andvisualizes data insight from text descriptions. GistVis decomposes thegeneration process into four modules: Discoverer, Annotator, Extractor, andVisualizer, with the first three modules utilizing the capabilities of largelanguage models and the fourth using visualization design knowledge. Technicalevaluation including a comparative study on Discoverer and an ablation study onAnnotator reveals decent performance of GistVis. Meanwhile, the user study(N=12) showed that GistVis could generate satisfactory word-scalevisualizations, indicating its effectiveness in facilitating users'understanding of data-rich documents (+5.6% accuracy) while significantlyreducing their mental demand (p=0.016) and perceived effort (p=0.033).",Ruishi Zou,2025-02-06,2025-02-06,,N/A,['cs.HC']
2502.03783v1,UltraBones100k: An Ultrasound Image Dataset with CT-Derived Labels for Lower Extremity Long Bone Surface Segmentation,http://arxiv.org/abs/2502.03783v1,"Ultrasound-based bone surface segmentation is crucial in computer-assistedorthopedic surgery. However, ultrasound images have limitations, including alow signal-to-noise ratio, and acoustic shadowing, which make interpretationdifficult. Existing deep learning models for bone segmentation rely primarilyon costly manual labeling by experts, limiting dataset size and modelgeneralizability. Additionally, the complexity of ultrasound physics andacoustic shadow makes the images difficult for humans to interpret, leading toincomplete labels in anechoic regions and limiting model performance. Toadvance ultrasound bone segmentation and establish effective model benchmarks,larger and higher-quality datasets are needed.  We propose a methodology for collecting ex-vivo ultrasound datasets withautomatically generated bone labels, including anechoic regions. The proposedlabels are derived by accurately superimposing tracked bone CT models onto thetracked ultrasound images. These initial labels are refined to account forultrasound physics. A clinical evaluation is conducted by an expert physicianspecialized on orthopedic sonography to assess the quality of the generatedbone labels. A neural network for bone segmentation is trained on the collecteddataset and its predictions are compared to expert manual labels, evaluatingaccuracy, completeness, and F1-score.  We collected the largest known dataset of 100k ultrasound images of humanlower limbs with bone labels, called UltraBones100k. A Wilcoxon signed-ranktest with Bonferroni correction confirmed that the bone alignment after ourmethod significantly improved the quality of bone labeling (p < 0.001). Themodel trained on UltraBones100k consistently outperforms manual labeling in allmetrics, particularly in low-intensity regions (320% improvement incompleteness at a distance threshold of 0.5 mm).",Luohong Wu,2025-02-06,2025-02-06,,N/A,"['eess.IV', 'cs.CV']"
2502.03782v1,Classification of Solar Radio Spectrum Based on Swin Transformer,http://arxiv.org/abs/2502.03782v1,"Solar radio observation is a method used to study the Sun. It is veryimportant for space weather early warning and solar physics research toautomatically classify solar radio spectrums in real time and judge whetherthere is a solar radio burst. As the number of solar radio burst spectrums issmall and uneven, this paper proposes a classification method for solar radiospectrums based on the Swin transformer. First, the method transfers theparameters of the pretrained model to the Swin transformer model. Then, thehidden layer weights of the Swin transformer are frozen, and the fullyconnected layer of the Swin transformer is trained on the target dataset.Finally, pa-rameter tuning is performed. The experimental results show that themethod can achieve a true positive rate of 100%, which is more accurate thanprevious methods. Moreover, the number of our model parameters is only 20million, which is 80% lower than that of the traditional VGG16 con-volutionalneural network with more than 130 million parameters.",Jian Chen,2025-02-06,2025-02-06,,N/A,"['astro-ph.IM', 'astro-ph.SR']"
2502.03781v1,Gaze-Assisted Human-Centric Domain Adaptation for Cardiac Ultrasound Image Segmentation,http://arxiv.org/abs/2502.03781v1,"Domain adaptation (DA) for cardiac ultrasound image segmentation isclinically significant and valuable. However, previous domain adaptationmethods are prone to be affected by the incomplete pseudo-label and low-qualitytarget to source images. Human-centric domain adaptation has great advantagesof human cognitive guidance to help model adapt to target domain and reducereliance on labels. Doctor gaze trajectories contains a large amount ofcross-domain human guidance. To leverage gaze information and human cognitionfor guiding domain adaptation, we propose gaze-assisted human-centric domainadaptation (GAHCDA), which reliably guides the domain adaptation of cardiacultrasound images. GAHCDA includes following modules: (1) Gaze AugmentAlignment (GAA): GAA enables the model to obtain human cognition generalfeatures to recognize segmentation target in different domain of cardiacultrasound images like humans. (2) Gaze Balance Loss (GBL): GBL fused gazeheatmap with outputs which makes the segmentation result structurally closer tothe target domain. The experimental results illustrate that our proposedframework is able to segment cardiac ultrasound images more effectively in thetarget domain than GAN-based methods and other self-train based methods,showing great potential in clinical application.",Ruiyi Li,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'eess.IV']"
2502.03779v1,Out-of-phase Plasmon Excitations in the Trilayer Cuprate Bi$_2$Sr$_2$Ca$_2$Cu$_3$O$_{10+δ}$,http://arxiv.org/abs/2502.03779v1,"Within a homologous series of cuprate superconductors, variations in thestacking of CuO$_2$ layers influence the collective charge dynamics through thelong-range Coulomb interactions. We use O $K$-edge resonant inelastic x-rayscattering to reveal plasmon excitations in the optimally-doped trilayerBi$_2$Sr$_2$Ca$_2$Cu$_3$O$_{10+\delta}$. The observed plasmon exhibits nearly$q_z$-independent dispersion and a large excitation gap of approximately 300meV. This mode is primarily ascribed to the $\omega_{-}$ mode, where the chargedensity on the outer CuO$_2$ sheets oscillates out of phase while the densityin the inner sheet remains unaltered at $q_z=0$. The intensity of the acoustic$\omega_3$ mode is relatively weak and becomes vanishingly small near $(q_x,q_y)=(0, 0)$. This result highlights a qualitative change in the eigenmode ofthe dominant low-energy plasmon with the number of CuO$_2$ layers.",S. Nakata,2025-02-06,2025-02-06,,N/A,['cond-mat.str-el']
2502.03778v1,Self-Supervised Learning for Solar Radio Spectrum Classification,http://arxiv.org/abs/2502.03778v1,"Solar radio observation is an important way to study the Sun. Solar radiobursts contain important information about solar activity. Therefore, real-timeautomatic detection and classification of solar radio bursts are of great valuefor subsequent solar physics research and space weather warnings. Traditionalimage classification methods based on deep learning often require consid-erabletraining data. To address insufficient solar radio spectrum images, transferlearning is generally used. However, the large difference between naturalimages and solar spectrum images has a large impact on the transfer learningeffect. In this paper, we propose a self-supervised learning method for solarradio spectrum classification. Our method uses self-supervised training with aself-masking approach in natural language processing. Self-supervised learningis more conducive to learning the essential information about images comparedwith supervised methods, and it is more suitable for transfer learning. First,the method pre-trains using a large amount of other existing data. Then, thetrained model is fine-tuned on the solar radio spectrum dataset. Experimentsshow that the method achieves a classification accuracy similar to that ofconvolutional neural networks and Transformer networks with supervisedtraining.",Siqi Li,2025-02-06,2025-02-06,,N/A,"['astro-ph.IM', 'astro-ph.SR']"
2502.03777v1,Multi-Label Test-Time Adaptation with Bound Entropy Minimization,http://arxiv.org/abs/2502.03777v1,"Mainstream test-time adaptation (TTA) techniques endeavor to mitigatedistribution shifts via entropy minimization for multi-class classification,inherently increasing the probability of the most confident class. However,when encountering multi-label instances, the primary challenge stems from thevarying number of labels per image, and prioritizing only the highestprobability class inevitably undermines the adaptation of other positivelabels. To address this issue, we investigate TTA within multi-label scenario(ML--TTA), developing Bound Entropy Minimization (BEM) objective tosimultaneously increase the confidence of multiple top predicted labels.Specifically, to determine the number of labels for each augmented view, weretrieve a paired caption with yielded textual labels for that view. Theselabels are allocated to both the view and caption, called weak label set andstrong label set with the same size k. Following this, the proposed BEMconsiders the highest top-k predicted labels from view and caption as a singleentity, respectively, learning both view and caption prompts concurrently. Bybinding top-k predicted labels, BEM overcomes the limitation of vanilla entropyminimization, which exclusively optimizes the most confident class. Across theMSCOCO, VOC, and NUSWIDE multi-label datasets, our ML--TTA framework equippedwith BEM exhibits superior performance compared to the latest SOTA methods,across various model architectures, prompt initialization, and varying labelscenarios. The code is available at https://github.com/Jinx630/ML-TTA.",Xiangyu Wu,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03775v1,Accretion disk dynamics in Teleparallel Born-Infeld gravity,http://arxiv.org/abs/2502.03775v1,"Teleparallel Born-Infeld gravity (TBI) is a modified theory of gravity thataims to maintain second-order field equations, leading to alternative scenariosfor strong gravity and cosmological settings. In this study, we examine theimpact of TBI gravity on the physical characteristics of thin (Novikov-Thorne)accretion disks, focusing on quantities such as flux, pressure, temperature,etc. We also examine the spectral luminosity, comparing it to disks around theSchwarzschild black holes. The analysis indicates that smaller values of$\lambda$ lead to more noticeable effects in the inner disk regions. Bycomparing the theoretical predictions to observational data in thelow-frequency regime, we demonstrate ability of the model to align with realastrophysical systems and distinguish subtle differences between TBI gravityand general relativity. Furthermore, the results suggest that observations ofX-ray spectra from the inner disk regions can provide valuable insights intothe properties of TBI gravity, potentially offering constraints on thismodified gravity theory through future astrophysical observations.",Ruijing Tang,2025-02-06,2025-02-06,,N/A,['gr-qc']
2502.03773v1,ExpProof : Operationalizing Explanations for Confidential Models with ZKPs,http://arxiv.org/abs/2502.03773v1,"In principle, explanations are intended as a way to increase trust in machinelearning models and are often obligated by regulations. However, manycircumstances where these are demanded are adversarial in nature, meaning theinvolved parties have misaligned interests and are incentivized to manipulateexplanations for their purpose. As a result, explainability methods fail to beoperational in such settings despite the demand \cite{bordt2022post}. In thispaper, we take a step towards operationalizing explanations in adversarialscenarios with Zero-Knowledge Proofs (ZKPs), a cryptographic primitive.Specifically we explore ZKP-amenable versions of the popular explainabilityalgorithm LIME and evaluate their performance on Neural Networks and RandomForests.",Chhavi Yadav,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI', 'cs.CR']"
2502.03772v1,A Retrospective Systematic Study on Hierarchical Sparse Query Transformer-assisted Ultrasound Screening for Early Hepatocellular Carcinoma,http://arxiv.org/abs/2502.03772v1,"Hepatocellular carcinoma (HCC) ranks as the third leading cause ofcancer-related mortality worldwide, with early detection being crucial forimproving patient survival rates. However, early screening for HCC usingultrasound suffers from insufficient sensitivity and is highly dependent on theexpertise of radiologists for interpretation. Leveraging the latestadvancements in artificial intelligence (AI) in medical imaging, this studyproposes an innovative Hierarchical Sparse Query Transformer (HSQformer) modelthat combines the strengths of Convolutional Neural Networks (CNNs) and VisionTransformers (ViTs) to enhance the accuracy of HCC diagnosis in ultrasoundscreening. The HSQformer leverages sparse latent space representations tocapture hierarchical details at various granularities without the need forcomplex adjustments, and adopts a modular, plug-and-play design philosophy,ensuring the model's versatility and ease of use. The HSQformer's performancewas rigorously tested across three distinct clinical scenarios: single-center,multi-center, and high-risk patient testing. In each of these settings, itconsistently outperformed existing state-of-the-art models, such as ConvNextand SwinTransformer. Notably, the HSQformer even matched the diagnosticcapabilities of senior radiologists and comprehensively surpassed those ofjunior radiologists. The experimental results from this study stronglydemonstrate the effectiveness and clinical potential of AI-assisted tools inHCC screening. The full code is available athttps://github.com/Asunatan/HSQformer.",Chaoyin She,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.AI']"
2502.03771v1,Adaptive Semantic Prompt Caching with VectorQ,http://arxiv.org/abs/2502.03771v1,"Semantic prompt caches reduce the latency and cost of large language model(LLM) inference by reusing cached LLM-generated responses for semanticallysimilar prompts. Vector similarity metrics assign a numerical score to quantifythe similarity between an embedded prompt and its nearest neighbor in thecache. Existing systems rely on a static threshold to classify whether thesimilarity score is sufficiently high to result in a cache hit. We show thatthis one-size-fits-all threshold is insufficient across different prompts. Wepropose VectorQ, a framework to learn embedding-specific threshold regions thatadapt to the complexity and uncertainty of an embedding. Through evaluations ona combination of four diverse datasets, we show that VectorQ consistentlyoutperforms state-of-the-art systems across all static thresholds, achieving upto 12x increases in cache hit rate and error rate reductions up to 92%.",Luis Gaspar Schroeder,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.CL']"
2502.03769v1,"Measurements of $\varUpsilon$ States Production in $\textit{p+p}$ Collisions at $\sqrt{s} = 500\:\mathrm{GeV}$ with STAR: Cross Sections, Ratios, and Multiplicity Dependence",http://arxiv.org/abs/2502.03769v1,"We report measurements of $\varUpsilon(1S)$, $\varUpsilon(2S)$ and$\varUpsilon(3S)$ production in $\textit{p+p}$ collisions at$\sqrt{s}=500\:\mathrm{GeV}$ by the STAR experiment in year 2011, correspondingto an integrated luminosity $\mathcal{L}_{int}=13\:\mathrm{pb^{-1}}$. Theresults provide precise cross sections, transverse momentum ($p_{T}$) andrapidity ($y$) spectra, as well as cross section ratios for$p_{\mathrm{T}}<10\:\mathrm{GeV/c}$ and $|y|<1$. The dependence of the$\varUpsilon$ yield on charged particle multiplicity has also been measured,offering new insights into the mechanisms of quarkonium production. The dataare compared to various theoretical models: the Color Evaporation Model (CEM)accurately describes the $\varUpsilon(1S)$ production, while the Color GlassCondensate + Non-relativistic Quantum Chromodynamics (CGC+NRQCD) modeloverestimates the data, particularly at low $p_{T}$. Conversely, the ColorSinglet Model (CSM) underestimates the rapidity dependence. These discrepancieshighlight the need for further development in understanding the productiondynamics of heavy quarkonia in high-energy hadronic collisions. The trend inthe multiplicity dependence is consistent with CGC/Saturation and StringPercolation models or $\varUpsilon$ production happening in multiple partoninteractions modeled by PYTHIA8.",The STAR Collaboration,2025-02-06,2025-02-06,,N/A,"['hep-ex', 'nucl-ex']"
2502.03768v1,Quantum integrable model for the quantum cohomology/quantum K-theory of flag varieties and the double $β$-Grothendieck polynomials,http://arxiv.org/abs/2502.03768v1,A GL$(n)$ quantum integrable system generalizing the asymmetric five vertexspin chain is shown to encode the ring relations of the equivariant quantumcohomology and quantum K-theory ring of flag varieties. We also show that theBethe ansatz states of this system generate the double $\beta$-Grothendieckpolynomials.,Jirui Guo,2025-02-06,2025-02-06,,N/A,"['math-ph', 'hep-th', 'math.AG', 'math.CO', 'math.MP', 'nlin.SI']"
2502.03766v1,Hierarchical Contextual Manifold Alignment for Structuring Latent Representations in Large Language Models,http://arxiv.org/abs/2502.03766v1,"The organization of latent token representations plays a crucial role indetermining the stability, generalization, and contextual consistency oflanguage models, yet conventional approaches to embedding refinement often relyon parameter modifications that introduce additional computational overhead. Ahierarchical alignment method was introduced to restructure token embeddingswithout altering core model weights, ensuring that representationaldistributions maintained coherence across different linguistic contexts.Experimental evaluations demonstrated improvements in rare token retrieval,adversarial robustness, and long-range dependency tracking, highlighting theadvantages of hierarchical structuring in mitigating inconsistencies in latentspace organization. The comparative analysis against conventional fine-tuningand embedding perturbation methods revealed that hierarchical restructuringmaintained computational efficiency while achieving measurable gains inrepresentation quality. Structural refinements introduced through the alignmentprocess resulted in improved contextual stability across varied linguistictasks, reducing inconsistencies in token proximity relationships and enhancinginterpretability in language generation. A detailed computational assessmentconfirmed that the realignment process introduced minimal inference overhead,ensuring that representational improvements did not compromise modelefficiency. The findings reinforced the broader significance of structuredrepresentation learning, illustrating that hierarchical embedding modificationscould serve as an effective strategy for refining latent space distributionswhile preserving pre-learned semantic associations.",Meiquan Dong,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.03763v1,Systolic Sparse Tensor Slices: FPGA Building Blocks for Sparse and Dense AI Acceleration,http://arxiv.org/abs/2502.03763v1,"FPGA architectures have recently been enhanced to meet the substantialcomputational demands of modern deep neural networks (DNNs). To this end, bothFPGA vendors and academic researchers have proposed in-fabric blocks thatperform efficient tensor computations. However, these blocks are primarilyoptimized for dense computation, while most DNNs exhibit sparsity. To addressthis limitation, we propose incorporating structured sparsity support into FPGAarchitectures. We architect 2D systolic in-fabric blocks, named systolic sparsetensor (SST) slices, that support multiple degrees of sparsity to efficientlyaccelerate a wide variety of DNNs. SSTs support dense operation, 2:4 (50%) and1:4 (75%) sparsity, as well as a new 1:3 (66.7%) sparsity level to furtherincrease flexibility. When demonstrating on general matrix multiplication(GEMM) accelerators, which are the heart of most current DNN accelerators, oursparse SST-based designs attain up to 5x higher FPGA frequency and 10.9x lowerarea, compared to traditional FPGAs. Moreover, evaluation of the proposed SSTson state-of-the-art sparse ViT and CNN models exhibits up to 3.52x speedup withminimal area increase of up to 13.3%, compared to dense in-fabric acceleration.",Endri Taka,2025-02-06,2025-02-06,,N/A,['cs.AR']
2502.03762v1,Learning Reward Machines from Partially Observed Optimal Policies,http://arxiv.org/abs/2502.03762v1,"Inverse reinforcement learning is the problem of inferring a reward functionfrom an optimal policy. In this work, it is assumed that the reward isexpressed as a reward machine whose transitions depend on atomic propositionsassociated with the state of a Markov Decision Process (MDP). Our goal is toidentify the true reward machine using finite information. To this end, wefirst introduce the notion of a prefix tree policy which associates adistribution of actions to each state of the MDP and each attainable finitesequence of atomic propositions. Then, we characterize an equivalence class ofreward machines that can be identified given the prefix tree policy. Finally,we propose a SAT-based algorithm that uses information extracted from theprefix tree policy to solve for a reward machine. It is proved that if theprefix tree policy is known up to a sufficient (but finite) depth, ouralgorithm recovers the exact reward machine up to the equivalence class. Thissufficient depth is derived as a function of the number of MDP states and (anupper bound on) the number of states of the reward machine. Several examplesare used to demonstrate the effectiveness of the approach.",Mohamad Louai Shehab,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.FL']"
2502.03760v1,RAMOTS: A Real-Time System for Aerial Multi-Object Tracking based on Deep Learning and Big Data Technology,http://arxiv.org/abs/2502.03760v1,"Multi-object tracking (MOT) in UAV-based video is challenging due tovariations in viewpoint, low resolution, and the presence of small objects.While other research on MOT dedicated to aerial videos primarily focuses on theacademic aspect by developing sophisticated algorithms, there is a lack ofattention to the practical aspect of these systems. In this paper, we propose anovel real-time MOT framework that integrates Apache Kafka and Apache Spark forefficient and fault-tolerant video stream processing, along withstate-of-the-art deep learning models YOLOv8/YOLOv10 and BYTETRACK/BoTSORT foraccurate object detection and tracking. Our work highlights the importance ofnot only the advanced algorithms but also the integration of these methods withscalable and distributed systems. By leveraging these technologies, our systemachieves a HOTA of 48.14 and a MOTA of 43.51 on the Visdrone2019-MOT test setwhile maintaining a real-time processing speed of 28 FPS on a single GPU. Ourwork demonstrates the potential of big data technologies and deep learning foraddressing the challenges of MOT in UAV applications.",Nhat-Tan Do,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03758v1,Improving Adversarial Robustness via Phase and Amplitude-aware Prompting,http://arxiv.org/abs/2502.03758v1,"Deep neural networks are found to be vulnerable to adversarial noises. Theprompt-based defense has been increasingly studied due to its high efficiency.However, existing prompt-based defenses mainly exploited mixed prompt patterns,where critical patterns closely related to object semantics lack sufficientfocus. The phase and amplitude spectra have been proven to be highly related tospecific semantic patterns and crucial for robustness. To this end, in thispaper, we propose a Phase and Amplitude-aware Prompting (PAP) defense.Specifically, we construct phase-level and amplitude-level prompts for eachclass, and adjust weights for prompting according to the model's robustperformance under these prompts during training. During testing, we selectprompts for each image using its predicted label to obtain the prompted image,which is inputted to the model to get the final prediction. Experimentalresults demonstrate the effectiveness of our method.",Yibo Xu,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03755v1,Regularization via f-Divergence: An Application to Multi-Oxide Spectroscopic Analysis,http://arxiv.org/abs/2502.03755v1,"In this paper, we address the task of characterizing the chemical compositionof planetary surfaces using convolutional neural networks (CNNs). Specifically,we seek to predict the multi-oxide weights of rock samples based onspectroscopic data collected under Martian conditions. We frame this problem asa multi-target regression task and propose a novel regularization method basedon f-divergence. The f-divergence regularization is designed to constrain thedistributional discrepancy between predictions and noisy targets. Thisregularizer serves a dual purpose: on the one hand, it mitigates overfitting byenforcing a constraint on the distributional difference between predictions andnoisy targets. On the other hand, it acts as an auxiliary loss function,penalizing the neural network when the divergence between the predicted andtarget distributions becomes too large. To enable backpropagation during neuralnetwork training, we develop a differentiable f-divergence and incorporate itinto the f-divergence regularization, making the network training feasible. Weconduct experiments using spectra collected in a Mars-like environment by theremote-sensing instruments aboard the Curiosity and Perseverance rovers.Experimental results on multi-oxide weight prediction demonstrate that theproposed $f$-divergence regularization performs better than or comparable tostandard regularization methods including $L_1$, $L_2$, and dropout. Notably,combining the $f$-divergence regularization with these standard regularizationfurther enhances performance, outperforming each regularization method usedindependently.",Weizhi Li,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.03754v1,Parametric reduced-order modeling and mode sensitivity of actuated cylinder flow from a matrix manifold perspective,http://arxiv.org/abs/2502.03754v1,"We present a framework for parametric proper orthogonal decomposition(POD)-Galerkin reduced-order modeling (ROM) of fluid flows that accommodatesvariations in flow parameters and control inputs. As an initial step, toexplore how the locally optimal POD modes vary with parameter changes, wedemonstrate a sensitivity analysis of POD modes and their spanned subspace,respectively rooted in Stiefel and Grassmann manifolds. The sensitivityanalysis, by defining distance between POD modes for different parameters, isapplied to the flow around a rotating cylinder with varying Reynolds numbersand rotation rates. The sensitivity of the subspace spanned by POD modes toparameter changes is represented by a tangent vector on the Grassmann manifold.For the cylinder case, the inverse of the subspace sensitivity on the Grassmannmanifold is proportional to the Roshko number, highlighting the connectionbetween geometric properties and flow physics. Furthermore, the Reynolds numberat which the subspace sensitivity approaches infinity corresponds to the lowerbound at which the characteristic frequency of the K\'arm\'an vortex streetexists (Noack & Eckelmann, JFM, 1994). From the Stiefel manifold perspective,sensitivity modes are derived to represent the flow field sensitivity,comprising the sensitivities of the POD modes and expansion coefficients. Thetemporal evolution of the flow field sensitivity is represented by superposingthe sensitivity modes. Lastly, we devise a parametric POD-Galerkin ROM based onsubspace interpolation on the Grassmann manifold. The reconstruction error ofthe ROM is intimately linked to the subspace-estimation error, which is in turnclosely related to subspace sensitivity.",Shintaro Sato,2025-02-06,2025-02-06,,N/A,['physics.flu-dyn']
2502.03750v1,Principal Curvatures Estimation with Applications to Single Cell Data,http://arxiv.org/abs/2502.03750v1,"The rapidly growing field of single-cell transcriptomic sequencing (scRNAseq)presents challenges for data analysis due to its massive datasets. A commonmethod in manifold learning consists in hypothesizing that datasets lie on alower dimensional manifold. This allows to study the geometry of point cloudsby extracting meaningful descriptors like curvature. In this work, we willpresent Adaptive Local PCA (AdaL-PCA), a data-driven method for accuratelyestimating various notions of intrinsic curvature on data manifolds, inparticular principal curvatures for surfaces. The model relies on local PCA toestimate the tangent spaces. The evaluation of AdaL-PCA on sampled surfacesshows state-of-the-art results. Combined with a PHATE embedding, the modelapplied to single-cell RNA sequencing data allows us to identify key variationsin the cellular differentiation.",Yanlei Zhang,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI']"
2502.03749v1,PINS: Proximal Iterations with Sparse Newton and Sinkhorn for Optimal Transport,http://arxiv.org/abs/2502.03749v1,"Optimal transport (OT) is a critical problem in optimization and machinelearning, where accuracy and efficiency are paramount. Although entropicregularization and the Sinkhorn algorithm improve scalability, they frequentlyencounter numerical instability and slow convergence, especially when theregularization parameter is small. In this work, we introduce ProximalIterations with Sparse Newton and Sinkhorn methods (PINS) to efficientlycompute highly accurate solutions for large-scale OT problems. A reducedcomputational complexity through overall sparsity and global convergence areguaranteed by rigorous theoretical analysis. Our approach offers three keyadvantages: it achieves accuracy comparable to exact solutions, progressivelyaccelerates each iteration for greater efficiency, and enhances robustness byreducing sensitivity to regularization parameters. Extensive experimentsconfirm these advantages, demonstrating superior performance compared torelated methods.",Di Wu,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'math.OC']"
2502.03748v1,Rethinking the Residual Distribution of Locate-then-Editing Methods in Model Editing,http://arxiv.org/abs/2502.03748v1,"Model editing is a powerful technique for updating the knowledge of LargeLanguage Models (LLMs). Locate-then-edit methods are a popular class ofapproaches that first identify the critical layers storing knowledge, thencompute the residual of the last critical layer based on the edited knowledge,and finally perform multi-layer updates using a least-squares solution byevenly distributing the residual from the first critical layer to the last.Although these methods achieve promising results, they have been shown todegrade the original knowledge of LLMs. We argue that residual distributionleads to this issue. To explore this, we conduct a comprehensive analysis ofresidual distribution in locate-then-edit methods from both empirical andtheoretical perspectives, revealing that residual distribution introducesediting errors, leading to inaccurate edits. To address this issue, we proposethe Boundary Layer UpdatE (BLUE) strategy to enhance locate-then-edit methods.Sequential batch editing experiments on three LLMs and two datasets demonstratethat BLUE not only delivers an average performance improvement of 35.59\%,significantly advancing the state of the art in model editing, but alsoenhances the preservation of LLMs' general capabilities. Our code is availableat https://github.com/xpq-tech/BLUE.",Xiaopeng Li,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.03746v1,Brain Tumor Identification using Improved YOLOv8,http://arxiv.org/abs/2502.03746v1,"Identifying the extent of brain tumors is a significant challenge in braincancer treatment. The main difficulty is in the approximate detection of tumorsize. Magnetic resonance imaging (MRI) has become a critical diagnostic tool.However, manually detecting the boundaries of brain tumors from MRI scans is alabor-intensive task that requires extensive expertise. Deep learning andcomputer-aided detection techniques have led to notable advances in machinelearning for this purpose. In this paper, we propose a modified You Only LookOnce (YOLOv8) model to accurately detect the tumors within the MRI images. Theproposed model replaced the Non-Maximum Suppression (NMS) algorithm with aReal-Time Detection Transformer (RT- DETR) in the detection head. NMS filtersout redundant or overlapping bounding boxes in the detected tumors, but theyare hand-designed and pre-set. RT-DETR removes hand-designed components. Thesecond improvement was made by replacing the normal convolution block withghost convolution. Ghost Convolution reduces computational and memory costswhile maintaining high accuracy and enabling faster inference, making it idealfor resource-constrained environments and real-time applications. The thirdimprovement was made by introducing a vision transformer block in the backboneof YOLOv8 to extract context-aware features. We used a publicly availabledataset of brain tumors in the proposed model. The proposed model performedbetter than the original YOLOv8 model and also performed better than otherobject detectors (Faster R- CNN, Mask R-CNN, YOLO, YOLOv3, YOLOv4, YOLOv5, SSD,RetinaNet, EfficientDet, and DETR). The proposed model achieved 0.91 mAP (meanAverage Precision)@0.5.",Rupesh Dulal,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.LG']"
2502.03745v1,Identifying Compton-thick AGNs in the COSMOS. I. Among X-ray AGNs with Low Photon Counts,http://arxiv.org/abs/2502.03745v1,"Compton-thick active galactic nuclei (CT-AGNs), characterized by asignificant absorption with column densities of $\mathrm{N_H}\geqslant1.5\times 10^{24} \ \mathrm{cm}^{-2}$, emit feeble X-ray radiation and are evenundetectable by X-ray instruments, making them difficult to identify. X-rayradiation from AGNs is the predominant source of the cosmic X-ray background(CXB). Based on AGN synthesis models for the CXB, the fraction of CT-AGNsshould constitute a substantial portion of AGN population, approximately 30\%or more. The fraction of CT-AGNs discovered in the Cosmological EvolutionSurvey (COSMOS) is significantly lower than this value. This means that manyCT-AGNs may be hidden in AGNs that exhibit low photon counts or that have notbeen detected by X-ray instruments. This work focuses on identifying CT-AGNshidden in AGNs with low photon counts. Firstly, we selected 440 AGNs withabundant multiwavelength data as our sample. Secondly, we analyzedmultiwavelength data, extracting crucial physical parameters required for theCT-AGN diagnosis. Finally, we used multiwavelength approaches to identifyCT-AGNs. We have successfully identified 18 CT-AGNs in our sample. Among theCT-AGNs, four AGNs show discrepant results across different diagnostic methods.We discuss the potential reasons behind these diagnostic discrepancies. Weexplore the impact of estimating [O~III]$\lambda~5007$ luminosities based on[O~II]$\lambda~3727$ luminosities for the CT-AGN diagnosis. We have also foundthat the properties of host galaxies for CT-AGNs and non-CT-AGNs do not showsignificant discrepancies.",Xiaotong Guo,2025-02-06,2025-02-06,,N/A,['astro-ph.GA']
2502.03738v1,"Scaling Laws in Patchification: An Image Is Worth 50,176 Tokens And More",http://arxiv.org/abs/2502.03738v1,"Since the introduction of Vision Transformer (ViT), patchification has longbeen regarded as a de facto image tokenization approach for plain visualarchitectures. By compressing the spatial size of images, this approach caneffectively shorten the token sequence and reduce the computational cost ofViT-like plain architectures. In this work, we aim to thoroughly examine theinformation loss caused by this patchification-based compressive encodingparadigm and how it affects visual understanding. We conduct extensive patchsize scaling experiments and excitedly observe an intriguing scaling law inpatchification: the models can consistently benefit from decreased patch sizesand attain improved predictive performance, until it reaches the minimum patchsize of 1x1, i.e., pixel tokenization. This conclusion is broadly applicableacross different vision tasks, various input scales, and diverse architecturessuch as ViT and the recent Mamba models. Moreover, as a by-product, we discoverthat with smaller patches, task-specific decoder heads become less critical fordense prediction. In the experiments, we successfully scale up the visualsequence to an exceptional length of 50,176 tokens, achieving a competitivetest accuracy of 84.6% with a base-sized model on the ImageNet-1k benchmark. Wehope this study can provide insights and theoretical foundations for futureworks of building non-compressive vision models. Code is available athttps://github.com/wangf3014/Patch_Scaling.",Feng Wang,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03735v1,Existence and stability of various models describing behaviour of the thermoviscoelastic-rate type fluids,http://arxiv.org/abs/2502.03735v1,"Viscoelastic rate-type fluid models are used to describe the behaviour ofmany complex materials from engineering up to application in biomaterials andmedicine. A classical model that belongs to the category of viscoelasticrate-type fluid models is the Giesekus model. Furthermore, in all theseapplications, the heat conduction frequently takes place and all materialcoefficients depend heavily on the temperature, and therefore, we introducehere a thermodynamically compatible model for viscoelastic rate-type andheat-conducting fluid for which we show the existence of global weak solutionin two-dimensional setting whenever the initial energy and entropy arecontrolled in natural norms.",Miroslav Bulìček,2025-02-06,2025-02-06,,N/A,"['math.AP', '35A01, 35Q35, 76A10, 76D03']"
2502.03734v1,Improving noisy free-energy measurements by adding more noise,http://arxiv.org/abs/2502.03734v1,"Estimating free-energy differences using nonequilibrium work relations, suchas the Jarzynski equality, is hindered by poor convergence when workfluctuations are large. For systems governed by overdamped Langevin dynamics,we propose the counterintuitive approach of adding noise in order to increasethe precision of such calculations. By introducing additional stochasticfluctuations to the system and rescaling its potential energy, we leave thethermodynamics of the system unchanged while increasing its relaxation rate.For a given time-dependent protocol this modification reduces dissipated work,leading to more accurate free-energy estimates. We demonstrate this principleusing computer simulations applied to two model systems. However, the regime ofapplicability of this strategy is likely limited, because it requires controlof the system's potential energy in a way that is feasible in only a fewexperimental settings.",Stephen Whitelam,2025-02-06,2025-02-06,,N/A,['cond-mat.stat-mech']
2502.03732v1,"More Modality, More AI: Exploring Design Opportunities of AI-Based Multi-modal Remote Monitoring Technologies for Early Detection of Mental Health Sequelae in Youth Concussion Patients",http://arxiv.org/abs/2502.03732v1,"Anxiety, depression, and suicidality are common mental health sequelaefollowing concussion in youth patients, often exacerbating concussion symptomsand prolonging recovery. Despite the critical need for early detection of thesemental health symptoms, clinicians often face challenges in accuratelycollecting patients' mental health data and making clinical decision-making ina timely manner. Today's remote patient monitoring (RPM) technologies offeropportunities to objectively monitor patients' activities, but they were notspecifically designed for youth concussion patients; moreover, the large amountof data collected by RPM technologies may also impose significant workloads onclinicians to keep up with and use the data. To address these gaps, we employeda three-stage study consisting of a formative study, interface design, anddesign evaluation. We first conducted a formative study through semi-structuredinterviews with six highly professional concussion clinicians and identifiedclinicians' key challenges in remotely collecting patient information andaccessing patient treatment compliance. Subsequently, we proposed preliminaryclinician-facing interface designs with the integration of AI-based RPMtechnologies (AI-RPM), followed by design evaluation sessions with highlyprofessional concussion clinicians. Clinicians underscored the value ofintegrating multi-modal AI-RPM technologies to support clinicians'decision-making while emphasizing the importance of customizable interfaceswith explainability and multiple responsible design considerations.",Bingsheng Yao,2025-02-06,2025-02-06,,N/A,['cs.HC']
2502.03731v1,A Physiological-Model-Based Neural Network Framework for Blood Pressure Estimation from Photoplethysmography Signals,http://arxiv.org/abs/2502.03731v1,"Continuous blood pressure (BP) estimation via photoplethysmography (PPG)remains a significant challenge, particularly in providing comprehensivecardiovascular insights for hypertensive complications. This study presents anovel physiological model-based neural network (PMB-NN) framework for BPestimation from PPG signals, incorporating the identification of totalperipheral resistance (TPR) and arterial compliance (AC) to enhancephysiological interpretability. Preliminary experimental results, obtained froma single healthy participant under varying activity intensities, demonstratedpromising accuracy, with a median root mean square error of 6.69 mmHg forsystolic BP and 3.26 mmHg for diastolic BP. The median (min, max) differencebetween estimated and measured TPR was 0.043 (0.024, 0.061) mmHg*s/cm^3. Asexpected, estimated TPR decreased with increasing activity intensity, while ACincreased within a physiologically plausible range (0.5-2.5 cm^3/mmHg).",Yaowen Zhang,2025-02-06,2025-02-06,,N/A,['physics.med-ph']
2502.03730v1,On the relationship between the cosmic web and the alignment of galaxies and AGN jets,http://arxiv.org/abs/2502.03730v1,"The impact of active galactic nuclei (AGN) on the evolution of galaxiesexplains the steep decrease in the number density of the most massive galaxiesin the Universe. However, the fueling of the AGN and the efficiency of thisfeedback largely depend on their environment. We use data from the LowFrequency Array (LOFAR) Two-metre Sky Survey Data Release 2 (LoTSS DR2), theDark Energy Spectroscopic Instrument (DESI) Legacy Imaging Surveys, and theSloan Digital Sky Survey (SDSS) DR12 to make the first study of theorientations of radio jets and their optical counterpart in relation to thecosmic web environment. We find that close to filaments ($\lesssim 11 \,\rmMpc$), galaxies tend to have their optical major axes aligned with the nearestfilaments. On the other hand, radio jets, which are generally alignedperpendicularly to the optical major axis of the host galaxy, show morerandomised orientations with respect to host galaxies within $\lesssim 8 \,\rmMpc$ of filaments. These results support the scenario that massive galaxies incosmic filaments grow by numerous mergers directed along the orientation of thefilaments while experiencing chaotic accretion of gas onto the central blackhole. The AGN-driven jets consequently have a strong impact preferentiallyalong the minor axes of dark matter halos within filaments. We discuss theimplications of these results for large-scale radio jet alignments, intrinsicalignments between galaxies, and the azimuthal anisotropy of the distributionof circumgalactic medium and anisotropic quenching.",Seoyoung Lyla Jung,2025-02-06,2025-02-06,,N/A,['astro-ph.GA']
2502.03729v1,Action-Free Reasoning for Policy Generalization,http://arxiv.org/abs/2502.03729v1,"End-to-end imitation learning offers a promising approach for training robotpolicies. However, generalizing to new settings remains a significantchallenge. Although large-scale robot demonstration datasets have shownpotential for inducing generalization, they are resource-intensive to scale. Incontrast, human video data is abundant and diverse, presenting an attractivealternative. Yet, these human-video datasets lack action labels, complicatingtheir use in imitation learning. Existing methods attempt to extract groundedaction representations (e.g., hand poses), but resulting policies struggle tobridge the embodiment gap between human and robot actions. We propose analternative approach: leveraging language-based reasoning from humanvideos-essential for guiding robot actions-to train generalizable robotpolicies. Building on recent advances in reasoning-based policy architectures,we introduce Reasoning through Action-free Data (RAD). RAD learns from bothrobot demonstration data (with reasoning and action labels) and action-freehuman video data (with only reasoning labels). The robot data teaches the modelto map reasoning to low-level actions, while the action-free data enhancesreasoning capabilities. Additionally, we will release a new dataset of 3,377human-hand demonstrations with reasoning annotations compatible with the BridgeV2 benchmark and aimed at facilitating future research on reasoning-drivenrobot learning. Our experiments show that RAD enables effective transfer acrossthe embodiment gap, allowing robots to perform tasks seen only in action-freedata. Furthermore, scaling up action-free reasoning data significantly improvespolicy performance and generalization to novel tasks. These results highlightthe promise of reasoning-driven learning from action-free datasets foradvancing generalizable robot control. Project page:https://rad-generalization.github.io",Jaden Clark,2025-02-06,2025-02-06,,N/A,"['cs.RO', 'cs.AI']"
2502.03727v1,Microstructure-Aware Bayesian Materials Design,http://arxiv.org/abs/2502.03727v1,"In this study, we propose a novel microstructure-sensitive Bayesianoptimization (BO) framework designed to enhance the efficiency of materialsdiscovery by explicitly incorporating microstructural information. Traditionalmaterials design approaches often focus exclusively on directchemistry-process-property relationships, overlooking the critical role ofmicrostructures. To address this limitation, our framework integratesmicrostructural descriptors as latent variables, enabling the construction of acomprehensive process-structure-property mapping that improves both predictiveaccuracy and optimization outcomes. By employing the active subspace method fordimensionality reduction, we identify the most influential microstructuralfeatures, thereby reducing computational complexity while maintaining highaccuracy in the design process. This approach also enhances the probabilisticmodeling capabilities of Gaussian processes, accelerating convergence tooptimal material configurations with fewer iterations and experimentalobservations. We demonstrate the efficacy of our framework through syntheticand real-world case studies, including the design of Mg$_2$Sn$_x$Si$_{1-x}$thermoelectric materials for energy conversion. Our results underscore thecritical role of microstructures in linking processing conditions to materialproperties, highlighting the potential of a microstructure-aware designparadigm to revolutionize materials discovery. Furthermore, this work suggeststhat since incorporating microstructure awareness improves the efficiency ofBayesian materials discovery, microstructure characterization stages should beintegral to automated -- and eventually autonomous -- platforms for materialsdevelopment.",Danial Khatamsaz,2025-02-06,2025-02-06,,N/A,['cond-mat.mtrl-sci']
2502.03726v1,DICE: Distilling Classifier-Free Guidance into Text Embeddings,http://arxiv.org/abs/2502.03726v1,"Text-to-image diffusion models are capable of generating high-quality images,but these images often fail to align closely with the given text prompts.Classifier-free guidance (CFG) is a popular and effective technique forimproving text-image alignment in the generative process. However, using CFGintroduces significant computational overhead and deviates from the establishedtheoretical foundations of diffusion models. In this paper, we presentDIstilling CFG by enhancing text Embeddings (DICE), a novel approach thatremoves the reliance on CFG in the generative process while maintaining thebenefits it provides. DICE distills a CFG-based text-to-image diffusion modelinto a CFG-free version by refining text embeddings to replicate CFG-baseddirections. In this way, we avoid the computational and theoretical drawbacksof CFG, enabling high-quality, well-aligned image generation at a fast samplingspeed. Extensive experiments on multiple Stable Diffusion v1.5 variants, SDXLand PixArt-$\alpha$ demonstrate the effectiveness of our method. Furthermore,DICE supports negative prompts for image editing to improve image qualityfurther. Code will be available soon.",Zhenyu Zhou,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03723v1,Speaking the Language of Teamwork: LLM-Guided Credit Assignment in Multi-Agent Reinforcement Learning,http://arxiv.org/abs/2502.03723v1,"Credit assignment, the process of attributing credit or blame to individualagents for their contributions to a team's success or failure, remains afundamental challenge in multi-agent reinforcement learning (MARL),particularly in environments with sparse rewards. Commonly-used approaches suchas value decomposition often lead to suboptimal policies in these settings, anddesigning dense reward functions that align with human intuition can be complexand labor-intensive. In this work, we propose a novel framework where a largelanguage model (LLM) generates dense, agent-specific rewards based on a naturallanguage description of the task and the overall team goal. By learning apotential-based reward function over multiple queries, our method reduces theimpact of ranking errors while allowing the LLM to evaluate each agent'scontribution to the overall task. Through extensive experiments, we demonstratethat our approach achieves faster convergence and higher policy returnscompared to state-of-the-art MARL baselines.",Muhan Lin,2025-02-06,2025-02-06,,N/A,['cs.MA']
2502.03724v1,MD-BERT: Action Recognition in Dark Videos via Dynamic Multi-Stream Fusion and Temporal Modeling,http://arxiv.org/abs/2502.03724v1,"Action recognition in dark, low-light (under-exposed) or noisy videos is achallenging task due to visibility degradation, which can hinder criticalspatiotemporal details. This paper proposes MD-BERT, a novel multi-streamapproach that integrates complementary pre-processing techniques such as gammacorrection and histogram equalization alongside raw dark frames to addressthese challenges. We introduce the Dynamic Feature Fusion (DFF) module,extending existing attentional fusion methods to a three-stream setting,thereby capturing fine-grained and global contextual information acrossdifferent brightness and contrast enhancements. The fused spatiotemporalfeatures are then processed by a BERT-based temporal model, which leverages itsbidirectional self-attention to effectively capture long-range dependencies andcontextual relationships across frames. Extensive experiments on the ARID V1.0and ARID V1.5 dark video datasets show that MD-BERT outperforms existingmethods, establishing a new state-of-the-art performance. Ablation studiesfurther highlight the individual contributions of each input stream and theeffectiveness of the proposed DFF and BERT modules. The official website ofthis work is available at: https://github.com/HrishavBakulBarua/DarkBERT",Sharana Dharshikgan Suresh Dass,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.AI', 'cs.HC', 'cs.LG', 'cs.MM', 'Artificial intelligence, Computer vision, Machine learning, Deep\n  learning, Human-computer Interaction', 'I.2; I.2.9; I.2.10; I.3.3; I.4.5']"
2502.03721v1,Detecting Backdoor Attacks via Similarity in Semantic Communication Systems,http://arxiv.org/abs/2502.03721v1,"Semantic communication systems, which leverage Generative AI (GAI) totransmit semantic meaning rather than raw data, are poised to revolutionizemodern communications. However, they are vulnerable to backdoor attacks, a typeof poisoning manipulation that embeds malicious triggers into trainingdatasets. As a result, Backdoor attacks mislead the inference for poisonedsamples while clean samples remain unaffected. The existing defenses may alterthe model structure (such as neuron pruning that potentially degrades inferenceperformance on clean inputs, or impose strict requirements on data formats(such as ``Semantic Shield"" that requires image-text pairs). To address theselimitations, this work proposes a defense mechanism that leverages semanticsimilarity to detect backdoor attacks without modifying the model structure orimposing data format constraints. By analyzing deviations in semantic featurespace and establishing a threshold-based detection framework, the proposedapproach effectively identifies poisoned samples. The experimental resultsdemonstrate high detection accuracy and recall across varying poisoning ratios,underlining the significant effectiveness of our proposed solution.",Ziyang Wei,2025-02-06,2025-02-06,,N/A,"['cs.CR', 'cs.LG']"
2502.03719v1,Code Shaping: Iterative Code Editing with Free-form AI-Interpreted Sketching,http://arxiv.org/abs/2502.03719v1,"We introduce the concept of code shaping, an interaction paradigm for editingcode using free-form sketch annotations directly on top of the code and consoleoutput. To evaluate this concept, we conducted a three-stage design study with18 different programmers to investigate how sketches can communicate intendedcode edits to an AI model for interpretation and execution. The results showhow different sketches are used, the strategies programmers employ duringiterative interactions with AI interpretations, and interaction designprinciples that support the reconciliation between the code editor andsketches. Finally, we demonstrate the practical application of the code shapingconcept with two use case scenarios, illustrating design implications from thestudy.",Ryan Yen,2025-02-06,2025-02-06,,N/A,['cs.HC']
2502.03717v1,Efficiently Generating Expressive Quadruped Behaviors via Language-Guided Preference Learning,http://arxiv.org/abs/2502.03717v1,"Expressive robotic behavior is essential for the widespread acceptance ofrobots in social environments. Recent advancements in learned legged locomotioncontrollers have enabled more dynamic and versatile robot behaviors. However,determining the optimal behavior for interactions with different users acrossvaried scenarios remains a challenge. Current methods either rely on naturallanguage input, which is efficient but low-resolution, or learn from humanpreferences, which, although high-resolution, is sample inefficient. This paperintroduces a novel approach that leverages priors generated by pre-trained LLMsalongside the precision of preference learning. Our method, termedLanguage-Guided Preference Learning (LGPL), uses LLMs to generate initialbehavior samples, which are then refined through preference-based feedback tolearn behaviors that closely align with human expectations. Our core insight isthat LLMs can guide the sampling process for preference learning, leading to asubstantial improvement in sample efficiency. We demonstrate that LGPL canquickly learn accurate and expressive behaviors with as few as four queries,outperforming both purely language-parameterized models and traditionalpreference learning approaches. Website with videos:https://lgpl-gaits.github.io/",Jaden Clark,2025-02-06,2025-02-06,,N/A,"['cs.RO', 'cs.AI']"
2502.03716v1,Optimal Constructions for DNA Self-Assembly of $k$-Regular Graphs,http://arxiv.org/abs/2502.03716v1,"Within biology, it is of interest to construct DNA complexes of a certainshape. These complexes can be represented through graph theory, using edges tomodel strands of DNA joined at junctions, represented by vertices. Becauseguided construction is inefficient, design strategies for DNA self-assembly aredesirable. In the flexible tile model, branched DNA molecules are referred toas tiles, each consisting of flexible unpaired cohesive ends with the abilityto form bond-edges. We thus consider the minimum number of tile and bond-edgetypes necessary to construct a graph $G$ (i.e. a target structure) withoutallowing the formation of graphs of lesser order, or nonisomorphic graphs ofequal order. We emphasize the concept of (un)swappable graphs, establishinglower bounds for unswappable graphs. We also introduce a method of establishingupper bounds via vertex covers. We apply both of these methods to prove newbounds on rook's graphs and Kneser graphs.",Lisa Baek,2025-02-06,2025-02-06,,N/A,['math.CO']
2502.03715v1,Boosting Knowledge Graph-based Recommendations through Confidence-Aware Augmentation with Large Language Models,http://arxiv.org/abs/2502.03715v1,"Knowledge Graph-based recommendations have gained significant attention dueto their ability to leverage rich semantic relationships. However, constructingand maintaining Knowledge Graphs (KGs) is resource-intensive, and the accuracyof KGs can suffer from noisy, outdated, or irrelevant triplets. Recentadvancements in Large Language Models (LLMs) offer a promising way to improvethe quality and relevance of KGs for recommendation tasks. Despite this,integrating LLMs into KG-based systems presents challenges, such as efficientlyaugmenting KGs, addressing hallucinations, and developing effective jointlearning methods. In this paper, we propose the Confidence-aware KG-basedRecommendation Framework with LLM Augmentation (CKG-LLMA), a novel frameworkthat combines KGs and LLMs for recommendation task. The framework includes: (1)an LLM-based subgraph augmenter for enriching KGs with high-qualityinformation, (2) a confidence-aware message propagation mechanism to filternoisy triplets, and (3) a dual-view contrastive learning method to integrateuser-item interactions and KG data. Additionally, we employ a confidence-awareexplanation generation process to guide LLMs in producing realisticexplanations for recommendations. Finally, extensive experiments demonstratethe effectiveness of CKG-LLMA across multiple public datasets.",Rui Cai,2025-02-06,2025-02-06,,N/A,"['cs.IR', 'cs.AI']"
2502.03714v1,Universal Sparse Autoencoders: Interpretable Cross-Model Concept Alignment,http://arxiv.org/abs/2502.03714v1,"We present Universal Sparse Autoencoders (USAEs), a framework for uncoveringand aligning interpretable concepts spanning multiple pretrained deep neuralnetworks. Unlike existing concept-based interpretability methods, which focuson a single model, USAEs jointly learn a universal concept space that canreconstruct and interpret the internal activations of multiple models at once.Our core insight is to train a single, overcomplete sparse autoencoder (SAE)that ingests activations from any model and decodes them to approximate theactivations of any other model under consideration. By optimizing a sharedobjective, the learned dictionary captures common factors ofvariation-concepts-across different tasks, architectures, and datasets. We showthat USAEs discover semantically coherent and important universal conceptsacross vision models; ranging from low-level features (e.g., colors andtextures) to higher-level structures (e.g., parts and objects). Overall, USAEsprovide a powerful new method for interpretable cross-model analysis and offersnovel applications, such as coordinated activation maximization, that openavenues for deeper insights in multi-model AI systems",Harrish Thasarathan,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.LG']"
2502.03713v1,A discrete Perfectly Matched Layer for peridynamic scalar waves in two-dimensional viscous media,http://arxiv.org/abs/2502.03713v1,"In this paper, we propose a discrete perfectly matched layer (PML) for theperidynamic scalar wave-type problems in viscous media. Constructing PMLs fornonlocal models is often challenging, mainly due to the fact that nonlocaloperators are usually associated with various kernels. We first convert thecontinua model to a spatial semi-discretized version by adoptingquadrature-based finite difference scheme, and then derive the PML equationsfrom the semi-discretized equations using discrete analytic continuation. Theharmonic exponential fundamental solutions (plane wave modes) of thesemi-discretized equations are absorbed by the PML layer without reflection andare exponentially damped. The excellent efficiency and stability of discretePML are demonstrated in numerical tests by comparison with exact absorbingboundary conditions.",Yu Du,2025-02-06,2025-02-06,,N/A,"['math.NA', 'cs.NA', '65N30, 65R20, 46N20, 45A05, 78A40', 'G.1.0; G.1.8']"
2502.03711v1,MultiQ&A: An Analysis in Measuring Robustness via Automated Crowdsourcing of Question Perturbations and Answers,http://arxiv.org/abs/2502.03711v1,"One critical challenge in the institutional adoption journey of LargeLanguage Models (LLMs) stems from their propensity to hallucinate in generatedresponses. To address this, we propose MultiQ&A, a systematic approach forevaluating the robustness and consistency of LLM-generated answers. Wedemonstrate MultiQ&A's ability to crowdsource question perturbations and theirrespective answers through independent LLM agents at scale. Our experimentsculminated in the examination of 1.9 million question perturbations and 2.3million answers. Furthermore, MultiQ&A shows that ensembled LLMs, such asgpt-3.5-turbo, remain relatively robust and consistent under perturbations.MultiQ&A provides clarity in the response generation space, offering aneffective method for inspecting disagreements and variability. Therefore, oursystem offers a potential framework for institutional LLM adoption with theability to measure confidence, consistency, and the quantification ofhallucinations.",Nicole Cho,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI', 'cs.LG']"
2502.03708v1,Aggregate and conquer: detecting and steering LLM concepts by combining nonlinear predictors over multiple layers,http://arxiv.org/abs/2502.03708v1,"A trained Large Language Model (LLM) contains much of human knowledge. Yet,it is difficult to gauge the extent or accuracy of that knowledge, as LLMs donot always ``know what they know'' and may even be actively misleading. In thiswork, we give a general method for detecting semantic concepts in the internalactivations of LLMs. Furthermore, we show that our methodology can be easilyadapted to steer LLMs toward desirable outputs. Our innovations are thefollowing: (1) we use a nonlinear feature learning method to identify importantlinear directions for predicting concepts from each layer; (2) we aggregatefeatures across layers to build powerful concept detectors and steeringmechanisms. We showcase the power of our approach by attaining state-of-the-artresults for detecting hallucinations, harmfulness, toxicity, and untruthfulcontent on seven benchmarks. We highlight the generality of our approach bysteering LLMs towards new concepts that, to the best of our knowledge, have notbeen previously considered in the literature, including: semanticdisambiguation, human languages, programming languages, hallucinated responses,science subjects, poetic/Shakespearean English, and even multiple conceptssimultaneously. Moreover, our method can steer concepts with numericalattributes such as product reviews. We provide our code (including a simple APIfor our methods) at https://github.com/dmbeaglehole/neural_controllers .",Daniel Beaglehole,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI', 'stat.ML']"
2502.03706v1,Novel echoes from black holes in conformal Weyl gravity,http://arxiv.org/abs/2502.03706v1,"We reveal a novel class of echoes from black holes in conformal Weyl gravityand show that they are generated due to the large-scale structure of thecosmos, rather than near-horizon modifications of black holes as well aswormhole spacetimes. To this end, we take into account the evolution of amassive scalar perturbation on the background geometry of conformal Weyl blackholes and show that the corresponding effective potential enjoys a double-peakbarrier against the incident scalar waves. We perform the calculations for thetime evolution profiles of scalar perturbations to understand how the linearterm in the metric function and the cosmological constant produce echoes. TheProny method is also employed to calculate the quasinormal frequencies of theearly-stage quasinormal ringing phase.",Mehrab Momennia,2025-02-06,2025-02-06,,N/A,"['gr-qc', 'hep-th']"
2502.03705v1,Dependence of Multi-band Absolute Magnitudes and Color Indexes of the Tip of Red Giant Branch Stars on Metallicity in the Galactic Globular Clusters,http://arxiv.org/abs/2502.03705v1,"The tip of red giant branch (TRGB) stars have attracted intensive attentionin recent years because their $I$-band absolute magnitudes, $M_\rm I$, areoften used for distance calibration in the Hubble constant measurements becauseof its almost independence on metallicity ([Fe/H]). However, a discrepancyexists between various studies and the theoretical stellar model predictsdependence of their luminosity on [Fe/H]. Here we present a careful study ofthe dependence of absolute magnitudes and color indexes on metallicity inoptical and near-infrared bands. With the TRGB stars identified in 33 Galacticglobular clusters by the reddest color in the $G_{\rm BP}-G_{\rm RP}$ vs.$G_{\rm RP}$ diagram, it is confirmed that $M_\rm I$ is almost constant of$-4.017 \pm 0.036 \pm 0.027$ mag when $[\rm Fe/H]<-1.2$, which would give$H_0=70.86\pm 1.2\pm0.9$ $\rm kms^{-1} Mp c^{-1}$ with this updated luminositycalibration for type Ia supernovae. However, for $[\rm Fe/H]>-1.2$, $M_\rm I$is found to become fainter with lower metallicity, which would lead to a largerHubble constant. In the optical $G_{\rm BP}, G_{\rm RP}$ and $V$ bands, theabsolute magnitude of TRGB stars tends to increase with metallicity, while inthe infrared $J, H$, and $K_{\rm S}$ bands, the variation with metallicityshows an inverse tendency. In addition, the analytical relations of the colorindexes with metallicity are presented, which have smaller dispersion thanthose derived for the corresponding absolute magnitudes.",Zhenzhen Shao,2025-02-06,2025-02-06,,N/A,"['astro-ph.SR', 'astro-ph.GA']"
2502.03701v1,First-ish Order Methods: Hessian-aware Scalings of Gradient Descent,http://arxiv.org/abs/2502.03701v1,"Gradient descent is the primary workhorse for optimizing large-scale problemsin machine learning. However, its performance is highly sensitive to the choiceof the learning rate. A key limitation of gradient descent is its lack ofnatural scaling, which often necessitates expensive line searches or heuristictuning to determine an appropriate step size. In this paper, we address thislimitation by incorporating Hessian information to scale the gradientdirection. By accounting for the curvature of the function along the gradient,our adaptive, Hessian-aware scaling method ensures a local unit step sizeguarantee, even in nonconvex settings. Near a local minimum that satisfies thesecond-order sufficient conditions, our approach achieves linear convergencewith a unit step size. We show that our method converges globally under asignificantly weaker version of the standard Lipschitz gradient smoothnessassumption. Even when Hessian information is inexact, the local unit step sizeguarantee and global convergence properties remain valid under mild conditions.Finally, we validate our theoretical results empirically on a range of convexand nonconvex machine learning tasks, showcasing the effectiveness of theapproach.",Oscar Smee,2025-02-06,2025-02-06,,N/A,"['math.OC', 'cs.LG', '49']"
2502.03700v1,Spectral parameters of the $ρ$ resonance from lattice QCD,http://arxiv.org/abs/2502.03700v1,"We present a lattice QCD investigation of the $\rho$ resonance using nine$N_f = 2 + 1$ Wilson-Clover ensembles with three lattice spacings and variouspion masses ranging from $135$ to $320$ MeV. For each ensemble, a large numberof finite volume energy levels are determined and the energy dependence of thephase shift obtained from L\""uscher's finite volume method. The mass and widthof the $\rho$ resonance are then extracted by assuming the Breit-Wigner form.The mass and width are extrapolated to the physical pion mass and continuumlimit ($\mathcal{O}(a^2)$) using a linear function of $a^2$ and $m^2_\pi$. Theextrapolated values for the mass and width in the Breit-Wigner form are$(m_\rho,\,\Gamma_\rho) = (781.6\pm10.0,\, 146.5\pm 9.9)$ MeV, which are ingood agreement with experiment. An alternative method of analysis, based onHamiltonian effective field theory, involves directly fitting the latticeenergy levels and accounting for the quark mass dependence of the hadronic loopdiagrams which yield the leading and next-to-leading non-analytic behaviour.This approach also yields consistent $\rho$ parameters at the physical point.This represents the most precise determination to date of the mass and width ofa hadron which is unstable under strong decay, achieved through comprehensivelattice QCD calculations and methods of analysis.",Zhengli Wang,2025-02-06,2025-02-06,,N/A,"['hep-lat', 'hep-ph']"
2502.03699v1,LLM Alignment as Retriever Optimization: An Information Retrieval Perspective,http://arxiv.org/abs/2502.03699v1,"Large Language Models (LLMs) have revolutionized artificial intelligence withcapabilities in reasoning, coding, and communication, driving innovation acrossindustries. Their true potential depends on effective alignment to ensurecorrect, trustworthy and ethical behavior, addressing challenges likemisinformation, hallucinations, bias and misuse. While existing ReinforcementLearning (RL)-based alignment methods are notoriously complex, directoptimization approaches offer a simpler alternative. In this work, we introducea novel direct optimization approach for LLM alignment by drawing onestablished Information Retrieval (IR) principles. We present a systematicframework that bridges LLM alignment and IR methodologies, mapping LLMgeneration and reward models to IR's retriever-reranker paradigm. Building onthis foundation, we propose LLM Alignment as Retriever Preference Optimization(LarPO), a new alignment method that enhances overall alignment quality.Extensive experiments validate LarPO's effectiveness with 38.9 % and 13.7 %averaged improvement on AlpacaEval2 and MixEval-Hard respectively. Our workopens new avenues for advancing LLM alignment by integrating IR foundations,offering a promising direction for future research.",Bowen Jin,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI', 'cs.IR']"
2502.03698v1,How vulnerable is my policy? Adversarial attacks on modern behavior cloning policies,http://arxiv.org/abs/2502.03698v1,"Learning from Demonstration (LfD) algorithms have shown promising results inrobotic manipulation tasks, but their vulnerability to adversarial attacksremains underexplored. This paper presents a comprehensive study of adversarialattacks on both classic and recently proposed algorithms, including BehaviorCloning (BC), LSTM-GMM, Implicit Behavior Cloning (IBC), Diffusion Policy (DP),and VQ-Behavior Transformer (VQ-BET). We study the vulnerability of thesemethods to untargeted, targeted and universal adversarial perturbations. Whileexplicit policies, such as BC, LSTM-GMM and VQ-BET can be attacked in the samemanner as standard computer vision models, we find that attacks for implicitand denoising policy models are nuanced and require developing novel attackmethods. Our experiments on several simulated robotic manipulation tasks revealthat most of the current methods are highly vulnerable to adversarialperturbations. We also show that these attacks are transferable acrossalgorithms, architectures, and tasks, raising concerning securityvulnerabilities with potentially a white-box threat model. In addition, we testthe efficacy of a randomized smoothing, a widely used adversarial defensetechnique, and highlight its limitation in defending against attacks on complexand multi-modal action distribution common in complex control tasks. Insummary, our findings highlight the vulnerabilities of modern BC algorithms,paving way for future work in addressing such limitations.",Basavasagar Patil,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.CR', 'cs.RO']"
2502.03696v1,Cascaded Learned Bloom Filter for Optimal Model-Filter Size Balance and Fast Rejection,http://arxiv.org/abs/2502.03696v1,"Recent studies have demonstrated that learned Bloom filters, which combinemachine learning with the classical Bloom filter, can achieve superior memoryefficiency. However, existing learned Bloom filters face two criticalunresolved challenges: the balance between the machine learning model size andthe Bloom filter size is not optimal, and the reject time cannot be minimizedeffectively. We propose the Cascaded Learned Bloom Filter (CLBF) to addressthese issues. Our dynamic programming-based optimization automatically selectsconfigurations that achieve an optimal balance between the model and filtersizes while minimizing reject time. Experiments on real-world datasets showthat CLBF reduces memory usage by up to 24% and decreases reject time by up to14 times compared to state-of-the-art learned Bloom filters.",Atsuki Sato,2025-02-06,2025-02-06,,N/A,"['cs.DS', 'cs.CC', 'cs.LG']"
2502.03695v1,Reduce Lap Time for Autonomous Racing with Curvature-Integrated MPCC Local Trajectory Planning Method,http://arxiv.org/abs/2502.03695v1,"The widespread application of autonomous driving technology has significantlyadvanced the field of autonomous racing. Model Predictive Contouring Control(MPCC) is a highly effective local trajectory planning method for autonomousracing. However, the traditional MPCC method struggles with racetracks thathave significant curvature changes, limiting the performance of the vehicleduring autonomous racing. To address this issue, we propose acurvature-integrated MPCC (CiMPCC) local trajectory planning method forautonomous racing. This method optimizes the velocity of the local trajectorybased on the curvature of the racetrack centerline. The specific implementationinvolves mapping the curvature of the racetrack centerline to a referencevelocity profile, which is then incorporated into the cost function foroptimizing the velocity of the local trajectory. This reference velocityprofile is created by normalizing and mapping the curvature of the racetrackcenterline, thereby ensuring efficient and performance-oriented localtrajectory planning in racetracks with significant curvature. The proposedCiMPCC method has been experimented on a self-built 1:10 scale F1TENTH racingvehicle deployed with ROS platform. The experimental results demonstrate thatthe proposed method achieves outstanding results on a challenging racetrackwith sharp curvature, improving the overall lap time by 11.4%-12.5% compared toother autonomous racing trajectory planning methods. Our code is available athttps://github.com/zhouhengli/CiMPCC.",Zhouheng Li,2025-02-06,2025-02-06,,N/A,"['cs.RO', 'cs.SY', 'eess.SY']"
2502.03693v1,Misspecification-Robust Shrinkage and Selection for VAR Forecasts and IRFs,http://arxiv.org/abs/2502.03693v1,"VARs are often estimated with Bayesian techniques to cope with modeldimensionality. The posterior means define a class of shrinkage estimators,indexed by hyperparameters that determine the relative weight on maximumlikelihood estimates and prior means. In a Bayesian setting, it is natural tochoose these hyperparameters by maximizing the marginal data density. However,this is undesirable if the VAR is misspecified. In this paper, we deriveasymptotically unbiased estimates of the multi-step forecasting risk and theimpulse response estimation risk to determine hyperparameters in settings wherethe VAR is (potentially) misspecified. The proposed criteria can be used tojointly select the optimal shrinkage hyperparameter, VAR lag length, and tochoose among different types of multi-step-ahead predictors; or among IRFestimates based on VARs and local projections. The selection approach isillustrated in a Monte Carlo study and an empirical application.",Oriol González-Casasús,2025-02-06,2025-02-06,,N/A,['econ.EM']
2502.03692v1,DocMIA: Document-Level Membership Inference Attacks against DocVQA Models,http://arxiv.org/abs/2502.03692v1,"Document Visual Question Answering (DocVQA) has introduced a new paradigm forend-to-end document understanding, and quickly became one of the standardbenchmarks for multimodal LLMs. Automating document processing workflows,driven by DocVQA models, presents significant potential for many businesssectors. However, documents tend to contain highly sensitive information,raising concerns about privacy risks associated with training such DocVQAmodels. One significant privacy vulnerability, exploited by the membershipinference attack, is the possibility for an adversary to determine if aparticular record was part of the model's training data. In this paper, weintroduce two novel membership inference attacks tailored specifically toDocVQA models. These attacks are designed for two different adversarialscenarios: a white-box setting, where the attacker has full access to the modelarchitecture and parameters, and a black-box setting, where only the model'soutputs are available. Notably, our attacks assume the adversary lacks accessto auxiliary datasets, which is more realistic in practice but also morechallenging. Our unsupervised methods outperform existing state-of-the-artmembership inference attacks across a variety of DocVQA models and datasets,demonstrating their effectiveness and highlighting the privacy risks in thisdomain.",Khanh Nguyen,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.CL', 'cs.CR']"
2502.03688v1,A Comparison of DeepSeek and Other LLMs,http://arxiv.org/abs/2502.03688v1,"Recently, DeepSeek has been the focus of attention in and beyond the AIcommunity. An interesting problem is how DeepSeek compares to other largelanguage models (LLMs). There are many tasks an LLM can do, and in this paper,we use the task of predicting an outcome using a short text for comparison. Weconsider two settings, an authorship classification setting and a citationclassification setting. In the first one, the goal is to determine whether ashort text is written by human or AI. In the second one, the goal is toclassify a citation to one of four types using the textual content. For eachexperiment, we compare DeepSeek with $4$ popular LLMs: Claude, Gemini, GPT, andLlama.  We find that, in terms of classification accuracy, DeepSeek outperformsGemini, GPT, and Llama in most cases, but underperforms Claude. We also findthat DeepSeek is comparably slower than others but with a low cost to use,while Claude is much more expensive than all the others. Finally, we find thatin terms of similarity, the output of DeepSeek is most similar to those ofGemini and Claude (and among all $5$ LLMs, Claude and Gemini have the mostsimilar outputs).  In this paper, we also present a fully-labeled dataset collected byourselves, and propose a recipe where we can use the LLMs and a recent dataset, MADStat, to generate new data sets. The datasets in our paper can be usedas benchmarks for future study on LLMs.",Tianchen Gao,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.03687v1,Conditional Diffusion Models are Medical Image Classifiers that Provide Explainability and Uncertainty for Free,http://arxiv.org/abs/2502.03687v1,"Discriminative classifiers have become a foundational tool in deep learningfor medical imaging, excelling at learning separable features of complex datadistributions. However, these models often need careful design, augmentation,and training techniques to ensure safe and reliable deployment. Recently,diffusion models have become synonymous with generative modeling in 2D. Thesemodels showcase robustness across a range of tasks including natural imageclassification, where classification is performed by comparing reconstructionerrors across images generated for each possible conditioning input. This workpresents the first exploration of the potential of class conditional diffusionmodels for 2D medical image classification. First, we develop a novel majorityvoting scheme shown to improve the performance of medical diffusionclassifiers. Next, extensive experiments on the CheXpert and ISIC Melanoma skincancer datasets demonstrate that foundation and trained-from-scratch diffusionmodels achieve competitive performance against SOTA discriminative classifierswithout the need for explicit supervision. In addition, we show that diffusionclassifiers are intrinsically explainable, and can be used to quantify theuncertainty of their predictions, increasing their trustworthiness andreliability in safety-critical, clinical contexts. Further information isavailable on our project page:https://faverogian.github.io/med-diffusion-classifier.github.io/",Gian Mario Favero,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.LG']"
2502.03686v1,Variational Control for Guidance in Diffusion Models,http://arxiv.org/abs/2502.03686v1,"Diffusion models exhibit excellent sample quality, but existing guidancemethods often require additional model training or are limited to specifictasks. We revisit guidance in diffusion models from the perspective ofvariational inference and control, introducing Diffusion Trajectory Matching(DTM) that enables guiding pretrained diffusion trajectories to satisfy aterminal cost. DTM unifies a broad class of guidance methods and enables novelinstantiations. We introduce a new method within this framework that achievesstate-of-the-art results on several linear and (blind) non-linear inverseproblems without requiring additional model training or modifications. Forinstance, in ImageNet non-linear deblurring, our model achieves an FID score of34.31, significantly improving over the best pretrained-method baseline (FID78.07). We will make the code available in a future update.",Kushagra Pandey,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI', 'cs.CV', 'stat.ML']"
2502.03685v1,Controlled LLM Decoding via Discrete Auto-regressive Biasing,http://arxiv.org/abs/2502.03685v1,"Controlled text generation allows for enforcing user-defined constraints onlarge language model outputs, an increasingly important field as LLMs becomemore prevalent in everyday life. One common approach uses energy-baseddecoding, which defines a target distribution through an energy function thatcombines multiple constraints into a weighted average. However, these methodsoften struggle to balance fluency with constraint satisfaction, even withextensive tuning of the energy function's coefficients. In this paper, weidentify that this suboptimal balance arises from sampling in continuous spacerather than the natural discrete space of text tokens. To address this, wepropose Discrete Auto-regressive Biasing, a controlled decoding algorithm thatleverages gradients while operating entirely in the discrete text domain.Specifically, we introduce a new formulation for controlled text generation bydefining a joint distribution over the generated sequence and an auxiliary biassequence. To efficiently sample from this joint distribution, we propose aLangevin-within-Gibbs sampling algorithm using gradient-based discrete MCMC.Our method significantly improves constraint satisfaction while maintainingcomparable or better fluency, all with even lower computational costs. Wedemonstrate the advantages of our controlled decoding method on sentimentcontrol, language detoxification, and keyword-guided generation.",Patrick Pynadath,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.LG', 'stat.ML']"
2502.03683v1,Ruling out AGNs as the dominant source of cosmic reionization with JWST,http://arxiv.org/abs/2502.03683v1,"Cosmic reionization represents the latest phase transition of theintergalactic medium (IGM) in the Universe. It has long been debated whethergalaxies or active galactic nuclei (AGNs) are the major source of Lymancontinuum (LyC) photons responsible for reionization. Previous observationsslightly favored galaxies as the major ionizing source. However, the James WebbSpace Telescope (JWST) recently discovered an unexpectedly high density of AGNcandidates at high redshift, which has largely enhanced the influence of AGNs.Here we derive a definitive upper bound on the AGN contribution to reionizationusing the latest JWST data, and conclusively rule out AGNs as the dominantionizing source during the epoch of reionization (EoR). We build a sample ofobjects (including galaxies and AGNs) in a specific redshift range between 7.15and 7.75 that has a high completeness. Each object is then decomposed into apoint-source component and an extended component in their rest-frame far-UVJWST images. Assuming all point-source components are AGNs, we obtain anabsolute upper limit for the density of the AGN population. This fiducial AGNsample reaches an unprecedentedly low luminosity of $M_{\rm UV} \approx -15$mag. Based on this sample, we find that AGNs can contribute at most one thirdof the LyC photons required to ionize the Universe in this redshift range. Ourresult implies that galaxies dominate the ionizing source during the EoR.",Danyang Jiang,2025-02-06,2025-02-06,,N/A,['astro-ph.GA']
