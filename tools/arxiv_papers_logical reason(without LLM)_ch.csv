Paper ID,Title,URL,Summary,First Author,Publish Date,Update Date,Code URL,Stars,Categories
2508.06623v1,ContextGuard-LVLM：通过细粒度跨模态上下文一致性验证增强新闻真实性,http://arxiv.org/abs/2508.06623v1,数字新闻媒体的激增需要强有力的方法来验证内容的真实性，尤其是在视觉信息和文本信息之间的一致性方面。传统的做法往往无法充分解决细粒度跨模态上下文一致性（FCCC）问题，这涉及到视觉叙事、情感基调以及背景信息与文本的更深层次对齐，而不仅仅是实体匹配。为了解决这个问题，我们提出了ContextGuard-LVLM，这是一个基于高级视觉-语言大型模型（LVLM）并集成了多阶段上下文推理机制的全新框架。我们的模型通过强化或对抗学习范式得到了独特增强，使其能够检测那些逃避零样本基线的微妙上下文不匹配。我们将三个已建立的语料库（TamperedNews-Ent、News400-Ent、MMG-Ent）扩展并增强，加入了新的细粒度上下文注释，包括“上下文情感”、“视觉叙事主题”和“场景-事件逻辑连贯性”，并引入了一个全面的CTXT（上下文一致性）实体类型。大量的实验表明，ContextGuard-LVLM在几乎所有细粒度一致性任务中，都持续优于最先进的零样本LVLM基线（InstructBLIP和LLaVA 1.5），在复杂逻辑推理和微妙上下文理解方面取得了显著进步。此外，我们的模型对细微的扰动表现出更高的鲁棒性，并且在挑战性样本上与人类专家判断的吻合度更高，这证实了它在辨别复杂形式的上下文分离方面的有效性。,这是一个人名，英文直译成中文就是“希翰·玛”。不过，根据汉语人名的习惯，可能更倾向于译作“西韩玛”或者“西汗·玛”。具体译法可能需要结合上下文来确定。,2025/8/8,2025/8/8,,,['cs.CV']
2508.04163v1,通用到特定推理与学习，以实现可扩展的临时团队协作,http://arxiv.org/abs/2508.04163v1,在辅助角色中部署的AI代理通常需要在事先没有协调的情况下与其他代理（人类、AI系统）进行协作。对于这种临时团队合作的最佳方法，通常追求一种数据驱动的方法，这种方法需要大量已标记的先前观察数据集，缺乏透明度，并且难以快速修订现有知识以应对变化。随着代理数量的增加，决策的复杂性使得有效协作变得困难。本文主张利用基于知识和数据驱动方法的互补优势，以实现推理和学习。对于任何既定目标，我们的架构使每个临时代理能够通过非单调逻辑推理来确定其行为：（a）先前的常识领域特定知识；（b）快速学习和修订的模型，以预测其他代理的行为；（c）基于现有基础模型中类似情况的一般知识所预期的抽象未来目标。我们通过在虚拟家庭（一个基于现实物理的3D模拟环境）中进行了实验，评估了我们架构的能力。,哈莎·多达梅帕伽马,2025/8/6,2025/8/6,,,"['cs.AI', 'cs.LO', 'cs.MA']"
2507.23541v2,Med-R$^3$：通过渐进式强化学习增强LLMs的医学检索增强推理,http://arxiv.org/abs/2507.23541v2,在医疗场景中，有效地检索外部知识并利用它进行严格的逻辑推理具有重大意义。尽管现有工作具有潜力，但主要集中于独立增强模型的检索或推理能力，而对两者联合优化的关注较少，导致这两个过程之间的协调性有限。此外，当前方法高度依赖监督微调（SFT），这可能导致模型记住现有的解决问题的路径，从而限制了它们在面对新颖问题情境时的泛化能力。此外，尽管一些研究通过强化学习探索了改进通用领域的检索增强推理，但它们的奖励函数设计并没有充分捕捉到医疗领域的特定需求。为了解决这些挑战，我们引入了**Med-R$^3$**，这是一个由渐进式**R**增强学习驱动的**Med**医疗**R**etrieval-augmented**R**easoning框架。在这个框架中，我们首先开发模型在医疗问题上进行逻辑推理的能力。随后，在此基础上，我们自适应地优化检索能力，以更好地适应知识库和外部信息在整个推理过程中的利用特点。最后，我们对模型的检索和推理协调进行联合优化。大量实验表明，**Med-R$^3$**能够达到最先进的性能，其中LLaMA3.1-8B-Instruct + Med-R$^3$在可比参数规模下超过了闭源GPT-4o-mini，提高了3.93%，而Qwen2.5-14B增强后使用Med-R$^3$的增益更为显著，达到了13.53%。,库尔·鲁,2025/7/31,2025/8/2,,,['cs.CL']
2507.20999v1,LoRA-PAR：一种灵活的双系统LoRA分区方法，用于高效地进行大型语言模型微调,http://arxiv.org/abs/2507.20999v1,像DeepSeek-R1和OpenAI-O1这样的大规模生成模型，从思维链（CoT）推理中受益匪浅，但要推动它们的性能，通常需要大量数据、大型模型尺寸以及全面参数微调。尽管参数高效微调（PEFT）有助于降低成本，但大多数现有方法主要关注领域自适应或分层分配，而不是明确地根据不同的响应需求调整数据和参数。受到《思考，快与慢》的启发，该书描述了两种不同的思维模式——系统1（快速、直觉、通常自动）和系统2（较慢、更深思熟虑且分析性）——我们进行了类比，即LLM参数的不同“子区域”可能同样会专门针对需要快速、直觉性回应的任务以及需要多步逻辑推理的任务。因此，我们提出了LoRA-PAR，这是一种双系统LoRA框架，根据系统1或系统2的需求将数据和参数进行分区，使用较少但更专注于每个任务的参数。具体来说，我们通过多模型角色扮演和投票来分类任务数据，并根据重要性评分来分区参数，然后采用两阶段微调策略：使用监督微调（SFT）训练系统1任务以增强知识和直觉，并通过强化学习（RL）来精细化训练系统2任务，以强化更深入的逻辑深思熟虑。广泛的实验表明，两阶段微调策略（SFT和RL）在降低活动参数使用量的同时，匹配或超越了最先进的PEFT基准。,黄寅宁,2025/7/28,2025/7/28,,,"['cs.LG', 'cs.CL']"
2507.20960v1,《经典神经网络中层次嵌套逻辑的限制》,http://arxiv.org/abs/2507.20960v1,我们提出了一种针对大型神经网络模型在语言推理中的局限性形式化模型，该模型基于其神经网络结构的深度。通过将神经网络视为逻辑谓词空间上的线性算子，我们表明每一层最多只能编码一个额外的逻辑推理层次。我们证明了特定深度的神经网络无法忠实表示一阶逻辑以上的谓词，例如在复杂谓词上的简单计数，这暗示了逻辑表达能力的严格上限。这种结构在分词和嵌入过程中诱导出一个非平凡的零空间，排除了高阶谓词的可表示性。我们的框架为诸如幻觉、重复和有限规划等现象提供了自然的解释，同时也为理解高阶逻辑近似可能如何出现提供了基础。这些结果激励了在语言模型未来发展中进行架构扩展和可解释性策略。,比尔·科克伦,2025/7/28,2025/7/28,,,['cs.AI']
2507.20529v1,通过视觉和文本思维提升空间推理能力,http://arxiv.org/abs/2507.20529v1,空间推理任务旨在对2D和3D空间中的空间关系进行推理，这是视觉问答（VQA）和机器人技术的基本能力。尽管近年来视觉语言模型（VLMs）发展迅速，但它们在空间推理任务上仍然面临挑战。在这篇论文中，我们介绍了一种通过同时进行视觉和文本思考来增强空间推理的方法（简称SpatialVTS）。在空间视觉思考阶段，我们的模型被训练来自动生成关键目标与位置相关的特定标记。不仅解决了问题中提到的物体，还考虑了与推理相关的潜在物体。在空间文本思考阶段，我们的模型基于视觉提示和对话进行长期思考，逐步推断出空间推理问题的答案。为了有效地支持模型的训练，我们对现有的空间推理数据集进行了人工校正，消除了自动标注产生的众多错误标签，重新构建了数据输入格式以增强泛化能力，并开发了具有逻辑推理细节的思考过程。在不引入额外信息（如遮罩或深度信息）的情况下，我们模型在几个空间理解任务中的整体平均表现相较于其他模型有显著提升。,寻良,2025/7/28,2025/7/28,,,"['cs.CV', 'cs.AI']"
2507.19992v1,NIRS：急性护理中非侵入性呼吸支持的本体论,http://arxiv.org/abs/2507.19992v1,目标：开发一种非侵入性呼吸支持（NIRS）本体，以支持急性护理环境中的知识表示。材料和方法：我们使用Web本体语言（OWL）语义和Protege来组织临床概念和关系，开发了NIRS本体。为了使基于规则的临床推理超越层次结构，我们添加了语义网规则语言（SWRL）规则。通过添加17个假设患者的临床场景来评估逻辑推理。我们使用SPARQL查询和电子重症监护单元（eICU）协作研究数据库中的数据来检索和测试目标推理。结果：该本体包含132个类、12个对象属性和17个数据属性，共有882个公理建立了概念关系。为了标准化临床概念，我们添加了350个注释，包括基于受控词汇的描述性定义。SPARQL查询成功验证了所有测试案例（规则），通过检索适当的患者结果，例如，由于急性呼吸衰竭而接受2小时高流量鼻导管（HFNC）治疗的患者可能避免气管插管。讨论：NIRS本体正式表示了特定领域的概念，包括通气方式、患者特征、治疗参数和结果。对临床场景的SPARQL查询评估证实了本体支持基于规则的推理和治疗建议的能力，为一致的记录实践、临床数据模型的集成和NIRS结果的深入分析提供了基础。结论：我们将NIRS概念统一到本体框架中，并通过评估假设患者场景和与标准化词汇的协调来证明其适用性。,法恩彻·伊斯拉姆先生,2025/7/26,2025/7/26,,,"['q-bio.OT', 'cs.AI']"
2507.22933v1,增强视觉-语言模型：系统综述,http://arxiv.org/abs/2507.22933v1,视觉语言机器学习模型在最近取得的进展展示了其利用自然语言理解和视觉场景的非凡能力，这得益于在大规模非结构化数据集上的训练。然而，这种训练模式无法产生其输出的可解释性解释，需要重新训练以整合新信息，资源消耗巨大，并且在某些形式的逻辑推理方面存在困难。一种有前景的解决方案是将神经网络与外部符号信息系统相结合，形成能够增强推理和记忆能力的神经符号系统。这些神经符号系统为其输出提供了更多可解释的解释，并能够在不进行大规模重新训练的情况下吸收新信息。利用强大的预训练视觉语言模型（VLMs）作为核心神经网络组件，并辅以外部系统，提供了一种实现神经符号集成优势的实用方法。本系统文献综述旨在分类通过与其他外部符号信息系统交互来改善视觉语言理解的技术。,安东尼·C·戴维斯,2025/7/24,2025/7/24,,,"['cs.CL', 'cs.AI']"
2507.17512v1,一个域名能帮助其他域名吗？基于强化学习在多域名推理中的数据驱动研究,http://arxiv.org/abs/2507.17512v1,可验证奖励强化学习（RLVR）已成为提升大型语言模型（LLM）推理能力的一种强大范式。现有研究主要集中在诸如数学问题解决、编码任务或逻辑推理等孤立的推理领域。然而，现实世界的推理场景本质上需要多种认知技能的综合应用。尽管如此，在强化学习中这些推理技能之间的相互作用仍然理解不足。为了弥合这一差距，我们系统地调查了RLVR框架内的多领域推理，明确关注三个主要领域：数学推理、代码生成和逻辑谜题解决。我们进行了一项包含四个关键组成部分的全面研究：（1）利用GRPO算法和Qwen-2.5-7B模型系列，我们的研究全面评估了在单领域数据集上训练的模型在领域内改进和跨领域泛化能力。（2）此外，我们还考察了在跨领域训练中出现的复杂交互，包括相互增强和冲突。（3）为了进一步了解强化学习（RL）的影响，我们还分析了在相同的RL配置下，基于基础模型和指令模型的性能差异。（4）此外，我们深入探讨了关键的RL训练细节，系统地探索了课程学习策略、奖励设计变化和语言特定因素的影响。通过大量实验，我们的结果为支配领域交互动态提供了重要的见解，揭示了影响专业化和可泛化推理性能的关键因素。这些发现为优化RL方法以培养LLM的全面、多领域推理能力提供了宝贵的指导。,余丽,2025/7/23,2025/7/23,,,"['cs.AI', 'cs.LG']"
2507.07498v2,《教学大型语言模型进行推理：无需代码的算法问题强化学习》,http://arxiv.org/abs/2507.07498v2,提升推理能力一直是LLM（大型语言模型）研究社区的核心关注点。一个有前景的方向是要求模型逐步模拟代码执行过程，以对给定的输入推导出输出。然而，由于代码通常是为大型系统设计的，直接应用会导致过度依赖复杂的数据结构和算法，即使是简单的情况也会如此，从而导致过度拟合算法模式而非核心推理结构。为了解决这个问题，我们提出了TeaR，旨在教会LLM更好地进行推理。TeaR利用精心整理的数据和强化学习来引导模型通过代码相关任务发现最优推理路径，从而提高一般推理能力。我们使用两种基础模型和三种长CoT蒸馏模型进行了广泛的实验，模型规模从15亿到320亿参数不等，并在涵盖数学、知识、代码和逻辑推理的17个基准测试中进行了测试。结果显示，性能显著提升。值得注意的是，TeaR在Qwen2.5-7B上实现了35.9%的改进，在R1-Distilled-7B上实现了5.9%的改进。,鲍克勤,2025/7/10,2025/7/14,,,"['cs.CL', 'cs.LG']"
2508.00004v1,在“警察与小偷”游戏中的不确定性推理,http://arxiv.org/abs/2508.00004v1,警察与小偷游戏是研究追捕逃逸环境中计算查询的重要模型之一。正如最近的逻辑探索所显示的，它的结构展现出与模态逻辑吸引人的类比。在这篇论文中，我们为游戏增加了一个设定，其中玩家可能拥有不完整的信息。我们提出了一个新的形式框架，即警察与小偷的知识逻辑（ELCR），以使游戏的核心概念更加精确，例如玩家的位置、观察力和推理。将ELCR应用于分析游戏，我们获得了一种自动跟踪玩家互动和描述他们在游戏过程中信息更新的方法。更新机制由一个新颖的动态运算符定义，并且我们从游戏和逻辑的角度将其与一些相关范例进行了比较。我们研究了ELCR的多种属性，包括公理化和解决能力。据我们所知，这是首次尝试从形式角度探索这些游戏，其中考虑了玩家可获得的（部分）信息。,李大柱,2025/7/9,2025/7/9,,,"['cs.LO', 'math.LO']"
2507.04770v1,FurniMAS：基于多智能体系统的语言引导家具装饰,http://arxiv.org/abs/2507.04770v1,家具装饰在众多工业应用中是一项重要的任务。然而，实现高质量的装饰效果往往耗时且需要专业的艺术技能。为了应对这些挑战，我们探讨如何利用多智能体系统来辅助自动化装饰过程。我们提出了FurniMAS，一个用于自动家具装饰的多智能体系统。具体来说，给定一个人类提示和一种家庭家具，比如办公桌或电视柜，我们的系统会推荐相关资产，包括合适的风格和材料，并将它们安排在物品上，确保装饰效果符合功能性、审美和氛围偏好。FurniMAS组建了一个基于LLM和非LLM代理的混合团队，在典型的装饰项目中各自扮演不同的角色。这些代理通过沟通、逻辑推理和验证来将需求转化为最终成果。大量的实验表明，我们的FurniMAS在生成高质量的3D装饰方面显著优于其他基线。,Toan Nguyen 翻译成中文是：阮东海,2025/7/7,2025/7/7,,,"['cs.AI', 'cs.CV']"
2507.02170v1,在多智能体大型语言模型系统中协同逻辑推理、知识管理和协作,http://arxiv.org/abs/2507.02170v1,本文探讨了将先进的多人代理系统（MAS）技术集成，以开发具备增强逻辑推理能力、长期知识保持能力和心智理论（ToM）能力的代理团队。通过将这些核心组件与优化的通信协议相结合，我们创造了一个名为SynergyMAS的新框架，该框架促进了协作团队工作和卓越的问题解决技能。通过一个产品开发团队案例研究，展示了该系统的有效性，我们的方法显著提高了性能和适应性。这些发现突出了SynergyMAS解决复杂、现实世界挑战的潜力。,亚当·科斯卡,2025/7/2,2025/7/2,,,['cs.MA']
2506.22434v1,MiCo：多图像对比用于强化视觉推理,http://arxiv.org/abs/2506.22434v1,这项研究探索了实现思维链（CoT）推理以连接多张图像中的视觉线索。一个直接的方法是采用基于规则的强化学习来适应视觉-语言模型（VLMs）。然而，这些方法通常依赖于人工整理的问题-答案对，在处理图像中的精细视觉细节和复杂逻辑时尤其具有挑战性。受到自监督视觉表征学习灵感的启发，我们观察到图像中存在内在约束，这些约束可以充当监督。基于这一洞察，我们构建了包含同一图像的两个增强视图和第三张相似但不同的图像的三重图像。在训练过程中，模型被提示生成一个推理过程来比较这些图像（即确定相同或不同）。然后我们用基于规则的强化学习来优化模型。由于视觉相似度很高，且存在增强，模型必须关注细微的视觉变化并执行逻辑推理才能成功。实验表明，虽然仅在视觉比较任务上训练，但所学习的推理能力在广泛的问答任务上表现出了有效的泛化能力。无需依赖于任何人工标注的问题-答案对，我们的方法在多图像推理基准测试上取得了显著的改进，并在一般视觉任务上表现出强大的性能。,Xi Chen 可以翻译为“奚辰”，这是一个人名。如果需要翻译成其他形式，例如在介绍或标题中，可以翻译为“奚先生”或“陈奚”。具体翻译还需根据上下文来确定。,2025/6/27,2025/6/27,,,['cs.CV']
2506.21656v1,细粒度偏好优化提升视觉语言模型中的空间推理能力,http://arxiv.org/abs/2506.21656v1,当前视觉-语言模型（VLMs）在细粒度空间推理方面存在困难，尤其是在需要多步逻辑和精确空间对齐的情况下。在这项工作中，我们介绍了SpatialReasoner-R1，这是一个旨在解决这些局限性的视觉-语言推理模型。为了构建高质量的空间推理监督，我们设计了一种多模型蒙特卡洛树搜索（M3CTS）方法，该方法生成多样、逻辑一致的长期思维（LongCoT）推理轨迹。此外，我们提出了细粒度直接偏好优化（fDPO），它引入了针对描述性基础和逻辑推理的段特定偏好粒度，由一个空间奖励机制引导，该机制根据视觉一致性、空间基础和逻辑一致性评估候选响应。实验结果表明，fDPO在空间质量任务上比标准DPO平均提高了4.1%，在空间数量任务上提高了9.0%。使用fDPO训练的SpatialReasoner-R1在SPATIALRGPT-Bench上设定了新的SOTA（最先进的技术水平），平均准确率比最强的基线提高了9.8%，同时在一般视觉-语言任务上保持了有竞争力的表现。,沈一帆,2025/6/26,2025/6/26,,,"['cs.CV', 'cs.CL']"
2506.18383v1,逻辑PO：利用LLMs和偏好优化高效地将基于自然语言的逻辑问题翻译为一阶逻辑（FOL）,http://arxiv.org/abs/2506.18383v1,逻辑推理是人工智能的关键任务，因为它在诸如问答、摘要等主要下游任务中扮演着重要角色。近年来，提高大型语言模型推理能力的方法在将自然语言推理问题正确转换为等价的逻辑表达形式方面存在不足，这阻碍了框架整体推理能力的发展。为此，我们提出利用偏好优化数据集进行微调，以学习将自然语言问题整体解析和表示为一致的逻辑程序。具体做法包括：1）引入新的监督和偏好优化数据集LogicPO；2）采用直接偏好优化（DPO）、卡尼曼-特沃斯基优化（KTO）等流行技术来微调开源大型语言模型。我们的最佳模型Phi-3.5在逻辑正确性和减少语法错误方面，均优于GPT-3.5-turbo（8次提示），分别高出10%和14%。通过该框架和改进的评估指标，我们为通过更好地表示逻辑表达形式来提升大型语言模型的逻辑推理能力提供了有前景的方向。,库什克·维什瓦纳达,2025/6/23,2025/6/23,,,"['cs.LG', 'cs.AI']"
2506.14373v2,离散JEPA：不进行重建学习离散标记表示,http://arxiv.org/abs/2506.14373v2,认知智能的基石在于从观察中提取隐藏的模式，并利用这些原则系统地预测未来的结果。然而，当前图像分词方法在需要符号抽象和逻辑推理能力以进行系统推理的任务中显示出显著的局限性。为了应对这一挑战，我们提出了离散-JEPA，它通过语义分词和新的辅助目标扩展了潜在预测编码框架，以创建适用于符号推理任务的鲁棒分词。离散-JEPA在视觉符号预测任务上显著优于基线模型，而引人注目的视觉证据揭示了在学习语义分词空间内自发出现的深思熟虑的系统模式。尽管这是一个初始模型，但我们的方法有望对推进人工智能系统中的符号世界建模和规划能力产生重大影响。,白俊燮,2025/6/17,2025/6/22,,,['cs.CV']
2506.17294v1,AI生成游戏解说：调查与数据表库,http://arxiv.org/abs/2506.17294v1,人工智能生成游戏解说（AIGGC）因其市场潜力和固有的技术挑战而受到越来越多的关注。作为一个全面的跨模态自然语言处理（NLP）任务，AIGGC对语言模型提出了巨大的要求，包括事实准确性、逻辑推理、表达性文本生成、生成速度和上下文管理。在这篇论文中，我们介绍了一个通用的AIGGC框架，并根据它们在这个领域旨在解决的关键挑战，对45个现有的游戏解说数据集和方法进行了全面的调查。我们进一步对这些领域常用的各种评估指标进行了分类和比较。为了支持未来的研究和基准测试，我们还提供了一个结构化的数据表，总结了这些数据集的基本属性，并将其作为附录提供，同时这些数据也在一个公开的存储库中可供访问。,郑琪瑞,2025/6/17,2025/6/17,,,"['cs.CL', 'cs.AI', 'cs.LG']"
2506.13331v1,认知推理者的混合：类似大脑的模块化专业化推理,http://arxiv.org/abs/2506.13331v1,人类智能源于专门的大脑网络之间的交互作用，每个网络都致力于不同的认知功能，如语言处理、逻辑推理、社会理解和记忆检索。受这一生物观察的启发，我们引入了混合认知推理器（MiCRo）架构和训练范式：一个模块化的基于变换器的语言模型，其训练课程鼓励不同模块之间功能专业化的出现。受神经科学研究的启发，我们将预训练的变换器模型的层划分为四个专家模块，每个模块对应一个研究得很好的认知大脑网络。我们的类脑模型相较于现有技术有三个关键优势：首先，这些专门的专家高度可解释且功能关键，移除一个模块会显著损害在领域相关基准上的性能。其次，我们的模型在七个推理基准上优于缺乏专业化的基线模型。第三，在推理时可以通过选择性地强调某些专家模块（例如，优先考虑社会推理而非逻辑推理）来引导模型的行为，从而实现对模型回答风格的精细控制。我们的发现表明，涉及人类认知的生物启发性归纳偏差在可解释性、性能和控制力方面带来了显著的建模收益。,巴德尔·阿尔卡米西（Badr AlKhamissi）,2025/6/16,2025/6/16,,,['cs.LG']
2506.12849v1,CAPO：强化医疗决策中的一致性推理,http://arxiv.org/abs/2506.12849v1,在医学视觉问答（Med-VQA）中，实现准确的回答依赖于三个关键步骤：对医学影像数据的精确感知、基于视觉输入和文本问题的逻辑推理，以及从推理过程中得出的连贯答案推导。最近在通用视觉语言模型（VLMs）方面的进展表明，大规模强化学习（RL）可以显著提高推理能力和整体模型性能。然而，它们在医学领域的应用受到两个基本挑战的阻碍：1）感知理解和推理阶段之间的不匹配，以及2）推理路径和答案生成之间的不一致，这两者都受到高质量医学数据集稀缺的限制，这对于有效的大规模RL至关重要。在本文中，我们首先介绍了Med-Zero-17K，这是一个用于纯RL训练的精确数据集，包含超过30种医学影像模态和24个临床任务。此外，我们提出了一种新颖的大规模RL框架，用于Med-VLMs，即一致性感知偏好优化（CAPO），它通过整合奖励来确保感知和推理之间的忠实度、推理到答案推导的一致性，以及最终答案的基于规则的准确性。在域内和域外场景上的大量实验表明，我们的方法在强大的VLM基线之上具有优越性，展示了强大的泛化能力，能够应用于3D Med-VQA基准和R1-like训练范式。,江松涛,2025/6/15,2025/6/15,,,['cs.CV']
2506.10209v1,TTT-Bench：一个用于评估简单和新颖井字棋风格游戏推理能力的基准测试,http://arxiv.org/abs/2506.10209v1,大型推理模型（LRMs）在包括奥林匹克级别的数学问题在内的广泛任务中展现了惊人的推理能力，这表明了它们复杂的推理能力。尽管许多推理基准集中于STEM领域，但LRMs在更广泛的任务领域中正确推理的能力仍未得到充分探索。在这项工作中，我们引入了\textbf{TTT-Bench}这一新的基准，它通过一套四款两人对弈的井字棋风格游戏来评估LRMs的基本战略、空间和逻辑推理能力，这些游戏是人类从小就能轻松解决的。我们提出了一种简单且可扩展的程序化方法来生成TTT-Bench的可验证两人游戏问题。虽然这些游戏对人类来说微不足道，但要确保胜利，就需要对对手的意图以及游戏板的空间配置进行推理。我们评估了一系列最先进的LRMs，并\textbf{发现那些在难题上表现优异的模型在这些简单的推理游戏中往往失败}。进一步的测试表明，与MATH 500和AIME 2024相比，我们评估的推理模型在TTT-Bench上的平均得分分别下降了41%和5%，其中较大的模型使用较短的推理轨迹实现了更高的性能，而在简单和新的TTT-Bench任务中，大多数模型在长期战略推理方面都显得力不从心。,帕卡米亚·米什拉,2025/6/11,2025/6/11,,,"['cs.CL', 'cs.AI']"
2506.11128v1,更强大的语言模型会产生更接近人类错误的错误。,http://arxiv.org/abs/2506.11128v1,随着语言模型不断改进，它们是否趋向于人类相似的推理模式？我们提供了令人惊讶的证据：尽管整体推理能力随着模型复杂性的增加而提高，但错误本质上的确越来越接近可预测的人类推理谬误：一种以前未曾观察到的反比例现象。为了研究这个问题，我们应用了推理的论题理论（Erotetic Theory of Reasoning，ETR），这是一个经过实证支持的正式认知框架，能够预测人类推理结果。使用开源包PyETR，我们生成了人类容易出错的逻辑推理问题，评估了38个语言模型在383个推理任务中的回答。我们的分析表明，随着模型在一般能力上的提升（以聊天机器人竞技场分数衡量），它们错误回答中符合ETR预测的人类谬误的比例趋于增加（$\rho = 0.360，p = 0.0265$）。值得注意的是，由于我们没有在这些任务中观察到模型复杂性与逻辑正确性之间的相关性，这种错误模式向人类相似性的转变是独立于错误率发生的。这些发现挑战了语言模型按比例扩大就能自然获得规范性理性的主流观点，反而表明模型趋向于人类相似的认知，包括我们特有的偏见和局限性，这一点我们通过展示语言模型推理中的顺序效应进一步得到证实。,安德鲁·基南·理查森,2025/6/10,2025/6/10,,,"['cs.CL', 'cs.AI']"
2506.07288v3,EVINET：通过证据推理网络实现开放世界图学习,http://arxiv.org/abs/2506.07288v3,图学习对于许多现实世界的任务至关重要，但它们通常是在一个封闭世界的假设下被研究的，即所有可能的数据标签都是事先已知的。为了在开放和嘈杂的环境中有效地进行图学习，当模型对已知类别的分布内数据进行错误预测时，即误分类检测，或者当模型遇到来自新颖类别的分布外数据时，即分布外检测，向模型用户告知模型的错误预测是至关重要的。本文介绍了证据推理网络（EVINET），这是一个通过在主观逻辑框架内整合Beta嵌入来应对这两个挑战的框架。EVINET包括两个关键模块：用于误分类检测的失调推理和用于分布外检测的空白推理。大量的实验表明，在分布内分类、误分类检测和分布外检测的任务中，EVINET在多个指标上优于最先进的方法。EVINET证明了不确定性估计和逻辑推理对于误分类检测和分布外检测的必要性，并为开放世界的图学习铺平了道路。我们的代码和数据可在https://github.com/SSSKJ/EviNET上获取。,关威杰,2025/6/8,2025/8/1,,,['cs.LG']
2506.06881v1,KnowCoder-V2：深度知识分析,http://arxiv.org/abs/2506.06881v1,深度知识分析任务通常涉及从大量数据中系统地提取和关联知识，随后通过逻辑推理来发现洞察。然而，为了解决这样的复杂任务，现有的深度研究框架面临着三个主要挑战：1）缺乏知识的系统组织和管理；2）纯在线操作，这使得依赖共享和大规模知识的任务效率低下；3）无法执行复杂的知识计算，限制了其生成有洞察力的分析结果的能力。受到这些挑战的启发，在本文中，我们提出了一种知识增强深度研究（KDR）框架，它赋予了深度研究以深度知识分析能力。具体来说，它引入了一个独立的知识组织阶段，将大规模、领域相关的数据预处理为离线系统化的知识。在此基础上，它扩展了深度研究，增加了一种额外的推理步骤，以在线方式执行复杂的知识计算。为了提高LLM在上述框架中解决知识分析任务的能力，我们进一步引入了知识计算与推理接口（KCII），一个通过统一代码生成桥接知识组织和推理的LLM。对于知识组织，它为预定义的类生成实例代码，将数据转换为知识对象。对于知识计算，它生成分析代码并在上述知识对象上执行，以获得深度分析结果。在六个知识分析任务上超过三十个数据集的实验结果表明了KCII的有效性。此外，当整合到KDR框架中时，与主流深度研究框架相比，KCII能够生成高质量的报告，其中包含有洞察力的分析结果。,李子萱,2025/6/7,2025/6/7,,,['cs.AI']
2506.03984v1,环游世界24小时：探究大型语言模型对时间和地点的认知,http://arxiv.org/abs/2506.03984v1,在时间和空间维度上进行推理对于理解我们的世界至关重要。然而，在此领域，语言模型的能力在很大程度上尚未被探索，因为以往的工作主要测试了它们在孤立或简单或人工环境中的逻辑推理能力。在这篇论文中，我们提出了对语言模型联合进行时间和空间推理能力的首次评估。为了使我们的分析成为可能，我们创建了GeoTemp数据集，该数据集包含320k个提示，涵盖217个国家的289个城市和37个时区。使用GeoTemp，我们评估了八个不同模型家族的八种开放聊天模型，以评估不同时间和地理知识的组合。我们发现，大多数模型在仅涉及时间知识的推理任务上表现良好，而且整体性能随着规模的增加而提高。然而，在需要连接时间和地理信息的工作中，性能仍然受限。我们没有发现与特定地理区域明显相关的性能。相反，我们发现对于模型困惑度低的地点名称，性能有显著提升，这表明它们在模型训练期间反复出现。我们进一步证明，它们的性能受提示制定的影响很大——直接注入地理知识可以提升性能，而令人惊讶的是，像思维链提示这样的技术却在简单的任务中降低了性能。,"Carolin Holtermann

卡罗琳·霍尔特曼",2025/6/4,2025/6/4,,,['cs.CL']
2506.03771v1,《迈向蕴涵检查：探索特征标记搜索》,http://arxiv.org/abs/2506.03771v1,逻辑蕴涵对于推理至关重要，但蕴涵检查的最坏情况复杂度是变量大小的指数级。随着最近的发展，当量子计算成熟时，可能会为各种组合问题提供有效的方法，包括蕴涵检查。Grover算法通过Grover操作、选择性相位反转和振幅放大来处理对非结构化数据的搜索，其效率比经典方法提高了平方级。其原始形式旨在解决单胜者场景：保证恰好有一个匹配。将其扩展到多胜者场景时，通过概率控制Grover操作的应用次数，而未胜者情况则通过超时处理。我们的研究探索了“特征标记”方法的多种方案。虽然仍然依赖于Grover操作，但这种方法引入了额外的量子比特来标记特征状态。标记的特征状态有助于解释测量结果，并增强对未胜者情况的识别（与蕴涵语境中的无逻辑违规相关）。我们的研究在IBM Aer模拟器上对双量子比特系统进行了三种特征标记变体的实验。结果显示，所有方案都具有很强的可区分性，在最坏情况下最佳相对可区分性为19，在平均情况下为53。我们的发现揭示了一种可行的量子机制，可以区分未胜者情况与其他场景，这可能在蕴涵检查和一般逻辑推理中发挥关键作用。,塔通·卡塔纽库尔,2025/6/4,2025/6/4,,,"['quant-ph', 'cs.ET', 'cs.LO']"
2506.03295v2,通过在一个问题上进行批判性微调，释放预训练大型语言模型（LLMs）的推理潜能,http://arxiv.org/abs/2506.03295v2,我们目睹了像Qwen-Math、MiMo和Phi-4这样的强大型语言模型（LLM）在预训练阶段就具备了巨大的推理潜力。通过强化学习（RL），这些模型在推理任务上的表现可以大幅提升。近期的研究表明，即使是针对单个问题的RL也能充分释放这些模型的推理能力。然而，RL不仅成本高昂，而且不够稳定。即使是单次RL也需要数百个GPU小时。这引发了一个关键问题：是否有更有效的方式来释放这些强大基LLM的推理潜力？在本工作中，我们展示了通过针对单个问题进行的批判性微调（CFT）可以有效释放LLM的推理潜力。我们的方法通过收集针对单个问题产生的多种模型解决方案，并使用教师LLM提供详细的批判来构建批判数据。我们在CFT数据上对从1.5B到14B参数的Qwen和Llama家族模型进行了微调，并观察到在多样化的推理任务上性能显著提升。例如，仅用5个GPU小时的训练时间，Qwen-Math-7B-CFT在六个数学基准测试上平均提高了15%，在三个逻辑推理基准测试上提高了16%。这些结果与RL的效果相当，甚至更好，而所需的计算量只是RL的1/20。消融研究揭示了单次CFT在针对不同提示问题的鲁棒性。这些结果突出了单次CFT作为一种简单、通用且计算高效的释放现代LLM推理能力的方法。,王宇博,2025/6/3,2025/6/5,,,"['cs.CL', 'cs.LG']"
2506.02690v1,面向大型模型时代的几何问题求解：综述,http://arxiv.org/abs/2506.02690v1,几何问题求解（GPS）是人工智能中的一个关键前沿领域，在教育、计算机辅助设计和计算图形学等领域有着深远的应用。尽管其意义重大，但由于对空间理解和严谨逻辑推理的双重需求，自动化GPS仍然具有挑战性。近年来，大型模型的发展使得在SAT级问题上有显著的突破，但该领域在方法、基准和评估框架上仍然存在碎片化。这篇综述系统地总结了GPS的进展，通过三个核心维度：1）基准构建；2）文本和图表解析；3）推理范式。我们进一步提出了一种统一的分析范式，评估了当前的局限性，并确定了未来研究的新机遇，以指导向人类水平几何推理迈进，包括自动基准生成和可解释的神经符号集成。,赵雨瑞,2025/6/3,2025/6/3,,,"['cs.CV', 'math.GT']"
2505.23977v1,视觉斯芬克斯：用于强化学习的大规模合成视觉逻辑谜题,http://arxiv.org/abs/2505.23977v1,视觉语言模型（VLMs）预计能够进行有效的多模态推理并做出逻辑上连贯的决策，这对于诸如图表理解和空间问题解决等任务至关重要。然而，当前VLM的推理缺乏大规模和结构良好的训练数据集。为了填补这一空白，我们提出了VisualSphinx，这是一种前所未有的大规模合成视觉逻辑推理训练数据。为了应对具有接地答案的图像合成的挑战，我们提出了一种从规则到图像的合成流程，该流程从种子问题中提取和扩展拼图规则，并为拼图样本组装生成接地合成图像合成的代码。实验表明，在VisualSphinx上使用GRPO训练的VLM得益于我们数据集的逻辑一致性和可读性，并在逻辑推理任务上表现出改进的性能。从VisualSphinx开发出的增强推理能力也惠及其他推理任务，如代数推理、算术推理和几何推理。,冯一尘,2025/5/29,2025/5/29,,,"['cs.CV', 'cs.AI', 'cs.LG']"
2505.23648v1,持续的思维链能够实现并行探索和推理。,http://arxiv.org/abs/2505.23648v1,当前的语言模型通过自回归地从一个有限词汇表中采样标记来生成思维链迹。虽然这种离散采样已经取得了显著的成功，但使用连续值的标记（CoT2）进行思维链提供了更丰富、更具有表现力的替代方案。我们的工作通过需要内在搜索能力的逻辑推理任务来考察CoT2的优点，并为CoT2提供优化和探索方法。理论上，我们表明CoT2允许模型并行跟踪多个轨迹，并量化其在推理效率方面的好处。值得注意的是，一个配备CoT2的一层Transformer可以在足够的嵌入维度下，证明性地解决组合“子集和问题”。这些见解导致了一种新颖而有效的监督策略，其中我们将softmax输出与一组目标轨迹的实证标记分布相匹配。补充这一策略，我们引入了采样策略，以解锁CoT2的政策优化和自我改进。我们的第一种策略在每一步解码时采样和组合$K$个离散标记，以控制并行程度，当$K=1$时，它简化为标准的CoT。我们的第二种策略依赖于在概率单纯形上的连续探索。实验证实，带有CoT2的政策优化确实提高了模型的性能，超过了其初始的离散或连续监督。,哈利勒·阿尔彭·戈泽滕,2025/5/29,2025/5/29,,,['cs.LG']
2505.21398v1,小学阶段基础人工智能素养的“结构化脱插”教学法,http://arxiv.org/abs/2505.21398v1,年轻一代在一个日益由智能技术塑造的世界中成长起来，因此，在早期培养对人工智能的识读能力对于掌握批判性地理解和导航这些技术所必需的技能至关重要。然而，在这个领域的教育往往强调基于工具的学习，优先考虑使用而非理解其背后的概念。这种知识的缺乏使非专业人士，尤其是儿童，容易产生误解、不切实际的期望，以及在识别偏见和刻板印象方面遇到困难。在这篇论文中，我们提出了一种结构化和可复制的教学方法，通过利用与小学课程紧密相关且引人入胜的核心数学元素，来培养小学生的基础人工智能识读能力，以加强概念化、数据表示、分类推理和人工智能的评价。为了评估我们方法的有效性，我们进行了一项实证研究，涉及两个班级的31名五年级学生，通过后测和满意度调查评估他们的进步。我们的结果表明，学生在术语理解和运用、特征描述、逻辑推理和评估技能方面有所提高，他们对决策过程及其局限性的理解也更加深入。此外，这种方法证明了其吸引力，学生们尤其喜欢将人工智能概念与现实世界推理联系起来的活动。材料链接：https://github.com/tail-unica/ai-literacy-primary-ed。,玛丽亚·克里斯蒂娜·卡利斯奇,2025/5/27,2025/5/27,,,"['cs.AI', 'cs.ET']"
2505.19797v3,《复仇者联盟》：将小型语言模型联合起来挑战专有巨头的简单配方,http://arxiv.org/abs/2505.19797v3,专有巨头正在越来越大地主导着对更大语言模型的竞争。开源的小型模型能否在广泛的任务中保持竞争力？在这篇论文中，我们提出了“复仇者”——一个利用这些小型模型集体智慧的简单方法。复仇者基于四个轻量级操作：（一）嵌入：使用文本嵌入模型编码查询；（二）聚类：根据查询的语义相似性进行分组；（三）评分：在每个聚类中对每个模型的性能进行评分；（四）投票：通过重复采样和投票来改进输出。在推理时，每个查询都被嵌入并分配到其最近的聚类。在该聚类中表现最好的模型被选中，通过重复采样生成响应。令人瞩目地，使用10个开源模型（每个模型约7亿参数），复仇者在涵盖数学、编码、逻辑推理、常识和情感任务等15个不同数据集的平均性能上超过了GPT-4o、4.1和4.5。特别是，它在数学任务上比GPT-4.1高出18.21%，在编码任务上高出7.46%。此外，复仇者展现了出色的泛化能力，并且在其唯一的参数——聚类数量——的各个值下，在各种嵌入模型、聚类算法、集成策略中都保持了鲁棒性。,张一群,2025/5/26,2025/6/18,,,['cs.CL']
2505.15817v2,通过混合思维进行逻辑推理的学习,http://arxiv.org/abs/2505.15817v2,人类天生会利用多种推理方式来学习和解决逻辑问题，即不同的表示格式，如自然语言、代码和符号逻辑。相比之下，大多数现有的基于大型语言模型（LLM）的方法在训练过程中通常只使用单一的推理方式，通常是自然语言。尽管一些方法在推理时探索了模态选择或增强，但训练过程仍然是模态盲的，限制了模态之间的协同作用。为了填补这一空白，我们提出了“混合思维”（MoT）框架，它使LLM能够跨越三种互补的模态进行推理：自然语言、代码以及一种新引入的符号模态——真值表，它系统地列举逻辑情况并部分缓解了自然语言推理中的关键失败模式。MoT采用两阶段设计：（1）自进化的MoT训练，它从不同模态的过滤和自我生成的理由中联合学习；（2）MoT推理，它充分利用三种模态的协同作用，产生更好的预测。在FOLIO和ProofWriter等逻辑推理基准测试上的实验表明，我们的MoT框架在一致性上显著优于具有单一模态思维链方法的强大LLM基线，平均准确率提升高达+11.7pp。进一步的分析表明，我们的MoT框架对训练和推理阶段都有益；它在更困难的逻辑推理问题上的效果尤其显著；不同的模态贡献了互补的优势，其中真值表推理有助于克服自然语言推理中的关键瓶颈。,通正,2025/5/21,2025/6/9,,,['cs.CL']
2505.12766v1,推理-OCR：大型多模态模型能否解决由OCR提示的复杂逻辑推理问题？,http://arxiv.org/abs/2505.12766v1,大型多模态模型（LMMs）在功能上变得越来越多样化，并伴随着令人印象深刻的OCR（光学字符识别）相关能力。现有的OCR相关基准主要强调评估LMMs在相对简单的视觉问答、视觉-文本解析等方面的能力。然而，LMMs基于OCR线索处理复杂逻辑推理问题的程度相对未被充分探索。为此，我们引入了Reasoning-OCR基准，它挑战LMMs基于从丰富的视觉-文本中提取的线索解决复杂推理问题。Reasoning-OCR涵盖了六个视觉场景，并包含150个精心设计的题目，这些题目被分为六个推理挑战。此外，Reasoning-OCR最小化了专业领域知识的影响。我们的评估为不同推理挑战中的专有和开源LMM提供了一些见解，强调了提高推理性能的紧迫性。我们希望Reasoning-OCR能够激发并促进基于OCR线索增强复杂推理能力的研究。Reasoning-OCR在https://github.com/Hxyz-123/ReasoningOCR上公开可用。,海斌河,2025/5/19,2025/5/19,,,['cs.CV']
2505.12307v1,LogicOCR：您的多模态大模型在处理富含文本的图像上的逻辑推理能力如何？,http://arxiv.org/abs/2505.12307v1,最近在大型多模态模型（LMMs）方面的进展显著提高了它们的推理和光学字符识别（OCR）能力。然而，它们在涉及丰富文本图像的复杂逻辑推理任务上的表现仍然未被充分探索。为了填补这一空白，我们引入了LogicOCR，这是一个包含1100道多选题的基准，旨在评估LMMs在文本丰富图像上的逻辑推理能力，同时最大限度地减少对特定领域知识的依赖（例如数学）。我们通过从中国国家公务员考试中精选文本语料库并开发一个可扩展的、自动化的流水线来构建LogicOCR，将文本语料库转换为多模态样本。首先，我们设计提示模板，引导GPT-Image-1生成具有多样化背景、交错文本-插图布局和不同字体的图像，确保语境相关性和视觉真实性。然后，生成的图像被人工验证，低质量的示例被淘汰。我们在思维链（CoT）和直接回答两种设置下评估了一系列代表性的开源和专有LMMs。我们的多维分析揭示了关键见解，例如测试时缩放的影响、输入模态差异以及对视觉-文本方向敏感性的影响。值得注意的是，与仅文本输入相比，LMMs在多模态推理方面仍然落后，这表明它们还没有完全弥合视觉阅读与推理之间的差距。我们希望LogicOCR将成为推动多模态推理研究的有价值资源。数据集可在https://github.com/MiliLab/LogicOCR上获取。,毛源益,2025/5/18,2025/5/18,,,"['cs.CV', 'cs.CL']"
2505.12284v1,通过长度感知优化实现推理模型的效率强化学习训练,http://arxiv.org/abs/2505.12284v1,大型推理模型，如OpenAI o1或DeepSeek R1，在推理任务上展现出非凡的表现，但通常需要漫长的推理路径，这带来了显著的内存和时间开销。现有的方法主要通过引入额外的训练数据和阶段来缩短推理路径。在本文中，我们提出了三个关键性的奖励设计，这些设计直接整合到大型推理模型的强化学习过程中，能够在不增加额外训练阶段的情况下缩短响应长度。在四个设置上的实验表明，我们的方法显著缩短了响应长度，同时保持了甚至提升了性能。具体来说，在逻辑推理设置中，我们实现了平均每步响应长度降低40%，性能提升了14%。对于数学问题，我们平均每步响应长度降低了33%，同时保持了性能。,袁丹龙,2025/5/18,2025/5/18,,,"['cs.AI', 'cs.CL']"
2505.12275v1,课程归因学习,http://arxiv.org/abs/2505.12275v1,归因学习（ABL）将机器学习与逻辑推理相结合，形成一个循环：学习模型从原始输入中预测符号概念标签，然后通过归因利用领域知识对这些标签进行修正，并将其反馈用于重新训练。然而，由于归因的不确定性，训练过程往往不稳定，特别是在知识库大而复杂时，这会导致一个难以承受的归因空间。虽然先前的研究专注于改进该空间内的候选者选择，但它们通常将知识库视为一个静态的黑盒。在这项工作中，我们提出了课程归因学习（C-ABL），这是一种方法，它明确地利用知识库的内部结构来解决ABL训练挑战。C-ABL将知识库划分为一系列子库，在训练过程中逐步引入。这减少了整个训练过程中的归因空间，并使模型能够逐步、平滑地引入逻辑。在多个任务上的实验表明，C-ABL优于之前的ABL实现，显著提高了训练稳定性、收敛速度和最终精度，尤其是在复杂知识设置下。,胡文超,2025/5/18,2025/5/18,,,"['cs.LG', 'cs.AI']"
2505.13529v1,桶（BARREL）：基于边界的用于事实和可靠低秩匹配的推理,http://arxiv.org/abs/2505.13529v1,近年来，大型推理模型（LRMs）在数学和逻辑推理方面的能力展现出了令人印象深刻的进步。然而，当前的LRM很少承认无知或以“我不知道”作为回应。相反，它们往往在表现出过度自信的同时产生错误的答案，引发了对其事实可靠性的担忧。在这项工作中，我们识别出两种由过度思考导致的病理推理模式，这些模式导致了过度自信和错误的答案：临时猜测和反复思考。为了解决这些问题，我们提出了BARREL——一个促进简洁和边界感知事实推理的新框架。我们的实验表明，BARREL训练将DeepSeek-R1-Distill-Llama-8B的可靠性从39.33%提高到61.48%，同时仍然实现了与在R1生成的推理数据上微调的模型相当的性能。这些结果证明了我们的初步研究对于构建更可靠和事实性的系统2 LRMs具有启发意义。,杨峻骁,2025/5/18,2025/5/18,,,"['cs.AI', 'cs.CL', 'cs.LG']"
2505.11854v1,评估大型推理模型的逻辑推理能力,http://arxiv.org/abs/2505.11854v1,大型推理模型，通常在长链思维（longCoT）数据上通过强化学习进行后训练，在数学、编码和领域特定推理基准测试中取得了最先进的性能。然而，它们的逻辑推理能力——这是人类认知的基础，并且独立于领域知识——仍被研究不足。为了填补这一空白，我们引入了LogiEval，这是一个全面评估大型推理模型中逻辑推理能力的基准。LogiEval涵盖了多种推理类型（演绎、归纳、类比和溯因推理）以及多种任务格式（例如，逻辑序列、论证分析），这些内容来自高质量的人类考试（例如，LSAT、GMAT）。我们的实验表明，现代推理模型在四选一论证分析问题和类比推理方面表现出色，超越了人类的表现，但在不同推理类型和格式上的能力参差不齐，凸显了它们泛化能力的局限性。我们的分析显示，人类的表现并不与模型失败分布相匹配。为了促进进一步的研究，我们精心制作了LogiEval-Hard，这是一个通过新颖的筛选范式确定的具有挑战性的子集，其中小型模型失败（Qwen3-30B-A3B）可靠地预测了大型模型的困难。现代模型在LogiEval-Hard上的失败非常明显且一致。这表明基本的推理瓶颈在模型规模上仍然存在，并将LogiEval-Hard确立为诊断工具和推进大型语言模型中逻辑推理的严格测试平台。,刘汉萌,2025/5/17,2025/5/17,,,['cs.AI']
2505.09862v1,修辞XAI：通过修辞设计解释AI的好处及其应用,http://arxiv.org/abs/2505.09862v1,本文探讨了将修辞设计融入可解释人工智能（XAI）系统设计中的潜在益处。虽然XAI传统上围绕解释个别预测或整体系统行为来构建，但解释也作为一种论证形式存在，影响着用户评估系统的感知有用性、可信度和培养适当的信任。修辞设计提供了一个有用的框架来分析AI系统和用户之间解释的沟通作用，重点关注以下三个方面：（1）通过不同类型的解释传达的逻辑推理，（2）系统及其开发者展现的可信度，以及（3）在用户中引发的情感共鸣。这些修辞诉求共同帮助我们理解解释如何影响用户感知并促进AI的采用。本文综合了先前XAI工作中的设计策略，这些策略与这三个修辞诉求相一致，并突出了将修辞设计整合到XAI设计中的机遇和挑战。,刘厚江,2025/5/14,2025/5/14,,,"['cs.HC', 'cs.CY']"
2505.03668v1,随着时间的推移，学习符号持久宏操作的POMDP求解,http://arxiv.org/abs/2505.03668v1,本文提出了一种将时态逻辑推理与部分可观测马尔可夫决策过程（POMDPs）相结合的方法，以实现具有宏观动作的不确定性可解释决策。我们的方法利用基于事件演算（EC）的线性时态逻辑（LTL）片段生成持久（即恒定）的宏观动作，这些动作指导基于蒙特卡洛树搜索（MCTS）的POMDP求解器在时间范围内进行搜索，显著减少了推理时间，同时确保了稳健的性能。这些宏观动作通过归纳逻辑编程（ILP）从少量执行轨迹（信念-动作对）中学习，从而消除了手动设计启发式算法的需要，并且只需要指定POMDP转换模型。在Pocman和Rocksample基准场景中，与我们学习的宏观动作相比，时间无关的启发式算法表现出更高的表达性和泛化能力，确实提供了显著的计算效率提升。,塞莱斯提·维罗内塞,2025/5/6,2025/5/6,,,['cs.AI']
2504.21088v1,使用红外温度计进行城市生物群落温度测绘：一种探究式物理教育的调查方法,http://arxiv.org/abs/2504.21088v1,近年来，地球上极端天气事件的频率显著增加。这一现象是由人类活动引起的温室效应加剧所驱动的，导致城市环境中的温度变化，影响热舒适度和生活质量。在此背景下，本研究利用红外温度计对城市生物群落进行温度测绘，这是在第21届全国科技活动周期间提供的一项动手工作坊的一部分。这一举措涉及公立学校的学生，并基于物理教育，旨在培养科学素养。参与者参与了基于问题的学习体验，积极投入到知识构建的各个阶段。目标是检验植被存在与其对城市环境温度影响之间的关系。采用了定性和定量相结合的方法论，使人们能够识别科学素养指标，如信息排序、数据组织、逻辑推理、假设形成、论证和现象解释。对学生陈述和活动指南的分析提供了他们批判性思维发展的见解。研究结果指出，学生发展了理解物理和环境现象的基本技能，有效地将收集到的数据与科学概念联系起来，并提出了有充分支持的解释。此外，这一经历加强了科学作为动态和探究过程的认知，培养了好奇心，提高了学生的辩论能力。因此，这个工作坊被证明是促进科学素养和让参与者参与城市环境中的环境影响研究的一种有效策略。,韦尔京顿·法比西奥·多斯·桑托斯·科斯塔,2025/4/29,2025/4/29,,,['physics.ed-ph']
2504.19852v2,自然指定和验证序列算法的正式框架,http://arxiv.org/abs/2504.19852v2,当前算法形式化验证的方法面临重要局限。在规格说明方面，它们无法自然、简洁地表达算法，尤其是对于具有状态和灵活控制流的算法。在验证方面，基于Hoare逻辑的形式化证明无法反映自然证明的逻辑结构。为了应对这些挑战，我们引入了一个用于在Coq中自然指定和验证顺序算法的正式框架。我们使用状态关系算子来整合Coq的表达式类型系统与命令式语言的灵活控制流。它支持非确定性操作和可自定义的程序状态，使算法能在适当的抽象级别上被指定。在验证方面，我们为算子构建了Hoare逻辑，并提出了一种新颖的两阶段证明方法，该方法将自然逻辑推理与机械组合分离。它反映了自然证明的逻辑结构，增强了模块化和可读性。我们通过形式化深度优先搜索（DFS）算法和验证Knuuth-Morris-Pratt（KMP）算法来评估该框架。,杨成曦,2025/4/28,2025/4/30,,,['cs.PL']
2504.16117v1,上下文感知和罕见事件的解释性，以发现和形式化关键故障模式,http://arxiv.org/abs/2504.16117v1,视觉系统越来越多地被部署在关键领域，如监控、执法和交通。然而，它们对罕见或不可预见的场景的脆弱性带来了显著的安全风险。为了应对这些挑战，我们引入了基于本体的、由人类辅助的发现框架“情境意识与罕见事件解释”（CAIRO），用于检测和形式化故障案例（或称为CP - 关键现象）。设计上，CAIRO鼓励在测试和评估由误判、对抗攻击和AI黑盒模型中的幻觉引发的关键性时，引入人类参与。我们对自动驾驶系统（ADS）中目标检测模型失败的稳健分析，展示了将观察到的摄像机感知与现实世界背景之间的差距形式化的可扩展和可解释方法，这些测试案例以显式知识图（以OWL/XML格式）的形式存储，便于共享、下游分析、逻辑推理和问责制。,斯里德维·波拉瓦拉姆,2025/4/18,2025/4/18,,,"['cs.CV', 'cs.AI', 'cs.HC']"
2504.12749v1,LAD-Reasoner：小型多模态模型在逻辑异常检测方面是优秀的推理者。,http://arxiv.org/abs/2504.12749v1,最近在工业异常检测领域的进展突显了进行深度逻辑异常分析的需求，这需要识别并解释物体、计数和空间配置之间意外的关系。现有方法往往依赖于大规模的外部推理模块或复杂的流水线设计，这阻碍了实际部署和可解释性。为了解决这些局限性，我们引入了一个新的任务，即推理逻辑异常检测（RLAD），它通过结合逻辑推理扩展了传统的异常检测。我们提出了一种新的框架，LAD-Reasoner，这是一个基于Qwen2.5-VL 3B的定制小型多模态语言模型。我们的方法采用两阶段训练范式，首先使用监督微调（SFT）进行细粒度视觉理解，然后使用组相对策略优化（GRPO）来细化逻辑异常检测并强制执行连贯、易于理解的理由。关键的是，奖励信号既来自检测精度也来自输出结构的质量，从而避免了构建思维链（CoT）推理数据的需求。在MVTec LOCO AD数据集上的实验表明，尽管LAD-Reasoner的规模显著减小，但在准确性和F1分数上与Qwen2.5-VL-72B相当，并且在产生简洁和可解释的理由方面表现更出色。这种统一的设计减少了对外部大型模型和复杂管道的依赖，同时为逻辑异常检测提供了透明和可解释的见解。代码和数据将公开发布。,李巍佳,2025/4/17,2025/4/17,,,['cs.CV']
2504.11008v2,MediSee：基于推理的医学图像像素级感知,http://arxiv.org/abs/2504.11008v2,尽管在像素级医学图像感知方面取得了显著的进步，现有方法要么局限于特定任务，要么高度依赖于准确的边界框或文本标签作为输入提示。然而，对输入所需的医学知识对于普通大众来说是一个巨大的障碍，这极大地降低了这些方法的普遍性。与这些领域特定的辅助信息相比，普通用户更倾向于依赖需要逻辑推理的口头查询。在这篇论文中，我们介绍了一个新的医学视觉任务：医学推理分割与检测（MedSD），该任务旨在理解关于医学图像的隐含查询，并为目标对象生成相应的分割掩码和边界框。为了完成这个任务，我们首先介绍了一个多视角、逻辑驱动的医学推理分割与检测（MLMR-SD）数据集，其中包含大量的医学实体目标和相应的推理。此外，我们提出了MediSee，这是一个为医学推理分割与检测设计的有效基线模型。实验结果表明，提出的方法可以有效解决MedSD的隐含口语查询问题，并优于传统的医学指代分割方法。,秦月桐,2025/4/15,2025/4/23,,,"['cs.CV', 'cs.AI']"
2504.10885v1,PuzzleBench：用于大型多模态拼图求解模型的全动态评估框架,http://arxiv.org/abs/2504.10885v1,"大型多模态模型（LMMs）在广泛的多模态任务中展示了令人印象深刻的性能，在各种评估基准上实现了持续提升。然而，现有的基准通常是静态的，并且往往与预训练数据集重叠，导致固定的复杂性约束和严重的数据污染问题。同时，手动标注的数据集劳动密集、耗时，且容易受到人类偏见和不一致性的影响，导致可靠性和可重复性问题。为了解决这些问题，我们提出了一种完全动态的多模态评估框架，命名为开放式视觉拼图生成（OVPG），旨在自动生成新鲜、多样且可验证的评估数据，用于拼图解决任务。具体来说，OVPG流程包括原材料采样模块、视觉内容生成模块和拼图规则设计模块，确保每个评估实例都是原始的、高度随机化的且独特可解的，从而能够持续适应LMMs的能力发展。基于OVPG，我们构建了PuzzleBench，这是一个动态且可扩展的基准，包含11,840个VQA样本。它包含六个精心设计的拼图任务，针对LMMs的三个核心能力：视觉识别、逻辑推理和上下文理解。PuzzleBench与静态基准不同，后者很快就会过时。它通过OVPG和丰富的开放式拼图设计实现数据集的持续更新，从而能够无缝适应LMMs的能力发展。",张泽宇,2025/4/15,2025/4/15,,,"['cs.CV', 'cs.AI']"
2504.09058v1,朝着逐步构建领域知识驱动的推理优化和反思改进,http://arxiv.org/abs/2504.09058v1,最近，对思维链（CoTs）的逐步监督在需要逻辑推理的任务，如编程和数学方面取得了提升，这得益于蒙特卡洛树搜索（MCTS）。然而，它在需要特定领域专业知识和知识方面的贡献尚未得到探索。受此启发，我们识别了在当前背景下纯MCTS的几个潜在挑战，并提出了逐步领域知识驱动推理优化框架，利用MCTS算法为需要基本理解、推理和专业知识的问题开发步骤级监督。此外，我们还引入了面向反思路径的偏好优化，它从更好的视角迭代地学习对推理思想的自我反思。我们进行了广泛的实验来评估这些方法的优势。实证结果表明，这些方法在各个法律领域问题上的有效性。我们还报告了一系列有价值的发现，希望激发对特定领域LLMs和MCTS研究的热情。,刘成原,2025/4/12,2025/4/12,,,"['cs.AI', 'cs.CL']"
2504.05419v1,推理模型知道何时自己是正确的：探查隐藏状态以进行自我验证,http://arxiv.org/abs/2504.05419v1,推理模型在数学和逻辑推理等任务上取得了显著的表现，这得益于它们在推理过程中的搜索能力。然而，它们仍然存在过度思考的问题，即使在得出正确答案后，也会进行不必要的推理步骤。这引发了这样一个问题：模型能否在推理过程中评估中间答案的正确性？在这项工作中，我们研究推理模型是否通过探测模型的隐藏状态来编码关于答案正确性的信息。产生的探测可以以高精度验证中间答案，并产生高度校准的分数。此外，我们发现模型的隐藏状态编码了未来答案的正确性，使得在中间答案完全形成之前就能提前预测其正确性。然后，我们将探测用作验证器，在推理过程中决定是否在中间答案时退出推理，从而将推理标记数减少了24%，而不影响性能。这些发现证实了推理模型确实编码了正确性的概念，但尚未充分利用它，揭示了提高其效率的大量未开发潜力。,张安琪,2025/4/7,2025/4/7,,,"['cs.AI', 'cs.CL']"
2504.04702v1,通过梯度下降学习多数布尔逻辑的语言模型可证失败,http://arxiv.org/abs/2504.04702v1,基于Transformer架构的近期进步，在自然语言处理任务中带来了令人印象深刻的突破，例如GPT-4、Claude和Gemini等模型展示了达到人类水平推理能力。然而，尽管这些模型性能出色，但对其固有限制的担忧仍然存在，尤其是在学习基本逻辑函数方面。尽管复杂性理论分析表明，由于Transformer属于$\mathsf{TC}^0$类，它可以自然地表示简单的逻辑函数（例如$\mathsf{AND}$、$\mathsf{OR}$和多数门），但这些结果基于理想的参数设置，并未考虑基于梯度下降的训练方法带来的约束。在本研究中，我们探讨了在采用基于梯度的训练方法时，Transformer是否真的可以学习简单的多数函数。我们关注Transformer架构的简化变体，并考虑了$n=\mathrm{poly}(d)$和$n=\exp(\Omega(d))$数量的训练样本，其中每个样本都是一个与基本多数函数输出配对的$d$位二进制字符串。我们的分析表明，即使在进行了$\mathrm{poly}(d)$次梯度查询之后，Transformer模型的泛化误差仍然相当大，随着$d$的增大而呈指数增长。这项工作突出了训练Transformer进行最简单的逻辑推理任务时存在的根本优化挑战，并为它们的理论限制提供了新的见解。,"抱歉，""Bo Chen"" 这个词组是一个人名，通常不需要翻译，因为它是一个专有名词。但如果您希望知道这个名字的中文发音，那么可以读作“波 陈”。在中文语境中，人们可能会按照拼音来称呼这个名字。",2025/4/7,2025/4/7,,,"['cs.LG', 'cs.AI', 'cs.CC']"
2504.02826v4,想象超越像素：基准测试基于推理的视觉编辑,http://arxiv.org/abs/2504.02826v4,大型多模态模型（LMMs）在视觉理解和生成方面取得了显著进展，但它们在通用视觉编辑方面仍面临挑战，尤其是在遵循复杂指令、保持外观一致性和支持灵活的输入格式方面。为了研究这一差距，我们引入了RISEBench，这是第一个用于评估基于推理的视觉编辑（RISE）的基准。RISEBench专注于四个关键推理类别：时间推理、因果关系推理、空间推理和逻辑推理。我们对每个类别精心制作了高质量的测试案例，并提出了一个稳健的评估框架，该框架通过人类评判者和LMM作为评判者的方法，评估指令推理、外观一致性和视觉合理性。我们进行了实验，评估了九个杰出的视觉编辑模型，包括开源和专有模型。评估结果表明，当前模型在基于推理的编辑任务中面临重大挑战。即使是最强大的模型GPT-4o-Image，其准确率也只有28.8%。RISEBench有效地突出了当代编辑模型的局限性，提供了宝贵的见解，并为推理感知视觉编辑领域的未来发展方向指明了路径。我们的代码和数据已在https://github.com/PhoenixZ810/RISEBench发布。,赵祥宇,2025/4/3,2025/5/27,,,['cs.CV']
2503.23064v2,VGRP-Bench：大型视觉-语言模型的可视化网格推理谜题基准,http://arxiv.org/abs/2503.23064v2,大型视觉语言模型（LVLMs）在解决需要精确感知、规则理解和逻辑推理的谜题时存在困难。评估和提升它们在这个领域的表现至关重要，因为这反映了它们进行结构化推理的能力——这是解决现实世界问题的必备技能。然而，现有的基准测试主要评估未经额外训练或微调的预训练模型，往往缺乏对推理的专门关注，并且未能建立系统性的评估框架。为了解决这些局限性，我们介绍了VGRP-Bench，这是一个包含20个不同谜题的视觉网格推理谜题基准。VGRP-Bench涵盖了多个难度级别，并不仅对现有的聊天LVLMs（例如GPT-4o）进行了广泛实验，还针对推理LVLMs（例如Gemini-Thinking）进行了实验。我们的结果显示，即使是处于顶尖水平的LVLMs在这些谜题上也存在困难，凸显了它们在解决谜题方面的基本局限性。最重要的是，通过系统性的实验，我们识别并分析了影响LVLMs解决谜题性能的关键因素，包括线索数量、网格大小和规则复杂性。此外，我们探索了两种在训练后可以使用的监督微调（SFT）策略：基于解决方案的微调（S-SFT）和基于合成推理过程的微调（R-SFT）。尽管这两种方法都在训练过的谜题上显著提升了性能，但它们在未见过的谜题上的泛化能力有限。我们将发布VGRP-Bench，以促进对LVLMs在解决复杂、现实世界问题方面进行进一步研究。项目页面：https://yufan-ren.com/subpage/VGRP-Bench/。,任宇帆,2025/3/29,2025/4/2,,,['cs.CV']
2503.22738v1,盾牌代理：通过可验证安全策略推理进行防护代理,http://arxiv.org/abs/2503.22738v1,由基础模型驱动的自主代理在各类现实应用中得到了广泛应用。然而，它们对恶意指令和攻击依然高度脆弱，这可能导致严重后果，如隐私泄露和财务损失。更重要的是，由于代理的复杂性和动态性，现有的LLM安全措施并不适用。为了应对这些挑战，我们提出了ShieldAgent，这是第一个通过逻辑推理强制执行其他受保护代理动作轨迹显式安全政策合规的防护代理。具体来说，ShieldAgent首先通过从政策文件中提取可验证规则并将它们构建成一系列基于动作的概率规则电路来构建一个安全政策模型。针对受保护代理的动作轨迹，ShieldAgent检索相关规则电路并生成一个防护计划，利用其综合的工具库和可执行代码进行形式验证。此外，鉴于缺乏针对代理的防护基准，我们引入了ShieldAgent-Bench，这是一个包含3K条与安全相关的代理指令和动作轨迹对的数据库，通过在6个网络环境和7个风险类别中进行的SOTA攻击收集而来。实验表明，ShieldAgent在ShieldAgent-Bench和三个现有基准测试中都达到了SOTA水平，平均性能比先前方法提高了11.3%，召回率高达90.1%。此外，ShieldAgent将API查询减少了64.7%，推理时间减少了58.2%，展示了其在保护代理方面的高精度和效率。,赵润 陈,2025/3/26,2025/3/26,,,"['cs.LG', 'cs.CR']"
2503.18213v1,《神经符号人工智能研究：医疗保健视角》,http://arxiv.org/abs/2503.18213v1,在过去的几十年里，人工智能（AI）科学家一直在进行研究，旨在通过机器完成认知任务来达到人类水平的表现。在机器学习领域，最终的目标是通过机器实现通用人工智能（AGI）。这一追求导致了两种截然不同的AI范式的探索。符号AI，也称为经典或GOFAI（老式的AI），以及连接主义（亚符号）AI，后者以神经网络为代表，是两种互斥的范式。符号AI在推理、可解释性和知识表示方面表现出色，但在处理包含噪声的复杂现实世界数据方面面临挑战。相反，深度学习（黑盒系统）在神经网络研究中的突破值得注意，但它们缺乏推理和可解释性。神经符号AI（NeSy），作为AI研究的一个新兴领域，试图通过将逻辑推理集成到神经网络中来弥合这一差距，使它们能够用符号表示来学习和推理。虽然这是一条漫长的道路，但这种策略已经在实现系统常识推理方面取得了重大进展。本文对来自主要科学数据库（DBLP、ACL、IEEEExplore、Scopus、PubMed、ICML、ICLR）的977多项研究进行了广泛回顾，全面考察了神经符号AI的多方面能力，特别是其医疗保健应用，尤其是在药物发现和蛋白质工程研究中的应用。这项调查涉及了重要的主题，包括推理、可解释性、集成策略、41个与医疗保健相关的用例、基准测试、数据集、来自医疗保健和更广泛视角的当前方法局限性，以及为未来实验提出的创新方法。,德尔洛·霍萨因,2025/3/23,2025/3/23,,,['cs.AI']
2503.18050v1,(I-DLE：通过KL散度最小化保持分布的Logit排除来进行生成推理的约束解码),http://arxiv.org/abs/2503.18050v1,我们提出了（G）I-DLE，一种新的受限解码方法，该方法利用KL散度最小化来保持自回归语言模型的内生条件概率分布，同时排除不希望出现的标记。与那些天真地将禁用标记的logits设置为$-\infty$的常规方法不同，这可能会扭曲原始logits到后验概率的转换并增加输出方差，(G）I-DLE重新规范化允许的标记概率，以最小化这种扭曲。我们在K2-Eval数据集上验证了我们的方法，该数据集是专门为评估韩国语言的流畅性、逻辑推理和文化恰当性而设计的。在Qwen2.5模型（从1.5B到14B）上的实验结果表明，G-IDLE不仅能提升平均评估分数，还能显著降低输出质量的方差。,李韩 Wool,2025/3/23,2025/3/23,,,"['cs.CE', 'cs.CL']"
2503.17860v1,增强检索系统通过推理时逻辑推理,http://arxiv.org/abs/2503.17860v1,传统的检索方法依赖于将用户查询转换为向量表示，并在嵌入空间内根据余弦相似度检索文档。虽然这种方法高效且可扩展，但往往无法处理涉及否定、合取和析取等逻辑结构的复杂查询。在这篇论文中，我们提出了一种新颖的推理时间逻辑推理框架，该框架明确地将逻辑推理融入检索过程。我们的方法从自然语言查询中提取逻辑推理结构，然后将单个余弦相似度得分进行组合，以制定最终的文档得分。这种方法使得检索过程能够处理复杂的逻辑推理，同时不会牺牲计算效率。我们在合成数据和现实世界基准测试中的结果表明，所提出的方法在不同模型和数据集上始终优于传统检索方法，显著提高了复杂查询的检索性能。,菲力克斯·法尔廷斯,2025/3/22,2025/3/22,,,['cs.CL']
2503.18968v3,MedAgent-Pro：通过推理代理工作流程迈向基于证据的多模态医学诊断,http://arxiv.org/abs/2503.18968v3,在现代医学中，临床诊断主要依赖于对文本和视觉数据的综合分析，并借助医学专业知识确保系统性和严谨的逻辑推理。近年来，大型视觉-语言模型（VLMs）和基于代理的方法在医疗诊断方面展现出巨大潜力，这得益于它们有效整合多模态患者数据的能力。然而，这些方法往往直接提供答案，并基于经验驱动的结论，而没有进行定量分析，这降低了它们的可靠性和临床实用性。我们提出了MedAgent-Pro，这是一种新的基于代理的推理范式，它遵循现代医学的诊断原则，将过程分解为逐步的、基于证据的推理的各个组成部分。我们的MedAgent-Pro工作流程呈现了一个层次化的诊断结构，以反映这一原则，包括疾病级别的标准化计划生成和患者级别的个性化逐步推理。为了支持疾病级别的规划，我们设计了一个基于RAG（检索即生成）的代理来检索医学指南，以确保与临床标准的一致性。对于患者级别的推理，我们提出整合专业工具，如视觉模型，以实现定量评估。同时，我们提出验证每个步骤的可靠性，以实现基于证据的诊断，强制执行严谨的逻辑推理和有充分依据的结论。在广泛的人体解剖区域、成像方式和疾病上的大量实验证明了MedAgent-Pro相对于主流VLMs、基于代理的系统以及最先进的专家模型的优越性。消融研究和临床专家的人类评估进一步验证了其鲁棒性和临床相关性。代码可在https://github.com/jinlab-imvr/MedAgent-Pro上找到。,王紫月,2025/3/21,2025/7/2,,,['cs.AI']
2503.17125v5,LaMOuR：利用语言模型在强化学习中的分布外恢复,http://arxiv.org/abs/2503.17125v5,深度强化学习（DRL）在机器人控制方面展现了强大的性能，但仍然容易受到分布外（OOD）状态的影响，这往往导致不可靠的行为和任务失败。虽然之前的方法主要关注最小化或防止OOD的发生，但它们在很大程度上忽略了代理遇到此类状态后的恢复。尽管最新的研究试图通过引导代理回归分布内状态来解决这个问题，但它们对不确定性估计的依赖阻碍了在复杂环境中的可扩展性。为了克服这一限制，我们引入了用于分布外恢复的语言模型（LaMOuR），它能够在不依赖不确定性估计的情况下进行恢复学习。LaMOuR生成密集的奖励代码，引导代理回到一个能够成功执行其原始任务的状态，利用LVLM在图像描述、逻辑推理和代码生成方面的能力。实验结果表明，LaMOuR在多种运动任务中显著提高了恢复效率，甚至能够有效地推广到包括类人运动和移动操作在内的复杂环境，而现有方法在这些环境中往往难以应对。代码和补充材料可在https://lamour-rl.github.io/找到。,陈金,2025/3/21,2025/3/28,,,"['cs.RO', 'cs.AI']"
2503.14499v2,衡量人工智能完成长时间任务的能力,http://arxiv.org/abs/2503.14499v2,尽管在人工智能基准测试方面取得了快速进展，但基准性能在现实世界中的意义仍然不明确。为了量化人工智能系统在人类能力方面的能力，我们提出了一种新的指标：50%任务完成时间范围。这是人类通常完成人工智能模型以50%成功率完成的任务所需的时间。我们首先对具有相关领域专业知识的人类在RE-Bench、HCAST和66个新的较短任务组合上进行了计时。在这些任务上，当前前沿的人工智能模型如Claude 3.7 Sonneth的50%时间范围大约为50分钟。此外，自2019年以来，前沿人工智能的时间范围大约每七个月翻一番，尽管这种趋势可能在2024年有所加快。人工智能模型时间范围的增加似乎主要是由更高的可靠性和适应错误的能力，以及更好的逻辑推理和工具使用能力所驱动的。我们讨论了我们结果（包括其外部有效性的程度）的局限性，以及增加自主性对危险能力的影响。如果这些结果可以推广到现实世界的软件任务，那么这一趋势的外推预测表明，在5年内，人工智能系统将能够自动化许多目前需要人类一个月才能完成的软件任务。,托马斯·夸（Thomas Kwa）,2025/3/18,2025/3/30,,,"['cs.AI', 'cs.LG']"
2503.15551v2,高效却易受攻击：LLM 批量提示攻击的基准测试与防御,http://arxiv.org/abs/2503.15551v2,批量提示，即在一次推理中结合多个具有相同上下文的查询，已经成为降低推理成本的一个有前景的解决方案。然而，我们的研究揭示了批量提示中存在一个重大的安全漏洞：恶意用户可以将攻击指令注入到批量查询中，导致所有查询产生不期望的干扰，可能包括包含恶意内容，如钓鱼链接，或破坏逻辑推理。在本文中，我们构建了BATCHSAFEBENCH，一个包含150条两种类型攻击指令和8k个批量实例的全面基准，以系统地研究批量提示漏洞。我们对封闭源代码和开源的大型语言模型（LLM）进行的评估表明，所有LLM都容易受到批量提示攻击。随后，我们探索了多种防御方法。虽然基于提示的防御对较小的LLM效果有限，但基于探测的方法在检测攻击时达到了约95%的准确率。此外，我们还进行了机制分析，以理解攻击原理并识别负责攻击的注意力头。,慕容岳,2025/3/18,2025/6/20,,,"['cs.CR', 'cs.AI', 'cs.LG']"
2503.12161v1,亚里士多德的原始思想：在人工智能时代，赞成与反对逻辑,http://arxiv.org/abs/2503.12161v1,亚里士多德通常被认为是逻辑学的奠基人。他在逻辑推理研究中所提出的观点，推动了科学在几个世纪中的发展。今天，在人工智能时代，这个“逻辑之父”的头衔又具有了新的意义。这背后是他原创性的观点，即人类的推理可以被研究为一个过程，也许存在普遍的推理系统，它支撑着所有人类推理，无论我们推理的内容是什么。在这篇文章中，我们从人工智能的现代视角出发，探讨了亚里士多德关于人类思维的工作，关于推理本身的工作，以及这些工作如何与更广泛的科学和人类努力相关联，并探讨这能否帮助我们更深入地理解人工智能和科学。,安东尼·C·卡卡斯,2025/3/15,2025/3/15,,,"['cs.AI', 'I.2.0 General']"
2503.10691v2,推理是视频泛化所需的一切：一个带有子问题评估的反事实基准,http://arxiv.org/abs/2503.10691v2,反事实推理对于稳健的视频理解至关重要，但在现有的多模态基准测试中却鲜有涉猎。在本文中，我们引入了 \textbf{COVER} (\textbf{\underline{CO}}unterfactual\textbf{\underline{V}}id\textbf{\underline{E}}o\textbf{\underline{R}}easoning)，这是一个多维度的多模态基准测试，系统地评估了跨抽象-具体和感知-认知维度的多语言语言模型（MLLM）。在先前的多模态基准测试之外，COVER 将复杂查询分解为结构化的子问题，从而实现了细致的推理分析。在商业和开源模型上的实验揭示了子问题准确率与反事实推理性能之间的强相关性，突出了结构化推理在视频理解中的作用。此外，我们的研究结果还表明一个关键洞察：增强模型的推理能力对于提高视频理解的稳健性至关重要。COVER 为评估 MLLM 在动态环境中的逻辑推理能力设定了新的标准。我们的工作可在 https://github.com/gongyifan-hash/COVER-Benchmark 上找到。,周其吉,2025/3/12,2025/6/4,,,['cs.CV']
2503.07536v2,LMM-R1：通过两阶段基于规则的强化学习，赋予30亿个LMM强大的推理能力,http://arxiv.org/abs/2503.07536v2,增强大型多模态模型（LMMs）的推理能力面临着独特的挑战，这些挑战源于视觉感知与逻辑推理之间的复杂相互作用，尤其是在参数量紧凑的3B参数架构中，架构限制使得推理能力受限和多模态对齐变得困难。虽然基于规则的强化学习（RL）在纯文本领域表现卓越，但其多模态扩展面临两个关键障碍：（1）由于模糊答案和稀缺的复杂推理示例导致的数据限制，以及（2）多模态预训练导致的推理基础下降。为了应对这些挑战，我们提出了\textbf{LMM-R1}，这是一个两阶段框架，通过\textbf{基础推理增强（FRE）}和随后进行的\textbf{多模态泛化训练（MGT）}来调整基于规则的RL以实现多模态推理。FRE阶段首先利用仅文本数据通过基于规则的RL强化推理能力，然后MGT阶段将这些推理能力泛化到多模态领域。在Qwen2.5-VL-Instruct-3B上的实验表明，LMM-R1在多模态和纯文本基准测试中分别实现了4.83%和4.5%的平均提升，在复杂的足球比赛任务中提升了3.63%。这些结果表明，基于文本的推理增强能够实现有效的多模态泛化，提供了一种数据高效的范式，绕过了昂贵的高质量多模态训练数据。,彭英哲,2025/3/10,2025/3/11,,,"['cs.CL', 'cs.AI']"
2503.06518v1,向更高量化精度迈进：一种层敏感方法,http://arxiv.org/abs/2503.06518v1,大型视觉和语言模型在自然语言理解、问题解决、逻辑推理和知识检索等任务上展现出了令人瞩目的类人智能。然而，训练和部署这些模型需要大量的计算资源，这给它们的广泛应用和进一步研究带来了重大障碍。为了缓解这一挑战，已经开发了各种模型压缩技术以降低计算需求。然而，现有方法通常采用统一的量化配置，未能考虑到量化大型神经网络模型时不同层级的难度差异。本文通过利用层敏感性特征，如激活敏感性和权重分布峰度，来识别量化难度较大的层级并分配额外的内存预算，从而解决了这一问题。所提出的方法分别命名为SensiBoost和KurtBoost，它们在量化精度上实现了显著的提升，与基线相比，在LLama模型上仅增加了2%的内存预算，就实现了高达9%的困惑度降低。,风张,2025/3/9,2025/3/9,,,"['cs.LG', 'cs.AI']"
2503.06427v1,视觉生成式归因学习的前训练元规则选择策略,http://arxiv.org/abs/2503.06427v1,视觉生成式演绎学习研究联合训练基于符号的神经网络视觉生成器和从数据中诱导逻辑规则，使得在学习之后，视觉生成过程受到诱导逻辑规则的指导。这一任务的一个主要挑战是降低学习过程中逻辑演绎的时间成本，这对于逻辑符号集很大且要诱导的逻辑规则复杂的情况下尤为重要。为了应对这一挑战，我们提出了一种预训练方法，用于获得最近提出的视觉生成学习方法AbdGen（Peng等人，2023）的元规则选择策略，旨在显著减少候选元规则集并裁剪搜索空间。选择模型基于案例符号化和元规则的嵌入表示，可以有效地与神经网络模型和逻辑推理系统集成。预训练过程在纯符号数据上完成，不涉及原始视觉输入的符号化学习，使整个学习过程成本低廉。一个有趣的额外观察是，选择策略可以纠正预训练过程中未见的符号化错误，这是由注意力机制的记忆能力和符号模式的相对稳定性造成的。实验结果表明，我们的方法能够有效解决视觉演绎的元规则选择问题，提高了视觉生成式演绎学习的效率。代码可在https://github.com/future-item/metarule-select找到。,于金,2025/3/9,2025/3/9,,,"['cs.LG', 'cs.AI', 'cs.CV']"
2503.04378v2,HelpSteer3：人工标注的反馈和编辑数据，以增强开放域任务中推理时缩放的效能,http://arxiv.org/abs/2503.04378v2,推理时间缩放对于近期如OpenAI o1和DeepSeek R1等模型的成功至关重要。然而，许多用于训练模型进行推理时间缩放的技术都需要任务有可验证的答案，这限制了它们在数学、编码和逻辑推理等领域的应用。我们从人类在广泛的开端性尝试中寻求灵感，向他人寻求详细的反馈，并根据这样的反馈进行改进。为此，我们收集了HelpSteer3数据来训练专门的反馈和编辑模型，这些模型能够为开放性通用领域任务执行推理时间缩放。在我们的设置中，一个模型生成初始响应，第二个模型提供反馈，然后第三个模型根据这些反馈编辑响应。我们表明，通过缩放初始响应草稿的数量、有效的反馈和编辑后的响应，可以在Arena Hard基准测试中提升性能，该基准测试对Chatbot Arena Elo的预测性很强。当我们的基于Llama 3系列70B模型的设置达到最佳缩放时，截至2025年3月5日，在Arena Hard上的SoTA性能可以达到92.7，超过了OpenAI o1-preview-2024-09-12的90.4和DeepSeek R1的92.3。,王志麟,2025/3/6,2025/5/30,,,"['cs.CL', 'cs.AI', 'cs.LG']"
2503.04848v2,在Transformer和大脑架构中的三层计算级别,http://arxiv.org/abs/2503.04848v2,人类语言和逻辑能力在经过广泛研究的语法-自动机层次结构中得到计算量化。我们确定了三个层次级别和两种相应的过渡，并展示了它们与基于转换器（transformer）的语言模型（LMs）中特定能力之间的对应关系。这些新兴能力通常用扩展性来描述；我们表明，决定系统能力的是层次之间的过渡，而不是扩展规模本身。具体来说，人类处理语言的能力无需多加训练，却能轻松完成；而进行算术或逻辑推理任务时则需要关键性的训练；LMs具有前辈系统中没有的语言能力，但在逻辑处理上仍面临挑战。我们提出了一个计算能力的创新基准，对人类和十五个LM进行了实证评估，更重要的是，提供了一个有理论基础的框架，以促进对这些关键话题的深入思考。由此产生的原则性分析解释了LMs的能力和不足，并提出了扩展其逻辑能力的可操作见解。,E Graham可以翻译为“E·格雷厄姆”。这里的E可能是一个名字的首字母缩写，而Graham是一个姓氏。如果是在特定语境中，例如人名或公司名，可能需要根据具体情况进行调整。,2025/3/5,2025/3/12,,,"['cs.CL', 'cs.NE', 'q-bio.NC']"
2503.02172v1,KGCompiler：知识图谱复杂逻辑查询应答的深度学习编译优化,http://arxiv.org/abs/2503.02172v1,复杂逻辑查询回答（CLQA）涉及在大规模且可能不完整的知识图谱（KGs）上进行的复杂多跳逻辑推理。尽管现有的CLQA算法在回答此类查询时达到了高精度，但它们的推理时间和内存使用量会随着涉及的谓词逻辑（FOL）运算符数量的增加而显著增加，给实际部署带来了严重挑战。此外，当前研究主要集中于CLQA任务的算法级优化，往往忽略了编译器级优化，后者可以提供更大的通用性和可扩展性。为了解决这些局限性，我们引入了一种知识图谱编译器，即KGCompiler，这是第一个专门为CLQA任务设计的深度学习编译器。通过结合本文提出的针对KG的优化，KGCompiler增强了CLQA算法的推理性能，而无需对其实现进行额外的手动修改。同时，它显著降低了内存使用量。大量实验表明，KGCompiler将CLQA算法加速了1.04倍到8.26倍，平均加速了3.71倍。我们还提供了一个接口，以便用户能够亲身体验KGCompiler。,林红玉,2025/3/4,2025/3/4,,,"['cs.AI', 'cs.SE']"
2502.16965v3,基于视觉全景提示的自动回归图像生成,http://arxiv.org/abs/2502.16965v3,在自回归（AR）图像生成中，基于大型语言模型（LLM）的“下一标记预测”范式的模型通过减少归纳偏差，其性能与扩散模型相当。然而，将LLM直接应用于复杂的图像生成时，在重建图像的结构和细节方面可能会遇到困难，这会影响生成的准确性和稳定性。此外，AR模型中的“下一标记预测”范式与人类视觉感知中涉及到的上下文扫描和逻辑推理过程不一致，限制了有效的图像生成。提示工程作为引导LLM的关键技术，通过特别设计的提示来提高模型在复杂自然语言处理（NLP）任务上的性能，增强了生成的准确性和稳定性，同时保持了上下文连贯性和逻辑一致性，类似于人类的推理。受NLP领域提示工程的启发，我们提出了视觉全视图提示（VF提示）来增强自回归图像生成。具体来说，我们为AR图像生成设计了专门与图像相关的VF提示，以模拟人类图像创造的过程。这通过允许模型首先感知整体分布信息然后再生成图像，增强了上下文逻辑能力，并通过增加推理步骤提高了生成稳定性。与未使用VF提示的AR方法相比，我们的方法表现出卓越的性能，并实现了大约20%的改进。,蔡喵喵,2025/2/24,2025/3/12,,,['cs.CV']
2502.14373v1,CrossVTON：基于三区先验的跨类别虚拟试穿中的逻辑推理模仿,http://arxiv.org/abs/2502.14373v1,尽管在基于图像的虚拟试穿系统中取得了显著进展，但生成适用于跨类别虚拟试穿的逼真且稳健的搭配图像仍然是一项具有挑战性的任务。主要困难源于缺乏类似人类的推理能力，这涉及到解决服装与模型之间的大小不匹配问题，同时识别并利用模型图像中各个区域的独特功能。为了解决这个问题，我们借鉴了人类的认知过程，并将跨类别试穿所需的复杂推理分解为一个结构化的框架。这个框架将模型图像系统地分解为三个不同的区域：试穿区、重建区和想象区。每个区域在适应服装和促进逼真合成方面都扮演着特定的角色。为了赋予模型在跨类别场景中稳健的推理能力，我们提出了一种迭代数据构造器。这个构造器涵盖了多种场景，包括同类别试穿、任何到服装的转换（用服装替换任何服装类别）以及服装到任何的转换（用另一种服装类别替换服装）。利用生成的数据集，我们引入了一个三区域先验生成器，它通过分析输入服装预期如何与模型图像对齐，智能地预测试穿区、重建区和想象区。在三个区域先验的指导下，我们提出的方法CrossVTON在定性和定量评估中均达到了最先进的性能，超越了现有的基线。值得注意的是，它在处理跨类别虚拟试穿方面表现出卓越的能力，满足了现实应用中的复杂需求。,罗东豪,2025/2/20,2025/2/20,,,['cs.CV']
2502.12919v1,从归纳到演绎的平稳过渡：基于概率符号感知的快速推论学习,http://arxiv.org/abs/2502.12919v1,归纳学习（ABL）将机器学习和逻辑推理的优势相结合，以提高学习的泛化能力，最近已被证明是有效的。然而，其效率受到从数值归纳到符号演绎的转换影响，在最坏的情况下导致高计算成本。针对这一问题的研究仍然有限。在本文中，我们确定了先前ABL优化算法不有效的原因有三个：未能充分利用预测、符号关系和成功归纳过程中的累积经验，导致对知识库的冗余计算。为了应对这些挑战，我们引入了一种名为概率符号感知（PSP）的优化算法，该算法在归纳和演绎之间实现平滑过渡，同时保持ABL的正确性不变。我们利用概率作为桥梁，并提出了一种高效的数据结构，以低计算复杂度将连续概率序列转换为离散布尔序列。实验结果表明了其有前景的结果。,贾林翰,2025/2/18,2025/2/18,,,['cs.LG']
2502.12304v1,《预热世代：一种无需监督初始状态生成的任务无关方法，用于指导序列到序列学习》,http://arxiv.org/abs/2502.12304v1,传统的监督微调（SFT）策略在序列到序列的任务中通常训练模型直接生成目标输出。最近的研究表明，通过中间步骤，如关键词、大纲或推理链来引导模型，可以显著提高性能、连贯性和可解释性。然而，这些方法通常依赖于预定义的中间格式和标注数据，限制了它们的可扩展性和泛化能力。在这项工作中，我们介绍了一个任务无关的框架，使模型能够生成中间的“预热”序列。这些预热序列作为后续生成的初始状态，经过优化以提高生成目标序列的概率，而不依赖于外部监督或人为设计的结构。受强化学习原理的启发，我们的方法迭代地细化这些中间步骤，以最大化其对最终输出的贡献，类似于强化学习中带有人类反馈的奖励驱动优化。在翻译、摘要和多选题问答等逻辑推理任务上的实验结果表明，我们的方法优于传统的SFT方法，并为序列到序列任务提供了一种可扩展且灵活的解决方案。,李森宇,2025/2/17,2025/2/17,,,"['cs.CL', 'cs.AI']"
